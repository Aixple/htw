\section{Einführung}
\subsection{Ziele}
\slides{06_SE-Usability-Einfuehrung}{5}
Effektiv: Gestaltung erlaubt, die Erfüllung der Aufgabe\\
Effizient: Gestaltung erlaubt, die Erfüllung der Aufgabe in einer für den Nutzer angemessenen Zeit mit einem angemessenen Aufwand
\subsection{Begriffsdefinition}
Fritz Lang thematisiert in Metropolis die Entmenschlichung der Technik und der Arbeitswelt. In dem Film wird der Mensch als Sklave der Maschine dargestellt.
\slides{06_SE-Usability-Einfuehrung}{7}
\slides{06_SE-Usability-Einfuehrung}{8}
\subsubsection{Ergonomie}
In der ersten Hälfte des 20. Jahrhunderts hatte man die Verbesserung der Mensch/Maschine-Interaktion als notwendiger Schritt für den Erfolg eines Unternehmens entdeckt.  Allerdings ging es damals noch um die Anpassung des Menschen an die Maschine. Es ging z.B. darum „unnötige“ Arbeitsabläufe zu minimieren.

Diese unmenschliche Einstellung zur Arbeit hat Fritz Lang in seinem genialen Streifen „Metropolis“ aus dem Jahre 1927 eindrucksvoll reflektiert (der Film wurde 2010 restauriert und auf der Berlinale wieder aufgeführt).

Die Ergonomie von Arbeitsplätzen wurde erst in der Mitte des 20. Jahrhunderts thematisiert. Die Arbeitgeber und Fabrikbesitzer mussten erkennen, dass der Mensch sich nicht beliebig anpassen kann. Es ist umgekehrt: die Anpassung der Arbeitsbedingungen an menschlichen Bedürfnissen ist für die Erhaltung der Gesundheit und letzten Endes für die Erhöhung der Produktivität und für den Erfolg eines Unternehmens unerlässlich. Aus diesem Grund wurde die Ergonomie geboren mit dem Ziel, die Arbeit menschlicher zu gestalten. Das Thema hat sich langsam zu einer Wissenschaft entwickelt: Ergonomie ist die allgemeine Wissenschaft der \emph{Anpassung der Technik an ihre Benutzer}. 

In unserem Zusammenhang kann man unterscheiden: 
\begin{itemize}
\item Hardware-Ergonomie: sie erörtert die Aspekte der menschengerechten Hardware-Ge\-stal\-tung: Eingabe- und Ausgabe-Geräte.
\item Software-Ergonomie: sie beschäftigt sich mit der benutzergerechten Gestaltung der Mensch-Computer Schnittstelle d.h. mit der Gestaltung der Benutzungsoberfläche von Software-Systemen.
\end{itemize}
\slides{06_SE-Usability-Einfuehrung}{10}
Für die menschliche Hand ist dies eine unmögliche Gestaltung: diese Maus mag schick aussehen, ergonomisch ist sie nicht.
\slides{06_SE-Usability-Einfuehrung}{11}

\subsubsection{Usability und Usability Engineering}
Usability ist das englische Wort für \emph{Gebrauchstauglichkeit, Bedienbarkeit}, und bezeichnet in diesem Zusammenhang die Eigenschaft der Software, ergonomisch und gut bedienbar zu sein. Das Wort „Usability“ hat sich – wie viele andere englische Wörter – in der Deutschen Fachsprache durchgesetzt, eine gute Übersetzung ist m.E. Nutzungsqualität.

Usability Engineering ist eine angewandte Disziplin, die die Prinzipien der Software-Ergonomie und die Methoden der empirischen Forschung für die Optimierung von Software-Oberflächen praktisch anwendet. Usability Engineering kann als die \emph{praktische Anwendung der Software-Ergonomie} verstanden werden. Sie orientiert sich an den Prinzipien des Nutzer-Orientierten Designprozesses.

Noch einmal zusammengefasst
\begin{itemize}
\item Ergonomie ist eine Wissenschaft; sie beschäftigt sich mit der Anpassung der Technik an den Menschen (und zwar nicht nur im Rahmen der Informationstechnologien).
\item Usability Engineering ist angewandte Wissenschaft, angewandte Ergonomie und zwar in Rahmen der IT
\item Usability ist eine Eigenschaft der Software bzw. der Hardware. 
\end{itemize}

Wenn Sie diese Begriffe klar voneinander unterscheiden, können Sie in einem zweiten Schritt darüber reflektieren, dass die Bedeutungsgrenzen in der Praxis verwischen, weil die Wörter nicht immer 100\% treffend benutzt werden: 

\begin{itemize}
\item Oft wird das Wort Usability allgemeiner genutzt, man bezeichnet damit  den ganzen Prozess des Usability Engineering oder gar die Ergonomie im IT-Bereich. 
\item Das Wort Ergonomie wird auch für die Eigenschaft genutzt, man spricht von „guter Ergonomie“ oder benutzt einfach das Adjektiv „ergonomisch“. 
\end{itemize}

\subsection{Geltung}
\slides{06_SE-Usability-Einfuehrung}{13}
\slides{06_SE-Usability-Einfuehrung}{14}
Eine gute Usability ist mehr denn je notwendig, denn die Technik breitet sich in unserem Leben immer mehr aus. 

Die Gebrauchstauglichkeit wird zum Glück immer mehr aber trotzdem nicht immer ausreichend berücksichtigt; das Ergebnis: Technikfrust als zunehmendes Problem in modernen Industriegesellschaften.

\section{Ergonomie im Alltag}
\slides{06_SE-Usability-Einfuehrung}{16}
Donald A. Norman, ein amerikanischer Wissenschaftler, der zusammen mit dem „Usability-Guru“ Jakob Nielsen eine Beratungsfirma betreibt, veröffentlichte 1990 das viel zitierte und immer wieder neu aufgelegte Buch „The Desing of Everyday Things“, das großen Aufsehen erregte und bis heute einen großen Einfluss ausübt.
 
Norman macht sich in seinem Buch Gedanken darüber, wie Alltagsgegenstände (z.B. Türen, Telefone etc.) so gestaltet werden können, dass sie einfach zu bedienen sind. 

Er ermittelt die vier Prinzipien, die bei der Gestaltung von Gegenständen eingehalten werden sollen.

\subsection{Sichtbarkeit}
\slides{06_SE-Usability-Einfuehrung}{17}
Diese Türgriffe sind sichtbar und auch haptisch so gestaltet, dass sie den Eindruck erwecken, dass sie gedruckt werden sollen. Aber weit gefehlt! sie müssen gezogen werden! Die Gestaltung vor allem in oberem Beispiel ist KATASTROPHAL. Die große Fläche lädt eindeutig dazu ein, zu drücken.

Wenn ein so einfaches Objekt wie ein Türgriff eine „Bedienungsanleitung“ benötigt (Wort „PULL“) liegt die Vermutung nah, dass das Design nicht gelungen ist.
\slides{06_SE-Usability-Einfuehrung}{18}
Zwei Beispiele für gut gestaltete Türgriffe. 
\begin{itemize}
\item Links handelt es sich um die typische Gestaltung von Türgriffen für einen Flugweg, die Tür wird gedrückt, das muss eindeutig sein, denn in diesem Fall geht es um Leben und Tod. 
\item Rechts ist die Tür eines Hotels dargestellt: elegant und gleichzeitig nutzerfreundlich. Der Griff selbst zeigt, wo gezogen und wo gedrückt werden soll; ein gelungenes Design.
\end{itemize} 
\subsection{Abbildung}
Die Gestaltung (Anzahl, Form, Position etc.) der Bedienelemente und die Art, wie sie bedient werden, müssen die Funktionalität des Geräts abbilden.
\slides{06_SE-Usability-Einfuehrung}{19}
Norman erläutert dieses Prinzip mit seinem Diaprojektor, der nur eine Taste zum vor- und rückwärtsblättern besitzt. Wird die Taste normal gedrückt, blättert der Projektor nach vorne, wird sie etwas länger gedrückt, blättert der Projektor zurück. 

Dieses Design mag elegant erscheinen, aber es ist sehr fehleranfällig und daher nutzerunfreundlich: drückt man aus Versehen oder weil man besonders gründlich sein möchte, etwas länger, blättert der Projektor in die falsche Richtung. Erschwerend kommt es in diesem Gerät hinzu, dass wenn man am Anfang der Präsentation ist und man rückwärts drückt, alle Dias auf dem Boden fallen (das Gerät ist nicht fehlertolerant): ein KATASTROPHALES Design. 
\slides{06_SE-Usability-Einfuehrung}{20}
Noch ein Beispiel für das Prinzip der Abbildung: die Regler für Kochfelder sollten die Anordnung der Kochfelder selbst abbilden. Das ist natürlich gar nicht so einfach, da die Felder zweidimensional sind, die Regler aber eindimensional angeordnet werden müssen.
\slides{06_SE-Usability-Einfuehrung}{21}
Diese Vorschläge von Norman erfüllen das Prinzip der Abbildung. Allerdings merkt jede Hausfrau aus der Mittelsicht, dass diese Kochfelder einfach zu viel Fläche in der Küche einnehmen würden. 
\slides{06_SE-Usability-Einfuehrung}{22}
Die Industrie hat in diesem Fall eine sehr gute Lösung gefunden. Die Regler für die hintere Kochfelder werden in die Mitte platziert denn, wenn man sich die dritte Dimension dazu vorstellt, rücken die hintere Kochfelder tatsächlich in die Mitte, wie man in diesem Bild feststellen kann. 

Die hier abgebildete Lösung des Herstellers Neff ist allerdings noch besser, die Abbildung selbst ist zweidimensional und damit sind die Kochfelder perfekt abgebildet (mapping). 
\subsection{Denkmodelle}
Wenn Menschen Geräte bedienen, machen sie sich immer Gedanken und erstellen Theorien darüber (ob richtig oder nicht), wie diese Geräte funktionieren. Norman führt an, dass die Bedienelemente ein richtiges Modell der Objektfunktionalität vermitteln sollten.
\slides{06_SE-Usability-Einfuehrung}{23}
Als Beispiel gibt hier Herr Norman sein Kühlschrank. Der Kühlteil und der Gefrierteil werden vom selben Motor gekühlt; um zwei unterschiedlichen Temperaturen zu regulieren, kann man mehr oder weniger kalte Luft in jede Richtung einführen. Dieses Bild zeigt wie das Gerät richtig funktioniert. 
\slides{06_SE-Usability-Einfuehrung}{24}
Die Funktionsweise des Geräts schien aber dem Designer zu schwer zu vermitteln. 

Die Bedienung (hier illustriert) besteht aus 2 Regler. Es sieht so aus, dass ein Bedienelement (rechts) für den Kühlschrank und ein anderes (links) für den Gefrierteil zuständig ist, als würden beide Teile unabhängig von einander gekühlt werden. 
\slides{06_SE-Usability-Einfuehrung}{25}
Diese Bild zeigt, welches Denkmodell die Bedienung dem Nutzer suggeriert: jeder Regler reguliert einen Motor, beide Teile sind unabhängig voneinander.

Weil das Denkmodell nicht stimmt, ist die Bedienung des Kühlschranks von Herrn Norman ausgesprochen schwer. Daher die lange Liste mit Bedienungshinweisen im Kühlschrank (siehe vorige Folie). Eine lange Bedienanleitung bei nur 2 Regler: mit diesem Design stimmt etwas nicht! In der Tat das „Conceptual Model“ ist falsch!
\subsection{Rückmeldung}
Das Gerät sollte über seinen Zustand informieren.
\slides{06_SE-Usability-Einfuehrung}{26}
Ein letztes Beispiel: mein eigener Kühlschrank, auch er hat zwei getrennte Temperaturzonen (genannt „cold“ und „fresh“), leider hat er aber nur einen Regler, hier stimmt das bereits erwähnte Prinzip der Abbildung nicht. Wir soll man zwei verschiedene Temperaturen mit nur einem Regler steuern? Ich weiss es heute immer noch nicht!

Außerdem wird hier nur eine Temperatur angezeigt und es ist nicht einmal klar, welche: für „cold“? oder für „fresh“?  Rückmeldung, das vierte Prinzip von Norman, wurde hier ebenfalls mit Füssen getreten. 

\section{Wissenschaftliche Disziplin}
\subsection{Definition}
Definition von Software-Ergonomie von Eberleh (1994)

Software-Ergonomie befasst sich mit der benutzergerechten Gestaltung der Mensch-Computer-Interaktion (MCI) oder Human Computer Interface (HCI) – und zwar mit den Softwareaspekten (im Gegensatz zur Hardware-Ergonomie).
 
Die Software-Ergonomie existiert in Deutschland als wissenschaftliche Disziplin seit den 80er Jahren. Die erste Fachtagung der Software-Ergonomie wurde in Deutschland 1983 abgehalten, dieses Datum ist entscheidend in die Geschichte der Software-Ergonomie.

\subsection{Ziele}
Die Benutzergerechte Gestaltung von Software-Interfaces berücksichtigt nach Eberleh  vier Aspekte bzw. hat vier Ziele:
\begin{itemize}
\item Menschengerechte Gestaltung\\
Dieses Ziel erfordert Kenntnisse über menschliche Wahrnehmung und Kognition (Medienpsychologie). 
\item Aufgabenangemessene Gestaltung\\
Dieses Ziel erfordert Kenntnisse über die Aufgaben und Ziele der Arbeit. 
Hier ordnet sich die Software-Gestaltung der Arbeitsgestaltung unter, die für menschengerechte Aufgaben und Arbeitsbedingungen zu sorgen hat. 
\item Organisationsgerechte Gestaltung\\
Die Mensch-Computer-Interaktion muss oft Organisations- und Kommunikationsaspekte berücksichtigen, da die Software in Organisationen und Unternehmen genutzt wird. 
\item Technikbewusste Gestaltung\\
Neue technische Optionen müssen bekannt sein und zum Wohle der Benutzer eingesetzt werden.
\end{itemize}

\subsection{Forschungsbereiche}
Hier sind die Forschungsbereiche der Software-Ergonomie aufgelistet. Dazu einige Erläuterungen.

\subsubsection*{Grundlagenforschung}
Psychologische Forschung zur:
\begin{itemize}
\item menschlichen Wahrnehmung
\item menschliche Informationsverarbeitung
\end{itemize}
 
Arbeits- und organisationspsychologische Grundlagen der Software-Ergonomie (werden wir nicht behandeln)
 
\subsubsection*{Softwareergonomische Forschung}
Analyse der Formen der \emph{Mensch-Computer-Interaktion}: Ein-/Ausgabe-Gestaltung und Interaktionstechniken.

Auch Fehlermanagement und Hilfesysteme.

\emph{Gestaltungsrichtlinien} und Empfehlungen für Software- und interaktive Systeme.
 
\subsubsection*{Angewandte Forschung}
Einbeziehung der Ergebnisse der Software-Ergonomie in \emph{Aufgaben-Analyse}, \emph{System-Entwurf} und \emph{System-Evaluation}, kurz Usability Engineering.

\section{Grundlagenforschung}
Die Menschengerechte Gestaltung von Software erfordert Erkenntnisse über die Ergebnisse der psychologischen Forschung zur menschlichen Wahrnehmung und Informationsverarbeitung / Gedächtnis. Wir beschäftigen uns zunächst mit Wahrnehmungspsychologie.

\subsection{Wahrnehmungspsychologie}
Was ist Wahrnehmung?\\
Wahrnehmung ist ein \emph{Prozess}. In der Wahrnehmung zeigt sich mir (dem Subjekt) die \emph{physische Welt} (das Objekt) über die \emph{Sinne}. 

Zwei „philosophische“ Anmerkungen dazu:
\begin{itemize}
\item Mein Körper ist ein Teil der physischen Welt, ein Teil des Objekts.
\item Die Wahrnehmung liefert uns eine Reduktion, eine Abstraktion der Welt, nicht die „wirkliche“ Welt, nicht die Welt „an sich“.
\end{itemize}
\slides{06_SE-Usability-Einfuehrung}{33}
Die Wahrnehmung ist selektiv und zwar in zwei Hinsichten:
\begin{enumerate}
\item wir nehmen nur das wahr, worauf sich gerade unsere Aufmerksamkeit richtet. Bekannt ist das sog. „Cocktail-Party“-Phänomen, wir nehmen nur die Konversation in unserer Gruppe war. Wird aber z.B. unser Name in einem anderen Gespräch genannt, richtet sich unsere Aufmerksamkeit auf das andere Gespräch. 
\item unsere Sinne können ohnehin nur ein Teil der Welt wahrnehmen, z.B. sehen unsere Augen nur einen winzigen Teil des elektromagnetischen Spektrums.
\end{enumerate}
\slides{06_SE-Usability-Einfuehrung}{34}
Mehrdeutige Figuren wie dieses bekannte Bild, das gleichzeitig eine alte und eine junge Frau darstellt, zeigen dass wir im Prozess der Wahrnehmung nicht passiv sind, sondern aktiv interpretieren, um Objekte zu erkennen. Die Wahrnehmung ist interpretativ.
\slides{06_SE-Usability-Einfuehrung}{35}
Der Würfel wird aus den Kreisen zusammengesetzt, aber eigentlich ist er gar nicht da. Er wird im Prozess der Wahrnehmung konstruiert. Die Wahrnehmung ist konstruktiv.
\subsubsection{Phasen im Wahrnehmungsprozess}
Betrachtet man den Wahrnehmungsprozess analytisch, kann man drei Phasen unterscheiden:
\begin{enumerate}
\item Empfinden (Empfindungen)
\item Organisieren (sog. Percepten)
\item Identifizieren und Einordnen (Objekten)
\end{enumerate}

\subsubsection*{Empfinden}
Empfindung ist die Umwandlung physikalischer Energie in elektrisch kodierte Information, die von Gehirn weiterverarbeitet werden kann. Diese Umwandlung heißt Transduktion.

Achtung! Hier findet schon eine Reduktion der Wirklichkeit statt. Z.B. sieht das menschliche Auge nur ein Teil des elektromagnetischen Spektrums.

\subsubsection*{Organisieren}
Die Empfindungen werden geordnet. Sie sind nicht chaotisch. Wir „schätzen“ Formen, Größen, Entfernungen...

Ein gutes Beispiel dieser Organisationsprozess liefert das nach Ames genannte  Amescher Raum (siehe nächste Folie).

\subsubsection*{Identifizieren und einordnen}
Den Perzepten wird Bedeutung zugewiesen, Objekte werden erkannt. Das ist ein höherer kognitiver und durchaus komplexer Prozess. Zum Beispiel können Blinde, die erfolgreich operiert wurden und auf einem Mal sehen können, Objekt oft nicht an seinem Erscheinungsbild erkennen, sondern sie müssen sie ertasten. Der Arzt Senden gibt  schon 1932 das Beispiel einer jungen Frau an, die früher blind war, und ihre Katze mit den Augen nicht als solche erkennen konnte, erst als sie die Katze anfassen konnte, hat sie sie erkannt. Sie konnte die Perzepten, die für sie ganz neu waren, nicht richtig einordnen.
 
 
\slides{06_SE-Usability-Einfuehrung}{37}
Der Raum, erfunden vom Augenarzt und Psychologe Adelbert Ames, erscheint dem Betrachter rechtwinklig, er ist aber trapezförmig: eine Ecke ist weiter entfernt als die andere, der Mensch, der weiter entfernt ist, erscheint viel kleiner. Die Wahrnehmung wird durch den Aufbau des Raumes getäuscht, daher klappt das Organisieren der Empfindungen nicht: Entfernungen und Größen werden falsch eingeschätzt. 
\slides{06_SE-Usability-Einfuehrung}{38}
\subsubsection{Wahrnehmungsorganisation}
\slides{06_SE-Usability-Einfuehrung}{39}
Das Organisieren ist der zweite Schritt im Wahrnehmungsprozess nach dem Empfinden und vor dem Erkennen von Objekten. Dieser Schritt der Wahrnehmung ist zur Beginn der 20er Jahren untersucht worden (Gestaltpsychologie). Er ist von besonderer Bedeutung für die Bildschirmgestaltung. 
 
Die Vertreter der Gestaltpsychologie entdeckten, dass die Wahrnehmung sich nicht aus den Empfindungen allein zusammensetzt (Bottom up), sondern bestimmte übergeordnete Gesetzte gehorcht (Top down):
\begin{itemize}
\item Wahrnehmungskonstanzen (Farb-, Größe-, Formkosntanz …)
\item Organisationsgesetzte
\end{itemize}
\slides{06_SE-Usability-Einfuehrung}{40}
Wir sehen hier aufgrund der Nähe vier Zeilen von Kreisen und nicht 10 Spalten.
\slides{06_SE-Usability-Einfuehrung}{41}
Wir sehen hier aufgrund der Ähnlichkeit Zeilen von Kreisen und Quadrate und nicht Spalten.
\slides{06_SE-Usability-Einfuehrung}{42}
\slides{06_SE-Usability-Einfuehrung}{44}
In dieser Figur erkennen wir schnell ein Rechteck und ein Dreieck.

\subsubsection{Dreidimensionale Wahrnehmung}
\slides{06_SE-Usability-Einfuehrung}{45}
\subsubsection*{Zweidimensionale Darstellung der dritten Dimension}
\slides{06_SE-Usability-Einfuehrung}{46}
\subsubsection*{Beispiele}
\slides{06_SE-Usability-Einfuehrung}{47}
Die Stäbe befinden sich hinter dem Gitter, sie werden dadurch verdeckt, die Vogel dagegen davor: sie verdecken das Gitter. 
\slides{06_SE-Usability-Einfuehrung}{48}
Der Maler hat damals diese Technik noch nicht perfekt beherrscht, um so eindeutiger zeigt sich hier die Idee.
\slides{06_SE-Usability-Einfuehrung}{49}
\slides{06_SE-Usability-Einfuehrung}{50}
Farben verlieren an Sättigung und das Licht wird diffuser mit zunehmender Entfernung. 
\slides{06_SE-Usability-Einfuehrung}{51}
Der Maler hat in diesem Bild diese Technik so meisterhaft beherrscht, dass er sich erlaubt hat, im Hintergrund (Mann an der Tür) ein starkes Licht zu setzen. Das Bild hängt im Prado in Madrid und ist in Spanien für den Eindruck der Tiefe des Raumes, das es vermittelt, sehr bekannt.
\slides{06_SE-Usability-Einfuehrung}{52}
Flat Design ist nicht ganz flach

\subsection{Kognitionspsychologie}
\subsubsection{Gedächtnissysteme}
\slides{06_SE-Usability-Einfuehrung}{54}
\subsubsection*{Kurzzeitgedächtnis}
\slides{06_SE-Usability-Einfuehrung}{55}
\subsubsection*{Kurzzeitgedächtnis und Software-Erogonmie}
\slides{06_SE-Usability-Einfuehrung}{56}
\slides{06_SE-Usability-Einfuehrung}{57}
Auf jeder Menüebene werden genaue 7 Punkte angeboten. Das ist kein Zufall, der Designer hat die Kapazität des KZG beachtet.
\slides{06_SE-Usability-Einfuehrung}{58}
\subsubsection*{Langzeitgedächtnis}
\slides{06_SE-Usability-Einfuehrung}{59}
\subsubsection*{Langzeitgedächtnis und Software-Ergonomie}
\slides{06_SE-Usability-Einfuehrung}{60}

\section{Formen der Mensch-Computer Interaktion}
\subsection{Kommandosprachen}
Kommandosprachen wie dos oder unix sind für Endanwender kaum mehr anzutreffen, da sie das Gedächtnis sehr belasten. 

Kommandosprachen sind durch Menüs, Formulare und bildliche Darstellungen (direkte Manipulation) ersetzt worden.
\subsection{Menüs}
Menüs nutzen den Vorteil der Widererkennung gegenüber der reinen Erinnerungsleistung der Kommandosprachen. 

Das ist der Grund, warum Menüs sich durchgesetzt und enorm entwickelt haben: Pull-down-Menüs, Kaskaden-Menüs, Kontext-Menüs …
\slides{06_SE-Usability-Einfuehrung}{63}
Probleme bzw. Herausforderungen der Menügestaltung
\begin{itemize}
\item Die Strukturierung und Benennung der Wahlpunkte
\item Menüs benötigen viel Platz auf dem Bildschirm 
\item Die Steuerung über Menüs ist langsamer als die über Kommandosprachen
\end{itemize}
Lösungen
\begin{itemize}
\item Das Problem vom Platz wird gelöst mit Kaskaden- und Kontext-Menüs und mit der Auslagerung von Menüs in entsprechenden Paletten.
\item Die Langsamkeit wird durch Tastatur-Eingaben gelöst, die für Routine-Benutzer und Experte gedacht sind.
\item Auch Toolbars sind eine Maßnahme, die für mehr Schnelligkeit sorgen soll.
\end{itemize} 

\subsection{Formulare}
 Masken und Formulare (heute sprechen wir von Fenstern oder Dialog-Fenstern) sind 2-dimensionalen Anordnungen von Feldern, in denen Information aus- und eingegeben werden kann.
 
 Sie werden benutzt, um Angaben und Aufgaben, die zusammen gehören, auf dem Bildschirm zu gruppieren und zusammen darzustellen und sind daher ein einfaches aber sehr effektives Gestaltungsmittel von benutzerfreundlichen Oberflächen.
 
 Formularen sind einen Mittel der Darstellung zwischen Menüs und Direkter Manipulation.

Anforderungen an Formularen:
\begin{itemize}
\item Sie sollen aufgabenangemessen und übersichtlich sein (KZG).  
\item Sie sollen sofort verstanden werden können (Selbstbeschreibungsfähig)
\end{itemize}

Maßnahmen zur Gestaltung von Formularen
\begin{itemize}
\item Bildung von Gruppen und unterschiedliche Darstellung des Formulars für Anfänger und Experten.
\item Dies wird im Dialog-Fenster „Gradationskurven“ von Photoshop beispielhaft dargestellt.
\end{itemize}


\slides{06_SE-Usability-Einfuehrung}{64}
\slides{06_SE-Usability-Einfuehrung}{65}
\slides{06_SE-Usability-Einfuehrung}{66}
\subsection{Direkte Manipulation} 
\subsubsection{Bedeutung}
Direkte Manipulation bedeutet, dass Objekte und Prozesse auf dem Bildschirm visuell, d.h. mit Bildern (sog. Piktogramme) dargestellt und direkt (per Drag \& Drop) gesteuert werden. Direkte Manipulation vermittelt das Gefühl des unmittelbaren Umgangs mit den Objekten.

Damit Direkte Manipulation möglich ist, sind eine grafische Benutzungsoberfläche und ein Zeigerinstrument notwendig.
\subsubsection{Entstehung}
Geforscht und entwickelt wurde diese Form des UI seit den 60er Jahren. Die Firma Xerox entwickelte die Maus in den 70er Jahren in Palo Alto Research Center, sog. Xerox PARC.  Zum ersten Mal kommerziell wurde diese Idee 1981 in Rechner Xerox Star benutzt. Aber der Rechner war ein Misserfolg. 

Die Firma Apple lizenzierte diese Technik und entwickelte 1983 den Rechner Lisa, der allerdings auch keinen Markterfolg hatte. Erst das Nachfolgemodell, der 1984 eingeführte Macintosh (passend zur Firma nach einer Apfelsorte genannt)  war wegen seiner grafischen Benutzeroberfläche erfolgreich.

Das Macintosh Betriebssystem erhielt revolutionäre Konzepte wie die Schreibtisch-Metapher, den Papierkorb und andere Icons, Drag \& Drop, etc.
\slides{06_SE-Usability-Einfuehrung}{68}
\subsubsection{Vorteile und Schwierigkeiten}
Schwierigkeiten bei der direkten Manipulation
\begin{itemize}
\item Viele Symbole (Piktogramme) sind nicht normiert, müssen extra erlernt werden.
\item Sie nehmen Platz auf dem Bildschirm.
\item Hantieren mit der Maus ist langsamer als die Handhabung der Tastatur.
\item Schwierig ist vor allem, wenn nicht nur Objekte (Daten oder Anwendungen) visuell dargestellt werden müssen, sondern auch Prozesse. In diesem Bild wird ein Downloadprozess mit einer Animation visuell dargestellt, das ist nicht so einfach und gelingt nur bedingt.
\end{itemize}
\slides{06_SE-Usability-Einfuehrung}{70}
Vorteile der direkter Manipulation\\
Die Vorteile der direkter Manipulation sind trotz Schwierigkeiten gut erkennbar und erklären ihr Siegeszug:
\begin{itemize}
\item Leichte Erlernbarkeit: visuelle Repräsentationen haben eine enorme unterstützende Wirkung. 
\item Unmittelbares visuelles Feedback
\end{itemize}
Die direkte Manipulation hat sich weiter entwickelt. Zum Beispiel werden heute oft Menüs und direkter Manipulation kombiniert. 
\slides{06_SE-Usability-Einfuehrung}{71}
\subsubsection{Übergang zum Natural User Interface}
Andere Zeigerinstrumente als die Maus haben sich für den PC nicht durchgesetzt.

Erst mit dem Siegeszug der Mulit-Touch-Technologie hat man ein neues Zeigerinstrument gefunden, das der Maus Konkurrenz machen kann: die Finger.

Dadurch hat sich die Direkte Manipulation zur Natural User Interface (NUI) weiter entwickelt.
\slides{06_SE-Usability-Einfuehrung}{72}
\subsection{Natural User Interface}
\slides{06_SE-Usability-Einfuehrung}{74}
\subsubsection{Enstehung der Multi-Touch-Technologie}
Die Forschung zu Multi-Touch-Geräten hat bereits Anfang der 1990er Jahre begonnen.  Im Jahr 2006 wurde der Forscher Jeff Han von der New York University durch eine Demonstration eines Multi-Touch-Prototypen auf der TED -Konferenz (Technology Entertainment Design, Kalifornien) bekannt. Im Mittelpunkt der Demonstration, die in YouTube zu sehen ist, steht nicht die Technologie selbst, sonder neue Bedienungskonzepte, die damit realisiert werden können.
 
Schon 2005 brachte die französische Firma Jazzmutant das Multimedia-Kontrollgerät Lemur zum Steuern von Mischpulten im professionellen Audio- und Videobereich mit Multi-Touch-Technologie auf den Markt.
 
Mit dem Iphone führte die Firma Apple 2007 als erster Unternehmen die Multitouch-Funktionalität in einem Gerät für das breite Publikum ein. 2008 ist die Technologie auch in das Notebook Air von Apple integriert worden und zwar nicht direkt auf dem Bildschirm sondern in Trackpad. 2010 wurde die Technologie in den iPad integriert. Es folgten viele andere Geräte, Smartphones und Tabletts.

\slides{06_SE-Usability-Einfuehrung}{73}
Eine frühere Vision der Multi-Touch-Technologie in einem Science Fiction-Film.
\slides{06_SE-Usability-Einfuehrung}{75}
\slides{06_SE-Usability-Einfuehrung}{76}
\slides{06_SE-Usability-Einfuehrung}{77}
\subsubsection{Bedienung durch Gesten}
\subsubsection*{Maus vs. Finger}
Die klassische Bedienung der Direkten Manipulation ist nur durch eine Geste möglich: „Point and Click“ wie es auch in den „Macintosh Human Interfaces Guidelines“ heisst: zielen und klicken. Dafür wird die Computermaus benutzt. 
 
Berührungssensitive Bildschirme bieten weitergehende Möglichkeiten. Wie so oft, werden aber die Möglichkeiten der neuen Technik nicht sofort erkannt. Viel mehr wurden die berührungssensitive Bildschirme zunächst einmal nach den alten Mustern benutzt: zielen und klicken, der Finger als Mauszeiger.
 
Aber Finger können mehr: Mit der Multitouch-Technologie können Software-Oberflächen (User-Interfaces) an mehren Punkten angefasst und durch verschiedenen Gesten bedient werden.

In der Zwischenzeit hatte sich die Maus allerdings weiter entwickelt. 1985 kam die rechte Taste für Kontextmenüs dazu, 1995 das Rad in der Mitte zum scrollen: Finger können das nicht. Auch die hilfreiche Rollover-Effekte sind mit Touch-Bedienung nicht möglich.

\subsubsection*{Typische Gesten}
Gesten sind Körperbewegungen, die Informationen ohne Sprache übermitteln.
Für die MCI müssen einfache und eindeutige Bewegungen, die durch das Eingabesystem erkannt werden, gefunden werden.

Typische Bewegungen, die sich bereits etabliert haben, sind: 
\begin{itemize}
\item Scrollen: der Finger wird über den Touchscreen gezogen, das Bild scrollt vertikal, horizontal oder aber auch diagonal. 
\item Strecken und Stauchen: Bewegen sich zwei Finger auf dem Bildschirm auseinander wird das Bild gezoomt, um das Bild wieder zu verkleinern, führt man die Finger wieder zusammen.
\item Schnelles Ziehen: schnelles Streichen des Fingers über den Bildschirm bewirkt ein Blättern zwischen Bildern, dazu muss der Finger am Ende der Bewegung den Touchscreen verlassen. 
\end{itemize}
 
Diese Entwicklung steht noch relativ am Anfang. In Zukunft wird sich diese Technologie weiter entwickeln. 
\subsubsection{Tipps für Touchscreen-Anwendungen}
\begin{itemize}
\item Allgemein\\
Der \emph{Mauszeiger sollte ausgeblendet} werden, damit nicht der falsche Eindruck entsteht, die Anwendung wäre auch mit einer Maus zu bedienen.

Man sollte auch \emph{berücksichtigen}, dass der Anwender evtl. noch \emph{ungeübt} mit Touchscreen-Anwendungen ist. Erfahrungen mit der Maus überwiegen, vor allem bei älteren Benutzern.
\item Schaltflächen\\
Buttons bzw. Schaltflächen sollten ausreichend \emph{groß} sein, wenn sie auch mit dem Finger eindeutig getroffen werden sollen.  Auch der \emph{Abstand} zu anderen Buttons muss ausreichend sein.

Die \emph{Position} ist ggf. wichtig, je nach dem wie der Bildschirm aufgestellt wird, besteht die Gefahr, dass der Arm Teile desselben verdeckt. 

Es muss berücksichtigt werden, dass die Schaltfläche nur auf \emph{einer Art} und Weise bedient werden kann. Es gibt keine Rollover-Effekte, keine rechten Maustasten und kein Doppelklick.
\item Hintergrundfarbe\\
Bei dunklen Farben werden die Spuren der Finger auf der Scheibe stark sichtbar, daher sollten \emph{helle Farben} vorgezogen werden.
\end{itemize}
\subsubsection{Weitere Formen}
\slides{06_SE-Usability-Einfuehrung}{80}
Eine Weiterentwicklung des NUI: der ganze Körper als Werkzeug der Mensch-Maschine-Schnittstelle.
\slides{06_SE-Usability-Einfuehrung}{81}
Die HCI mittels Sprache wird sicherlich immer mehr an Bedeutung gewinnen. Die Sprachschnittstelle des iPhone hat große Fortschritte gemacht. 






