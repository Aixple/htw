\section{Grundlagen}
\subsection{Motivation}
\slides{04-mem}{2}
\subsection{Probleme}
\slides{04-mem}{3}
Prüfungsfrage: Welche Arten von Fragmentierung gibt es?
\begin{itemize}
\item intern: Segmentgröße „zu groß“ $\to$ kleinere Segmente belegen trotzdem ganzes Segment
\item extern: Stichwort „defragmentierung“ $\to$ Segmente sind verteilt mit Lücken dazwischen
\end{itemize}

\section{Bitmap}
\slides{04-mem}{4}
\subsection*{Blockungsfaktor}
\slides{04-mem}{5}

\section{Freispeicherliste}
\slides{04-mem}{6}
Nachteil: Verteilungsaufwand (Pflege der Liste, Folgen der Pointer in der Liste usw., Finden von freien Listenelementen)!
\subsection{Implementierung: Blöcke mit integrierten Headern}
\slides{04-mem}{7}
$\to$ Liste wird im Speicher integriert.\\
Nachteil: noch ineffizienterer Zugriff (generiert viel Cache-misses/pagefaults).\\
Vorteil: ist fehlertoleranter (Liste kann nicht überschrieben werden, da sie im Hauptspeicher integriert ist).
\subsection{Suchstrategien}
\slides{04-mem}{8}
First/Next Fit: beste Strategien, dabei First Fit das bessere (Daumenregel: da schneller, die Fragmentierung ist zweitrangig).
\slides{04-mem}{9}
Best Fit: es hat sich gezeigt, dass es sich nicht lohnt.\\
Wort Fit: nur „akademischer Natur“
\subsection{Techniken zur Effizienzsteigerung}
\slides{04-mem}{10}
\slides{04-mem}{11}
\subsection{Getrennte Freispeicherliste (Segregated Fits)}
\slides{04-mem}{12}
\slides{04-mem}{13}
Vereinigung benachbarter freier Segmente kostet wieder Geschwindigkeit!
\subsection{Buddy-Verfahren}
\slides{04-mem}{14}
Teilung passiert rekursiv:\\
Wenn nur ein 1MiB Block frei ist und 78KiB gefordert sind, wird des 1MiB zerstückelt:
\begin{itemize}
\item 2*512KiB (davon eins wieder zerstückelt)
\item 2*256KiB (davon eins wieder zerstückelt)
\item 2*128KiB (davon wird eins ausgeliefert).
\end{itemize}
Resultiert in freien Blöcken:\\
1*512KiB, 1*256KiB, 1*128KiB
\subsubsection*{Beurteilung}
\slides{04-mem}{15}

\section{Virtueller Speicher}
\lecdate{10.05.2017}
\subsection{Motivation}
\slides{04-mem}{16}
\subsection{Seiten vs Kacheln}
\slides{04-mem}{17}
\slides{04-mem}{18}
Kacheln/Seitenrahmen: Segmente im physischen Speicher\\
(virtuelle/logische)Seiten: Segmente im virtuellen Speicher\\
MMU+OS: Memory Management Unit (im Prozessor) + Betriebssystem (Prozessor muss es unterstützen und Betriebssystem muss es nutzen)
\subsection{Gestreute Speicherung}
Umsetzung virtueller in physische Adresse
\slides{04-mem}{19}
Seitentabelle existiert für jeden Prozess.
\subsection{Seitentabelleneintrag/Page Table Entry (PTE)}
\slides{04-mem}{20}
\subsubsection{Größe der Seitentabelle}
\slides{04-mem}{21}
\slides{04-mem}{22}
Zugriffe: Immer eins mehr als die Hierarchiestufe.
\subsubsection{Beispiel: Zweistufige Seitentabelle i386}
\slides{04-mem}{23}
\subsection{Demand Paging}
\slides{04-mem}{24}
\subsection{Seitenfehler/Pagefault}
\slides{04-mem}{25}
\subsection{Einlagerungstrategien}
\slides{04-mem}{26}
\subsection{Seitenaustauschverfahren}
\slides{04-mem}{27}
\subsubsection{Optimales Verfahren, LRU}
\slides{04-mem}{28}
\subsubsection{Not Recently Used (NRU)}
\slides{04-mem}{29}
\slides{04-mem}{30}
\subsubsection{FIFO, Second Chance}
\slides{04-mem}{31}
Second Chance Lazy Evaluation: Im „Uhrzeigersinn“ durch die (Ring-)Liste gehen und alle R-Bits auf 0 setzen wenn 1 war oder Eintrag löschen, falls R-Bit 0.
\subsubsection{NFU, Aging}
\slides{04-mem}{32}
\slides{04-mem}{33}
(Hier würde also 3. rausfliegen)
\subsection{Arbeitsmenge (Working Set)}
(nur geringfügig relevant für Klausur)
\slides{04-mem}{34}
\slides{04-mem}{35}
\slides{04-mem}{36}
\subsubsection{Abhängigkeit der Größe der Arbeitsmenge von Delta}
\slides{04-mem}{37}
\slides{04-mem}{38}
\subsection{Idee für Ersetzungsstrategie}
\slides{04-mem}{39}

\subsection{Beladys Anomalie}
\slides{04-mem}{40}
\slides{04-mem}{41}
\lecdate{17.05.2017}
Bei bestimmten Prozess gibt es bestimmte Anzahl von Seiten. Dabei gibt es eine bestimmte Anzahl von Pagefaults. Die Annahme wäre, dass die Pagefaults bei mehr Seiten sinken würde (anders herum müsste sie weiter steigen). Beladys Annomalie besagt, dass das unter bestimmten Systemkonfigurationen auch anders sein kann (dass also Pagefaults mit mehr verfügbaren Seiten steigt).

\subsection{Weitere Aspekte zur Seitenersetzung}
\slides{04-mem}{42}
\begin{itemize}
\item lokale vs globale Ersetzung: global erleichtert Entscheidung, weil Auswahl der Seiten größer ist. Lokal hat weniger Entscheidungen und verdrängt damit vielleicht eigentlich noch benötigte Seiten. Im globalen können Seiten also besser verteilt werden. Im Ernstfall können aber Prozesse verdrängt werden ($\to$ Thrashing) -- das kann im lokalen nicht passieren. Im lokalen können die benötigten Seiten ggf. schneller gefunden werden.
\item variable vs konstante Größe: variable zwar flexibler, aber höherer Verwaltungsaufwand.
\end{itemize}

\section{Schnittstelle zu UNIX}
\slides{04-mem}{43}
\subsection{Speicherabbild}
\slides{04-mem}{44}
\subsection{Systembruf brk()}
\slides{04-mem}{45}
\subsection{Stackanfordernug alloca()}
\slides{04-mem}{46}
Keine Rückgabefunktion: Stack ist in Rahmen eingeteilt. Wenn die Funktion betreten wird wird ein Rahmen mit der Größe für die lokalen Variablen erstellt. Wird innerhalb dieser Funktion eine weitere Funktion (mit lokalen Variablen) aufgerufen wird, wird ein weiterer Stack-Rahmen erstellt. Sobald eine Funktion beendet ist (bspw. durch return), wird dieser Stack-Rahmen wieder gelöscht.\\
alloca verschiebt einfach den Stackpointer $\to$ keine Rückgabe nötig. Wenn Funktion beendet wird, wird Stackframe inkl. dem mit alloca vergrößerten Bereich gelöscht (daher kein free nötig).\\
(Praktisch wenig relevant)
\subsection{Ausschaltung des Pagings (Pinning)}
\slides{04-mem}{47}
Ausschaltung bei sicherheitskritischen Prozessen: wird beispielsweise in Passwort in die Pagefile geschrieben, wäre er persistent unverschlüsselt gespeichert!
\subsection{Memory-Mapped Files}
\slides{04-mem}{48}
(„speichereingeblendete Dateien“)
\subsubsection*{open/read/write/close}
\begin{itemize}
\item Quell- und Zieldatei eröffnen: 2 mal \lstinline`open()`
\item Speicherbereich „besorgen“: \lstinline`malloc()`
\item Quelldatei einlesen: x mal \lstinline`read()`
\item Zieldatei schreiben: x mal \lstinline`write()`
\item Speicher zurückgeben: \lstinline`free()`
\item 2 mal \lstinline`close()` (in der Regel werden Dateien erst jetzt tatsächlich in die Datei geschrieben)
\end{itemize}
\subsubsection*{mmap}
\begin{itemize}
\item Quell- und Zieldatei eröffnen: 2 mal \lstinline`open()`
\item Quelldatei abbilden: \lstinline`mmap()`
\item Zieldatei auf Länge Quelldatei „aufblasen“: \lstinline`lseek()`, 1 mal \lstinline`write()`
\item Zieldatei abbilden: \lstinline`mmap()`
\item Kopiervorgang: \lstinline`memcpy()`
\item 2 mal \lstinline`close()`
\end{itemize}
$\to$ 1 mal \lstinline`memcpy` deutlich schneller als x mal \lstinline`read/write`!

\section{Zusammenfassung}
\slides{04-mem}{49}