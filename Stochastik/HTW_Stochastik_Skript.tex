\newcommand{\customDir}{../}
% LaTeX master Datei(en) zusammengestellt von Falk-Jonatan Strube zur Nutzung an der Hochschule für Technik und Wirtschaft Dresden: https://github.com/genericFJS/htw
\documentclass{scrreprt}
\gdef\pathtomaster{../_LaTeX_master}
\input{\pathtomaster/htwcd_content.sty}
\input{\pathtomaster/fjs_packages-macros.sty}

\faculty{Fakultät Informatik/Mathematik}
\chair{Lehrstuhl für Stochastik}
\subject{lecture}
\title{Stochastik}
\author{Falk-Jonatan Strube}
\professor{Prof. Dr. Fabian Schwarzenberger}

\setlist[enumerate,1]{label=(\arabic*)}
\renewenvironment{anumerate}{\begin{enumerate}[label=(\alph*)]}{\end{enumerate}} % Alphabetische Aufzählung

\begin{document}
\maketitle
\tableofcontents

\chapter*{Vorbemerkung}
Lernraum: Dienstag 17:00 S327, S329

\chapter*{Stochastik}

\section*{Was ist Stochastik}
Stochastik…
\begin{itemize}
\item … kommt etymologisch aus dem Griechischem; Bedeutung: „Kunst des Vermutens“
\item … beschäftigt sich mit der Beschreibung und dem Untersuchen von zufälligen Ereignissen (z.B. Lotto, Wurf eines Würfels, Lebensdauer einer Glühbirne, …)
\item … beinhaltet die Teilgebiete
\begin{itemize}
\item Wahrscheinlichkeitsrechnung:\\
Zu Grunde liegende Gesetzmäßigkeit des Zufalls bekannt. Frage nach Wahrscheinlichkeiten „interessanter“ Ereignisse

Bsp. Würfel: Jede Seite fällt mit Wahrscheinlichkeit $\frac{1}{6}$. \\
Wie groß ist die Wahrscheinlichkeit, dass unter $10$ Würfen mindestens $4$ mal 6 kommt? 
\item Statistik:\\
Zur Grunde liegende Gesetzmäßigkeit des Zufalls ist unbekannt. Idee: Nutze Stichproben/Daten um diese Gesetzmäßigkeiten zu erkennen.

Bsp.: Gesamtproduktion $100\,000$ Teile, Stichprobe von $100$ Teilen enthält $2$ defekte. \\
Kann davon ausgegangen werden, dass die Fehlerquote von $1\%$ nicht eingehalten wird?
\end{itemize}
\end{itemize}

\chapter{Wahrscheinlichkeitsrechnung}
\section{Zufallsexperimente, Ereignisse und Wahrscheinlichkeiten}
\subsection{Zufallsexperimente und Ereignisse}
Erster wichtiger Begriff:
\cparagraph{Definition}
Ein \emph{Zufallsexperiment} ist ein Vorgang
\begin{itemize}
\item der beliebig oft unter gleichartigen Bedingungen wiederholt werden kann und
\item dessen Ergebnis nicht mit Sicherheit vorhergesagt werden kann
\end{itemize}
$\Omega:=$ Ergebnismenge (oder Ergebnisraum) ist die Menge aller möglichen Ergebnisse

\cparagraph{Bemerkung} Drei wichtige Fälle
\begin{itemize}
\item $\Omega$ endlich, d.h. $\Omega=\{\omega_1,\omega_2,\dots,\omega_n\}$
\item $\Omega$ abzählbar unendlich, d.h. $\Omega=\{\omega_1,\omega_2,\dots\}$ (Ereignisse lassen sich mit den natürlichen Zahlen aufzählen)\footnote{zu natürlichen Zahlen (in dieser VL): $\NN=\{1,2,3,\dots\}, \; \NN_0=\{0,1,2,3,\dots\}$}
\item $\Omega$ überabzählbar unendlich, d.h. $\Omega=\RR$ oder $\Omega [0,1)$
\end{itemize}

\cparagraph{Beispiel} 
\begin{itemize}
\item Würfel: $\Omega=\{1,2,3,4,5,6\}$
\item Anzahl der defekten Glühbirnen in einer Stichprobe von 100 Stück: $\Omega=\{0,1,2,\dots,100\}$
\item Anzahl der Anrufe im Call-Center zwischen 8:00 und 9:00
\begin{enumerate}
\item Möglichkeit 1: $\Omega = \{0,1,2,\dots\}=\NN_0$
\item Möglichkeit 2: $\Omega = \{\omega_1,\omega_2,\dots, \omega_{100}\}$ mit \\
$w_i =\begin{cases}
i \text{ Anrufe, falls }i\leq 99\\
100 \text{ oder mehr Anrufe, falls }i=100
\end{cases}$
\end{enumerate}
\item Downloadzeit einer Datei: $\Omega = (0,\infty)$
\end{itemize}
Wir interessieren uns oft nicht allein für das Eintreten von einem $w\in \Omega$, sondern dafür ob ein $w$ aus einer gewissen Teilmenge aus $\Omega$ eingetreten ist (z.B. sind weniger als $3$ Glühbirnen defekt). Daher:
\cparagraph{Definition} Ein \emph{zufälliges Ereignis} $A$ ist eine Teilmenge des Ergebnisraums $\Omega$. 

Spezielle Ereignisse:
\begin{itemize}
\item $A = \emptyset$ \tab … das unmögliche Ereignis ($\omega\in \emptyset$ tritt nie ein)
\item $A=\Omega$ \tab … das sichere Ereignis ($\omega \in \Omega$ tritt immer ein)
\item $A=\{\omega\}$ \tab … Elementarereignis (für ein $\omega \in \Omega$)
\item $\bar A = \Omega \setminus A$ \tab … Gegenereignis zu $A$
\end{itemize}
Sprechweise: „Das Ereignis $A$ tritt ein“, falls ein $\omega \in A$ beobachtet wird.

\cparagraph{Beispiel} (Würfel)\\
$A=\{\text{„gerade Zahl fällt“}\}$\\
$\Rightarrow A=\{2,4,6\} \subseteq \Omega = \{1,\dots,6\}$\\
Gegenereignis: $\bar A = \{1,3,5\}$

\cparagraph{Bemerkung} Da Ereignisse Teilmengen von $\Omega$ sind, lassen sich alle Rechenoperationen für Mengen anwenden. Seien $A,B \subseteq \Omega$.
\begin{itemize}
\item $A \subseteq B$ … $A$ ist Teilereignis von $B$
\item $A=B$, gleiche Ereignisse
\item Durchschnitt: $A \cap B$, „$A$ und $B$“ (beide Ereignisse treten gleichzeitig ein)
\item Vereinigung: $A \cup B$, „$A$ oder $B$“ (entweder $A$ oder $B$ treten ein)
\item Differenz: $A \setminus B$, „$A$ ohne $B$“ ($A$ tritt ein, $B$ aber nicht)
\item Negation/Gegenereignis: $\bar A = \Omega\setminus A$ ($A$ tritt nicht ein)
\item gilt $A \cap B = \emptyset$, so heißen $A$ und $B$ \emph{unvereinbar/disjunkt}.
\end{itemize}

\cparagraph{Beispiel} (Würfel)\\
$\Omega = \{1,\dots,6\}$,\\
$A=\{2,4,6\},\; B=\{2,3,5\},\; C =\{1,3\}$\\
Bestimme: $A \cup B$, $A \cap B$, $A \cap C$, $C \cup \bar C$\\
$A \cup B = \{2,3,4,5,6\}$\\
$A \cap B = \{2\}$\\
$A \cap C = \emptyset$\\
$C \cup \bar C = \Omega$

\cparagraph{Satz} (Rechenregeln) Es seien $A$, $B$ und $C$ Ereignisse. Dann gilt:
\begin{itemize}
\item $A \cap B = B \cap A \quad A \cup B = B \cup A$ \tab(Kommutativgesetz)
\item $A \cap (B \cap C)=(A \cap B) \cap C$\\
$A \cup (B \cup C) = (A \cup B ) \cup C$ \tab\tab (Assoziativgesetze)
\item $A \cap (B \cup C) = (A \cap B) \cup (A \cap C)$\\
$A \cup(B \cap C) = (A \cup B) \cap (A \cup C)$ \tab (Distributivgesetze)
\item $\overline{A\cap B} = \bar A \cup \bar B$\\
$\overline{A \cup B} = \bar A \cap \bar B$ \tab\tab (De Morgansche Regeln)
\item aus $A \subseteq B$ folgt $\bar B \subseteq \bar A$ und $A\setminus B=A \cap \bar B$
\end{itemize}

\cparagraph{Definition} Sei $\Omega$ eine Menge. Ein Mengensystem $\cA\subseteq \cP(\Omega)$ heißt $\sigma$-Algebra, falls gilt
\begin{itemize}
\item $\Omega \in \cA$
\item $A \in \cA \Rightarrow \bar A \in \cA$
\item $A_1, A_2, A_3, \dots \in \cA \Rightarrow \bigcap_{i=1}^\infty A_i \in \cA$
\end{itemize}
(Sprich: die Menge, alle Komplemente und die Schnitte und Vereinigungen aller Teilmengen müssen in $\cA$ liegen [Mächtigkeit der $\sigma$-Algebra ist bei einer endlichen Grundmenge immer eine 2er-Potenz!])

\cparagraph{Bemerkung} Sei $\cA$ eine $\sigma$-Algebra auf $\Omega$. Dann gilt:
\begin{itemize}
\item $\emptyset \in \cA$
\item $A, B \in \cA \Rightarrow A \setminus B \in \cA$
\item $A_1, A_2,A_3,\dots \in \cA \Rightarrow \bigcup_{i=1}^\infty A_i \in \cA$
\end{itemize}

\cparagraph{Beispiel} (Würfel)
\begin{itemize}
\item $\cA=\{\{1\},\{2\},\emptyset, \{1,2\}, \{3,4,5,6\}, \{2,3,4,5,6\}, \{1,3,4,5,6\}, \underset{=\Omega}{\{1,2,3,4,5,6\} }\}$ ist eine $\sigma$-Algebra über $\Omega=\{1,\dots,6\}$
\item $\cA=\{A \;|\; A \subseteq \Omega\} = \cP(\Omega)$ ist auch ein $\sigma$-Algebra
\end{itemize}

\cparagraph{Bemerkung} Besteht $\Omega$ aus $n$ Elementen, so enthält $\cP(\Omega)$ genau $2^n$ Elemente.

\subsection{Definition der Wahrscheinlichkeit}

Ziel: Ordne zufälligem Ereignis $A$ eine Wahrscheinlichkeit $\PP(A)$ zu, die die Chance beurteilt, dass $A$ eintritt.

\cparagraph{Definition} (Kolmogorov 1933)\\
Gegeben sei eine Ereignismenge $\Omega$ und eine $\sigma$-Algebra $\cA$. Eine Funktion $\PP : \cA \to [0,1]$ heißt \emph{Wahrscheinlichkeitsmaß auf $(\Omega,\cA)$}, falls
\begin{enumerate}
\item $\PP (\Omega) =1$
\item für paarweise disjunkte $A_i \in \cA, \; i=1,2,\dots$ (d.h. $A_i \cap A_J = \emptyset$ falls $i \not = j$) gilt $\PP(A_1 \cup A_2 \cup \dots ) = \PP(A_1)+\PP(A_2)+\dots$.
\end{enumerate}
Weitere Bezeichnungen:
\begin{itemize}
\item $\PP(A)$ … Wahrscheinlichkeit des Ereignisses $A$
\item $(\Omega,\cA, \PP)$ … Wahrscheinlichkeitsraum / Wahrscheinlichkeitsmodell
\end{itemize}

\cparagraph{Bemerkung} (Allgemeines Vorgehen, Vereinfacht Darstellung)
\begin{enumerate}
\item Theoretische Untersuchungen (Kombinatorik, physikalische Gesetze); Beobachtung der relativen Häufigkeit (deskriptive Statistik)
\item Schritt (1) liefert für gewisse Grundereignisse die Wahrscheinlichkeiten (exakt oder zumindest näherungsweise)
\item Bestimmen der Wahrscheinlichkeiten für alle interessierenden Ereignisse (mittels Rechenregeln, siehe später)
\end{enumerate}

\cparagraph{Satz} Seien $A,B,C$ sowie $A_1, A_2, \dots ,A_n$ zufällige Ereignisse. Dann gilt:
\begin{anumerate}
\item $\PP(\emptyset)=0$
\item $\PP(\bar A) = 1 - \PP (A)$
\item $A \subseteq B \Rightarrow \PP(A) \subseteq \PP (B)$
\item $\PP(A \cup B)=\PP(A)+\PP(B)-\PP(A \cap B)$\\
$\PP ( A \cup B \cup C) = \PP(A) + \PP(B) + \PP(C)-\PP(A \cap B) - \PP(A\cap C) - \PP(B\cap C ) + \PP(A \cap B \cap C)$\\
(Gut zu veranschaulichen durch Venn-Diagramme)
\end{anumerate}
Es gilt sogar der Additionssatz:
\cparagraph{Satz} Seien $A_1, \dots, A_n$ zufällige Ereignisse. Dann gilt: \\
$\PP(A_1 \cup \dots \cup A_n)=\sum_{i=1}^n \PP(A_i)-\sum_{i<j} \PP(A_i \cap A_j) + \sum_{i<j<k}\PP(A_i \cap A_j \cap A_k) - \dots + (-1)^{n+1} \PP(A_1\cap A_1 \cap \dots \cap A_n)$

\subsection{Laplacesches Modell}
Nun wollen wir ein spezielles, einfaches, aber oft sehr nützliches WK-Maß einführen.
\cparagraph{Definition} Ein WK-Modell $(\Omega, \cA, \PP)$ heißt \emph{Laplacesches Modell}, falls \\$\Omega = \{\omega_1, \omega_2, \dots , \omega_n\}$ endlich ist, $\cA = \cP ( \Omega)$ und $\PP(\{\omega_1\})=P(\{\omega_2\})=\dots = \PP(\{\omega_n\})=\frac{1}{n}$ gilt.

\cparagraph{Bemerkung} für beliebiges $A \in \cA$ gilt im Laplaceschen Modell:\\
$\PP(A) = \frac{|A|}{|\Omega|}=\frac{m}{n}$, wobei $m=|A|$ die Anzahl der Elemente in $A$ ist (und $|\Omega|=n$).\\
Also $\PP(A)=\frac{\text{Anzahl der günstigen Elementarereignisse}}{\text{Anzahl der möglichen Elementarereignisse}}$.\\
Man sagt auch: $\PP$ ist dann die diskrete Gleichverteilung auf $\Omega$.

\cparagraph{Beispiel}
\begin{anumerate}
\item (fairer Würfel) Wie groß ist die WK eine Zahl größer $4$ zu würfeln?\\
$\Omega = \{1,2,3,4,5,6\}$, $A=\{5,6\}$ und es gilt $\PP(\{1\})=\PP(\{2\})=\dots=\PP(\{6\})=\frac{1}{6}$\\
Daher: $\PP(A) = \frac{|A|}{|\Omega|}=\frac{2}{6}=\frac{1}{3}$
\item (2 faire Würfel) Wie groß ist die WK mit 2 Würfeln mindestens eine 11 zu würfeln?
\begin{align*}
\Omega=\{ & (1,1), (1,2), \dots , (1,6)\\
&\vdots\\
&(6,1), (6,2), \dots , (6,6)\}
\end{align*}
$A=\{(6,5), (5,6), (6,6)\}$ und es gilt $\PP(\{(i,j)\})=\frac{1}{36}$ für beliebiges $i,j \in \{1,\dots,6\}$. Also liegt Laplace Modell vor.\\
Daher gilt: $\PP(A) = \frac{3}{36}= \frac{1}{12}$.
\end{anumerate}
Um in Laplace-Modellen die Größe (Mächtigkeit) von Ereignissen zu bestimmen, sind oft spezielle „Abzähltricks“ sinnvoll. Diese liefert die Kombinatorik.

\subsection{Kombinatorik}
Fragestellung: Wie viele Möglichkeiten gibt es aus einer $n$-elementigen Menge $k$ Elemente auszuwählen? Dabei sind die Spielregeln zu klären:
\begin{itemize}
\item Spielt die Reihenfolge eine Rolle?
\item Dürfen Elemente mehrfach ausgewählt werden (mit Zurücklegen oder ohne)?
\end{itemize}

\cparagraph{Satz} In einer Urne befinden sich $n$ (voneinander unterscheidbare) Elemente. Wir ziehen $k$ davon…
\begin{anumerate}
\item … mit Zurücklegen, unter Berücksichtigung der Reihenfolge, dann gibt es
\[\bar v_n^k = n^k\]
viele Möglichkeiten (Variation von $n$ Elementen zur $k$-ten Klasse mit Wiederholungen).
\item … ohne Zurücklegen, unter Berücksichtigung der Reihenfolge, dann gibt es
\[v_n^k=n\cdot (n-1) \cdot (n-2) \cdot \dots \cdot (n-(k-1))=\frac{n!}{(n-k)!}\]
viele Möglichkeiten (Variation von $n$ Elementen zur $k$-ten Klasse ohne Wiederholungen).
\item … mit Zurücklegen, ohne Berücksichtigung der Reihenfolge, dann gibt es
\[\bar c_n^k=\binom{n+k-1}{k}=\frac{(n+k-1)!}{k!(n-1)!}\]
viele Möglichkeiten (Kombination von $n$ Elementen zur $k$-ten Klasse mit Wiederholungen).
\item … ohne Zurücklegen, ohne Berücksichtigung der Reihenfolge, dann gibt es
\[c_n^k=\binom{n}{k}=\frac{n!}{k!(n-k)!}\]
viele Möglichkeiten (Kombination von $n$ Elementen zur $k$-ten Klasse ohne Wiederholungen).
\end{anumerate}

\cparagraph{Bemerkungen}
\begin{itemize}
\item $n!=n\cdot (n-1) \cdot \dots \cdot 2\cdot 1$ mit $0!=1$
\item Spezialfall in (b): $n=k$, dann $v_n^k=n!$. Dies beschreibt die Anzahl der möglichen Anordnungen von $n$ Elementen (Permutationen).
\item Spezialfälle in (d): 
\begin{itemize}
\item $n=k$, dann $c_n^k=1=\binom{n}{n}$
\item $k=0$, dann $c_n^0=\binom{n}{0}=1$
\item $k=1$, dann $c_n^1=\binom{n}{1}=n$
\end{itemize}
\end{itemize}

\cparagraph{Beispiel}
\begin{anumerate}
\item Wie viele mögliche Zieleinläufe gibt es beim 100m-Lauf mit 8 Teilnehmern?\\
$8!=40320$
\item Wie viele Möglichkeiten gibt es beim Lotto (6 aus 49)\\
$\binom{49}{6}=13\;983\;816$
\item Wie viele Möglichkeiten gibt es ein Nummernschild der Art „DD-Buchstabe Buchstabe Ziffer Ziffer Ziffer“ zu konstruieren?\\
$26^2\cdot 10^3=676 \; 000$
\item Wie viele Möglichkeiten gibt es 5 (nicht unterscheidbare) Äpfel auf 3 Kinder aufzuteilen?\\
$\binom{3+5-1}{5}=\binom{7}{1}=21$
\end{anumerate}

\subsection{Bedingte Wahrscheinlichkeit}
Frage: Wie verändert sich die Wahrscheinlichkeit eines Ereignisses, falls ich Zusatzwissen mit einfließen lasse? 

\cparagraph{Beispiel} HIV Prävalenz liegt weltweit bei $0,8\%$, also:\\
$\PP_1 (\{\text{zufällig ausgewählte Person ist HIV-positiv\}})=0,008$\\
Modell 1: $\Omega =\{0,1\},\; \PP_1 ( \{1\}) = 0,008, \; \PP_1(\{0\})=0,992$\\
Zusatzwissen: ausgewählte Person ist Europäer und Prävalenz in Europa: $=0,2\%$, also:\\
$\PP_2 (\{\text{zufällig ausgewählte Person ist HIV-positiv\}})=0,002$\\
Modell 2: $\Omega = \{0,1\}, \; \PP_2(\{1\})=0,002=1-\PP(\{0\})$\\
Problem/Frage:
\begin{itemize}
\item Wie kombiniert man beide Modelle?
\item Wir wollen nicht mit 2 verschiedenen $\PP$s rechnen.
\item WK für HIV positiv unter Nicht-Europäern?
\end{itemize}

\cparagraph{Beispiel}
\begin{itemize}
\item Von insgesamt $800$ Schülern besitzen $440$ ein Smartphone.
\item Unter den Smartphone-Besitzern sind $60\%$ männlich.
\item Unter den Nicht-Smartphone-Besitzern sind $35\%$ männlich.
\item Unter allen $800$ Schülern wird ein Smartphone verlost.
\end{itemize}
Fragen:
\begin{anumerate}
\item Wie groß ist die Wahrscheinlichkeit, dass der Gewinner bereits ein Smartphone besitzt?
\item Wie groß ist die WK, dass der Gewinner bereits ein Smartphone besitzt, wenn man schon weiß, dass ein Mädchen gewonnen hat?
\end{anumerate}

\cparagraph{Definition} Sei $(\Omega, \cA, \PP)$ ein Wk-Raum und seien $A, B \subset \Omega$ Ereignisse mit $\PP(B)>0$. Dann definieren wir $$\PP(A|B):=\frac{\PP(A \cap B)}{\PP(B)}$$ und nennen $\PP (A|B)$ die Wahrscheinlichkeit von $A$ bedingt auf $B$.\\
Interpretation: „Wie groß ist die Wk,von $A$, wenn ich schon weiß, dass $B$ eingetreten ist?“

\cparagraph{Beispiel} (Smartphone, s.o.)\\
$\Omega = \{ (S,M), (\bar S, M), (S, W), (\bar S, W)\}$\\
$S$ … Gewinnende Person besitzt Smartphone\\
$\bar S$ … Gewinnende Person besitzt kein Smartphone\\
$M$ … Gewinnende Person ist männlich\\
$W$ … Gewinnende Person ist weiblich\\
\begin{tikzpicture}[scale=2]
\node (v1) at (5,1) {$M/W$ / $S/\bar S$};
\node (v2) at (3.5,0) {$S$};
\node (v3) at (6.5,0) {$\bar S$};
\node (v4) at (3,-1) {$M$};
\node (v5) at (4,-1) {$W$};
\node (v6) at (6,-1) {$M$};
\node (v7) at (7,-1) {$W$};
\node at (v4) [below = 1em, align=center]{$0,33$\\$(=0,55\cdot0,6)$};
\node at (v5) [below = 1em]{$0,22$};
\node at (v6) [below = 1em]{$0,1575$};
\node at (v7) [below = 1em]{$0,2925$};
\draw (v1) -- node[left, pos =.5]{$0,55\left(=\frac{440}{800}\right)$} (v2);
\draw (v1) -- node[right, pos =.5]{$0,45$}(v3);
\draw (v2) -- node[left, pos =.5]{$0,6$}(v4);
\draw (v2) -- node[right, pos =.5]{$0,4$}(v5);
\draw (v3) -- node[left, pos =.5]{$0,35$}(v6);
\draw (v3) -- node[right, pos =.5]{$0,65$}(v7);
\end{tikzpicture}
\\
gegeben: \\
$\PP(\{(S,M)\})=0,33$\\
$\PP(\{(S,W)\})=0,22$\\
$\PP(\{ (\bar S, M )\})=0,1575$\\
$\PP(\{ (\bar S, W )\})=0,2925$\\
Antwort auf Fragen:
\begin{anumerate}
\item $0,55$ (klar)
\item Intuition: Wir wissen, dass nur noch die Stränge mit „W“ interessieren. Die Stränge ohne „W“ sollten wir „streichen“. Wie groß ist die WK der Kombination (S,W) im Vergleich zu allen, wo W vorkommt? Also:$$\frac{\PP(\{(S,W)\})}{\PP(\{(S,W),(\bar S,W)\})}=\frac{0,22}{0,22+0,2925}=0,4293$$
Was hat das mit der bedingten WK aus Def. 1.1.25 zu tun? \\
$A:=\{\text{Person besitzt Smartphone}\}=\{(S,M),(S,W)\}$\\
$B:=\{\text{Person ist weiblich}\} = \{(S,W), (\bar S ,W)\}$ \\
$\PP(A|B)=\frac{\PP(\{(S,W)\})}{\PP(\{(S,W), (\bar S, W)\})}=\dots =0,4293$
\end{anumerate}

\cparagraph{Satz} (Rechnen mit bedingten WK)\\
Sei $(\Omega, \cA, \PP)$ ein WK-Raum und $A, A_1, A_2, B \in \cA$ Ereignisse mit $\PP(B)>0$. Dann gilt:
\begin{itemize}
\item $\PP(B|B)=1$, $\PP(\emptyset|B)=0$
\item Falls $A$ und $B$ disjunkt, gilt $\PP(A|B)=0$
\item $\PP(\bar A | B) = 1-\PP(A|B)$
\item $\PP(A_1 \cup A_2 | B ) =\PP(A_1 | B ) + \PP (A_2|B) - \PP (A_1 \cap A_2 | B)$
\item Falls $B\subseteq A$, so gilt $\PP(A|B)=1$
\item Falls $A \subseteq B$, so gilt $\PP(A|B)=\PP(A)$
\end{itemize}

\cparagraph{Beispiel} Auf einer E-Mail Adresse kommen im Schnitt $80\%$ Spam-Mails und $20\%$ gute Mails.\\
Eine „gute“ Mail enthalte mit $2\%$ WK das Wort „Viagra“. In einer Spam-Mail liegt dieser Anteil bei $60\%$. Berechnen Sie die WK, dass eine Spam-Mail vorliegt, falls man weiß, dass das Wort „Viagra“ enthalten ist.\\
Lösung:\\
$A=\{\text{Mail enthält „Viagra“}\}$\\
$\bar A=\{\text{Mail enthält kein „Viagra“}\}$\\
$B=\{\text{Mail ist Spam}\}$\\
$\bar B=\{\text{Mail ist kein Spam}\}$\\
4-Felder-Tafel:\\
\begin{tabular}{l | c | c | l}
& $B$: Spam & $\bar B$ kein Spam & \\
\hline
$A$, mit Viagra & $0,8\cdot 0,6=0,48$ & $0,2 \cdot 0,002=0,004$ & $0,484$\\
$\bar A$, ohne Viagra & $0,32$ & $0,196$ & $0,516$\\
\hline 
& $0,8$ & $0,2$ & $1$
\end{tabular}\\
Gesucht ist $\PP(B|A)=\frac{\PP(B\cup A)}{\PP(A)}=\frac{0,48}{0,484}=0,9917$
Auch interessant ist die WK, dass die Mail kein Spam ist, wenn man schon weiß, dass „Viagra“ nicht enthalten ist. $\PP(\bar B | \bar A)=\frac{0,196}{0,516}=0,3798$

\cparagraph{Satz} (Multiplikationssatz)\\
Seien $A$ und $B$ Ereignisse mit $\PP(A)>0,\; \PP(B)>0$. Dann gilt:
$$\PP(A\cup B ) = \PP(A ) \cdot \PP(B|A) = \PP(B) \cdot \PP(A|B)$$
Sind $A_1,\dots,A_n$ Ereignisse mit $\PP\left( \bigcap_{i=1}^{n-1} A_i\right) >0$, dann gilt sogar:
$$\PP(A_1\cap A_2 \cap \dots \cap A_n)=\PP(A_1)\cdot \PP(A_2|A_1) \cdot \PP (A_3|A_1 \cap A_2)\cdot \dots \cdot \PP(A_n|A_1 \cap \dots \cap A_{n-1})$$

\cparagraph{Beispiel} In einer Los-Trommel befinden sich $20$ Lose. Jemand zieht $3$ nacheinander. Es gibt insgesamt $5$ Gewinnlose. Wie groß ist die WK, dass alle $3$ gezogenen Lose Gewinnlose sind?\\
$A_k=\{\text{Gewinn beim $k$-ten Los}\}, \; k=1,2,3$\\
Gesucht: $\PP(A_1\cap A_2 \cap A_3)$\\
Satz 1.1.29 liefert: \\
$\PP(A_1 \cap A_2 \cap A_3)=\PP(A_1) \cdot \PP(A_2 | A_1) \cdot \PP(A_3 | A_1 \cap A_2)$\\
$\PP(A_1) = \frac{5}{20}= \frac{1}{4}$ (5 Günstige in 20 Losen)\\
$\PP(A_2 | A_1) = \frac{4}{19}$\\
$\PP(A_3 | A_1 \cap A_2) = \frac{3}{18}$\\
$\Rightarrow \PP(A_1 \cap A_2 \cap A_3)=\frac{1}{4}\cdot \frac{4}{19}\cdot \frac{3}{18}=\frac{1}{114}=0,0087$

\cparagraph{Satz} (Formel der totalen WK)\\
Sei $(\Omega, \cA, \PP)$ ein WK-Raum und seien $B_1,\dots,B_n \in \cA$ mit 
\begin{itemize}
\item $\bigcup_{i=1}^n B_i = \Omega$
\item $B_i \cap B_j = \emptyset $ für $i \not= j$
\item $\PP (B_i) >0$ für alle $i=1,\dots,n$
\end{itemize}
Dann gilt:
$$\PP(A) = \sum_{i=1}^n \PP(A|B_i) \cdot \PP (B_i)$$
\begin{center}
\includegraphics[scale=.75]{Vorlesung/ABB2}
\end{center}

\cparagraph{Beispiel} (Prävalenz von HIV)
\begin{itemize}
\item HIV-Prävalenz weltweit: $0,8\%$
\item HIV-Prävalenz in Europa: $0,2\%$
\item es gibt $7$ Mrd. Menschen auf der Erde
\item es gibt $740$ Mio Menschen in Europa
\end{itemize}
Gesucht:
\begin{itemize}
\item WK, dass zufällig ausgewählter Europäer HIV-positiv ist.
\item WK, dass zufällig ausgewählter Nicht-Europäer HIV-positiv ist.
\end{itemize}
Lösung:\\
$E:=\{\text{ausgewählte Person ist Europäer}\}$\\
$P:=\{\text{ausgewählte Person ist HIV positiv}\}$\\
Wir wissen: \\
$\PP(P)=0,008$, $\PP(E)=\frac{74}{700}\approx 0,1057$\\
$\PP(P|E)=0,002$.\\
Wir wollen wissen:
\begin{itemize}
\item $\PP(\bar P | E)=1-\PP(P|E)=1-002=0,998$
\item $\PP(P | \bar E)=\PP(B|\bar E) \cdot \PP(E)+\PP(P|E) \cdot \PP(E)$ (mit $B_1=\bar E$ und $B_2=E$)\\
Umstellen liefert:\\
$\PP(P|\bar E) = \frac{\PP(B)-\PP(P|E)\cdot\PP(E)}{\PP(\bar E)}=\frac{0,008-0,002\cdot 0,1057}{1-0,1057}=0,008709$
\end{itemize}

\cparagraph{Satz} (Formel von Bayes)\\
Sei $(\Omega, \cA, \PP)$ WK-Räume und seien $B_1,\dots,B_n \in \cA$ mit 
\begin{itemize}
\item $\bigcup_{i=1}^n B_i = \Omega$
\item $B_i \cap B_j = \emptyset $ für $i \not= j$
\item $\PP (B_i) >0$ für alle $i=1,\dots,n$
\end{itemize}
Dann gilt für beliebige $A \in \cA$ mit $\PP(A) >0$ und beliebiges $j\in \{1,\dots,n\}$:
$$\PP(B_j|A)=\frac{\PP(A|B_j)\cdot \PP(B_j)}{\PP(A)}=\frac{\PP(A|B_j)\cdot \PP(B_j)}{\sum_{i=1}^n \PP(A|B_i) \cdot \PP(B_i)}$$
Formel von Bayes dreht also die Bedingung um.

\cparagraph{Beispiel} (Ziegenproblem)\\
In einer Spielshow steht der Kandidat vor $3$ verschlossenen Türen. Eine Türe verbirgt den Hauptgewinn, ein Auto. Hinter den beiden anderen Türen sind Ziegen. Der Kandidat zeigt auf eine der Türen, der Spielleiter (der weiß, wo das Auto steht) öffnet gemäß der Spielregeln eine der beiden anderen Türen um eine Ziege zu präsentieren. \\
Der Kandidat darf nun seine Wahl ändern. Sollte er das tun?
\begin{center}
\includegraphics[scale=.75]{Vorlesung/ABB3}
\end{center}
Lösung: \\
Wir legen uns fest, dass der Kandidat Tor 1 gewählt hat und Moderator Tor 3 öffnet(ohne Beschränkung der Allgemeinheit(oBdA): sonst Umnummerieren).\\
Ergebnismenge: $\Omega = \{(i,j)\;|\; i,j=1,2,3\}$ mit $(i,j)$ … Gewinn ist hinter Tor $i$, Moderator öffnet Tor $j$.\\
Definiere die Ereignisse \\
$G_i:= \{ \text{Gewinn hinter Tor }i\}=\{(i,1), (i,2), (i,3)\}$ und\\
$M_j:=\{\text{Moderator öffnet Tor }j\}=\{(1,j), (2,q), (3,q)\}$\\
Wir wissen:\\
$\PP(G_i)=\frac{1}{3}$ für alle $i=1,2,3$\\
$\PP(M_3|G_1)=\tfrac{1}{2}$\\
$\PP(M_3|G_2)=1$\\
$\PP(M_3|G_3)=0$\\
Gesucht: $\PP(G_2|M_3)$
\begin{align*}
\PP(G_2|M_3)&=\frac{\PP(M_3|G_2)\cdot \PP(G_2)}{\PP(M_3|G_1)\cdot \PP(G_1)+\PP(M_3|G_2)\cdot \PP(G_2)+\PP(M_3|G_3)\cdot \PP(G_3)}\\
&=\frac{1\cdot \frac{1}{3}}{\frac{1}{2}\cdot \frac{1}{3}+1\cdot \frac{1}{3}+0\cdot \frac{1}{3}}\\
&=\frac{2}{3}
\end{align*}
Dieses scheinbare Paradoxon ist gut zu veranschaulichen, wenn man sich nicht 3 sondern 100 Tore vorstellt. Wenn man eines der 100 auswählt und der Moderator von den restlichen 99 Toren 98 öffnet, ist offensichtlich, dass die Wahrscheinlichkeit zu gewinne höher ist, wenn man das Tor wechselt. Die gesamte Wahrscheinlichkeiten der geöffneten Tore „sammeln“ sich hinter dem nicht geöffneten, nicht ausgewählten Tor.

\cparagraph{Beispiel} (Zuverlässigkeit diagnostischer Tests)\\
Betrachten eines Test zum diagnostizieren einer Krankheit. Dieser kann entweder „positiv“ oder „negativ“ sein.\\
Gegebene Ereignisse:\\
$P:=\{\text{Test positiv}\}$ … Test tippt darauf, dass Krankheit vorliegt.\\
$\bar P:=\{\text{Test negativ}\}$ … Test tippt darauf, dass Krankheit nicht vorliegt.\\
$K:= \{\text{Person ist krank}\}$\\
$\bar K:= \{\text{Person ist nicht krank}\}$
\begin{itemize}
\item $\text{Sensitivität}:=\PP(P|K)$ (WK, dass Test „positiv“ anzeigt, wenn man tatsächlich auch krank ist. D.h. richtig-positiver Test)
\item $\text{Spezifität}:=\PP(\bar P|\bar K)$ (WK, dass Test „negativ“ anzeigt, wenn man tatsächlich gesund ist. D.h. richtig-negativer Test)
\end{itemize}
\begin{tabular}{r | c c}
& krank & gesund\\
\hline
Test positiv & richtig-positiv & falsch-positiv\\
Test negativ & falsch-negativ & richtig-negativ
\end{tabular}

Problem: Typischerweise sind Sensitivität und Spezifität gegeben, aber eigentlich interessieren uns $\PP(K|P)$ oder $\PP(K|\bar P)$.

\subsection{Unabhängigkeit}
Wir untersuchen die Frage, ob sich Ereignisse gegenseitig beeinflussen.

\cparagraph{Definition} Zwei Ereignisse $A,B \in \cA$ heißen (stochastisch) unabhängig, wenn 
$$\PP(A\cup B)=\PP(A) \cdot \PP(B)\text{.}$$
Die Ereignisse $A_1,\dots, A_n$ heißen paarweise (stochastisch) unabhängig, wenn 
$$\PP(A_i\cup A_j) = \PP(A_i)\cdot \PP(A_j)$$
für alle $i\not=j$.\\
Die Ereignisse $A_1,\dots,A_n$ heißen (stochastisch) unabhängig (in ihrer Gesamtheit), wenn 
$$\PP(A_{i_1}\cap A_{i_2}\cap \dots \cap A_{i_k}=\PP(A_{i_1})\cdot \dots \cdot \PP(A_{i_k})$$
für jede beliebige Auswahl von $k \;(2\leq k \leq n)$ der $n$ Ereignisse.

\cparagraph{Bemerkung}
\begin{enumerate}
\item $A_1, \dots , A_n$ (in ihrer Gesamtheit) unabhängig $\Rightarrow A_1, \dots , A_n$ paarweise unabhängig. Rückrichtung gilt im Allgemeinen nicht (siehe Übung).
\item Ist $\PP(B) >0$ so gilt $A$ und $B$ unabhängig $\Leftrightarrow P(A|B) = \PP(A)$\\
Beweis:
\begin{itemize}
\item[„$\Rightarrow$“]
$\PP(A|B) \overset{\text{Def.}}{=}\frac{\PP(A\cap B)}{\PP(B)}=\frac{\PP(A) \cdot \PP(B)}{\PP(B)}=\PP(A)$
\item[„$\Leftarrow$“]
$\PP(A\cap B) = \frac{\PP(A \cap B)}{\PP(B)}\cdot \PP(B) = \PP(A|B) \cdot \PP(B) = \PP(A) \cdot \PP(B)$
\end{itemize}
$A$ und $B$ unabhängig: Die WK für das Eintreten von $A$ hängt nicht von dem Wissen, ob $B$ bereits eingetreten ist, ab.
\item $A$ und $B$ disjunkt und $\PP(A) > 0, \; \PP(B) >0$.\\
$\Rightarrow A$ und $B$ sind stochastisch \emph{abhängig}.\\
\fbox{Sind $A$ und $B$ disjunkt, so sind sie abhängig!}\\
denn: $\PP(A\cap B) = 0 \not = \PP(A) \cdot \PP(B)$
\item Sind $A$ und $B$ stochastisch unabhängig, so sind:
\begin{itemize}
\item $A$ und $\bar B$ stochastisch unabhängig
\item $\bar A$ und $B$ stochastisch unabhängig
\item $\bar A$ und $\bar B$ stochastisch unabhängig
\end{itemize}
Analog für mehr als zwei Ereignisse.
\item $\emptyset$ und $\Omega$ sind zu jedem $A \in \cA$ unabhängig.
\end{enumerate}

\cparagraph{Beispiel} (Münze und Würfel)\\
Werfen faire Münze (Werte $0/1$) und fairen Würfel (Werte $1,\dots,6$). Untersuche auf Unabhängigkeit:
\begin{enumerate}
\item $A=\{\text{Wer der Münze ist }1\}$, $B=\{\text{Würfel }>4\}$
\item $A=\{\text{Wer der Münze ist }1\}$, $C=\{\text{(Würfel + Münze)} >4 \}$
\item $A=\{\text{Wer der Münze ist }1\}$, $D=\{\text{(Würfel + Münze)}\in\{2,3,4\}\}$
\end{enumerate}
Lösung:\\
$\Omega = \{ (0,1), (0,2), (0,3),\dots , (1,6)\}$
\begin{enumerate}
\item $\PP(A) =\frac{|A|}{|\Omega|}=\frac{6}{12}=\frac{1}{2}$,\quad $\PP(B) = \frac{|B|}{|\Omega|}=\frac{4}{12}=\frac{1}{3}$\\
$\PP(A \cap B)=\frac{|A\cap B|}{|\Omega|}=\frac{2}{12}=\frac{1}{6}$\\
$\Rightarrow \PP(A\cap B) = \frac{1}{6}=\frac{1}{2}\cdot \frac{1}{3}= \PP(A)\cdot \PP(B) \checkmark$\\
$\Rightarrow A$ und $B$ unabhängig.
\item $\PP(C) = \frac{5}{12}$\\
$\PP(A \cap C) = \frac{3}{12} \not = \frac{1}{2}\cdot \frac{5}{12} = \frac{5}{24} = \PP(A) \cdot \PP(C)$\\
$\Rightarrow A$ und $B$ nicht unabhängig, also abhängig.
\item $\PP(D)=\frac{1}{2}$\\
$\PP(A \cap D ) = \frac{1}{4} = \frac{1}{2} \cdot \frac{1}{2} = \PP(A) \cdot \PP(D) \checkmark$\\
$\Rightarrow A$ und $B$ unabhängig.
\end{enumerate}

\cparagraph{Beispiel} Eine Maschine besteht aus $2$ Bauteilen. Bauteil 1 ist mit WK $0,05$ defekt, Bauteil 2 mit WK $0,02$.\\
Wir nehmen, dass sie unabhängig voneinander ausfallen.\\
Frage: Wie groß ist die WK, dass mindestens 1 defekt ist?\\
Lösung: $\Omega = \{(0,0), (0,1), (1,0), (1,1)\}$\\
$A=\{\text{Bauteil 1 defekt}\}=\{(0,1),(0,0)\}$\\
$B=\{\text{Bauteil 2 defekt}\}=\{(0,0), (1,0)\}$\\
$\PP(A) = 0,05$ \quad $\PP(B) = 0,02$\\
Gesucht: $\PP(A \cup B)$\\
1. Variante: $\PP(A \cup B) = 1 - \PP(\overline{A \cup B}) = 1 - \PP(\bar A \cap \bar B) = 1 - \PP(\bar A) \cdot \PP(\bar B) = 1-0,95\cdot 0,98 = 0,069$\\
2. Variante: $\PP(A \cup B) = \PP(A) + \PP(B) - \PP(A \cap B) = 0,05 + 0,02 - 0,05\cdot 0,02 = 0,069$

\cparagraph{Satz} Seien $A_1, \dots, A_n$ unabhängige Ereignisse. Dann gilt:
$$\PP(A_1 \cup A_2 \cup \dots \cup A_n) = 1 - \PP(\bar A_1) \cdot \dots \cdot \PP(\bar A_n)$$
Beweis: 
\begin{align*}
\PP(A_1 \cup \dots \cup A_n) &= 1 - \PP(\overline{A_1 \cup \dots \cup A_n})\\
&= 1 - \PP(\bar A_1 \cup \dots \cup \bar A_n)\\
&= 1- \PP(\bar A_1) \cdot \dots \cdot \PP(\bar A_2)
\end{align*}

\cparagraph{Beispiel} Drei Jäger schießen gleichzeitig und unabhängig voneinander auf Bambi.\\
Jäger 1 trifft mit WK $0,85$, Jäger 2 mit $0,75$ und Jäger 3 mit $0,2$.\\
Mit welcher WK wird Bambi getroffen?\\
Lösung: $A=\{\text{Jäger }i\text{ trifft}\;|\; i =1,2,3\}$\\
Gesucht: WK von $A_1 \cup A_2 \cup A_3$ 
\begin{align*}
\PP(A_1 \cup A_2 \cup A_3) &= 1 - \PP(\bar A_1) \cdot \PP(\bar A_2) \cdot \PP(\bar A_3)\\
&= 1 - 0,15\cdot 0,25 \cdot 0,8\\
&= 0,97
\end{align*}

\cparagraph{Beispiel} Parallel- und Reihenschaltung\\
Ein System besteht aus mehreren Elementen.
\begin{itemize}
\item Die Zuverlässigkeit (WK in einem bestimmten Zeitintervall nicht auszufallen) sei für jedes Element bekannt.
\item Die Elemente heißen \emph{in Reihe geschaltet}, wenn das System genau dann funktioniert, wenn alle Elemente funktionieren.
\item Die Elemente heißen \emph{parallel geschaltet}, wenn das System genau dann funktioniert, wenn wenigstens eins der Elemente funktioniert.
\end{itemize}
$F:=\{\text{System funktioniert in betrachtetem Zeitintervall}\}$\\
$F_i= \{\text{Element } i\text{ funktioniert in betrachtetem Zeitintervall}\}$\\
Wir betrachten eine Sicherungsanlage mit 2 Teilsystemen, die beide funktionieren müssen. Zur Erhöhung der Zuverlässigkeit sind bei Teilsystem 1 ein Element und bei Teilsystem 2 zwei Elemente zu den Hauptelementen als Reserve parallel geschaltet. Die Zuverlässigkeit der Elemente in TS 1 beträgt je $0,9$ und die der Elemente in TS 2 je $0,8$. Die Elemente arbeiten unabhängig voneinander.\\
Teilsystem 1 (mit parallelen Elementen $E_1$[Hauptelement] und $E_3$) liegt in Reihe zu Teilsystem 2 (mit parallelen Elementen $E_2$[Hauptelement], $E_4$ und $E_5$).\\
$F_k:= \{ \text{Element }E_k\text{ funktioniert in betrachtetem Zeitintervall}\}$

Lösung:\\
$F=\underbrace{(F_1 \cup F_3)}_{=:F_{13}} \cap \underbrace{(F_2\cup F_4 \cup F_5)}_{=:F_{245}}$\\
$\PP(F) = \PP(F_{13} \cap F_{245} ) = \PP(F_{13} \cdot \PP(F_{245})$\\
$\PP(F_{13})=1-\PP(\bar F_1) \cdot \PP(\bar F_3) = 1- 0,1^2 = 0,99$\\
$\PP(F_{245})=1-\PP(\bar F_2) \cdot \PP(\bar F_4) \cdot \PP(\bar F_5) = 1-0,2^3=0,992$\\
$\Rightarrow \PP(F) = 0,99\cdot 0,992 = 0,98208$

\section{Zufallsvariablen}

\subsection{Grundlagen}

\cparagraph{Definition} Sei $(\Omega,  \cA, \PP)$ ein WK-Raum. Eine Zufallsvariable (ZV) oder Zufallsgröße ist eine Funktion $X$, die jedem Elementarereignis eine reelle Zahl zuordnet (d.h. $X: \Omega \to \RR$) und die Zusatzeigenschaft
$$\text{für jedes Intervall gilt: }\{\omega \in \Omega \;|\;  X(\omega) \in I\} \in \cA$$
erfüllt.

\cparagraph{Bemerkung} Manchmal benötigt man noch allgemeinere Definitionen von ZVen. Auch wenn $X$ nicht zwingend Werte aus $\RR$ annimmt (und eine ähnliche Bedingung wie in Definition 1.2-1 erfüllt) spricht man von ZVen.\\
Bsp.: $X$ nimmt komplexe Zahlen, Farben, Geschlechter usw an.

\cparagraph{Bemerkung}
\begin{itemize}
\item Oft interessiert man sich für WKen:
$$\PP(\omega \in \Omega \;|\; X(\omega) \in I\})$$
bzw. in Kurzschreibweise:
$$\PP(X\in I) \quad \text{für }I \subseteq \RR$$
\item Die Bedingung aus Definition 1.2-1 stellt sicher, dass solche WKen berechnet werden können.
\item Zur effektiven Beschreibung solcher WKen dient die Verteilungnsfunktion.
\end{itemize}

\cparagraph{Beispiel} Gegeben: (idealer) Würfel mit gefärbten Seiten (ohne Zahlen). \\
Ergebnisraum $\Omega = \{$blau, grün, gelb, rot, schwarz, magenta$\}$\\
Um mit den zufälligen Ergebnissen „rechnen“ zu können, führen wir eine ZV $X: \Omega \to \RR$ ein. Wir setzen $X(\text{blau}):=1$, $X(\text{grün}):=2$, $X(\text{gelb}):=3$, $X(\text{rot})=4$, $X(\text{schwarz}):=5$, $X(\text{magenta}):=6$\\
Es gilt dann z.B.:
$$\PP(X=3) = \PP(\underbrace{\{ \omega \in \Omega \;|\; X(\omega) = 3}_{\{\text{gelb}\}} = \frac{1}{6}$$
$$\PP(X \leq 2) = \PP(\underbrace{\{\omega \in \Omega \;|\; X(\omega) = 1 \vee X(\omega) = 2\}}_{\{\text{blau, grün}\}}=\PP(\{\text{blau}\}) + \PP(\{\text{grün}\}) = \frac{2}{6}=\frac{1}{3}$$

\cparagraph{Beispiel} Alfons (A) und Britta (B) spielen ein Würfelspiel. Gewürfelt wird gleichzeitig. Das Ergebnis von Alfons' Würfel sagt, wie viel Euro Alfons von Britta bekommt. Das Ergebnis von Brittas Würfel sagt, wie viel Euro Britta von Alfons bekommt.\\
Gesucht:
\begin{anumerate}
\item Passendes WK-Modell um die ZV, die den Nettogewinn von Alfons beschreibt.
\item WK, dass Alfons (netto) mehr als $3$\euro{} Verlust hat.
\end{anumerate}
Lösung:
\begin{anumerate}
\item Gesucht: $(\Omega, \cA, \PP)$:\\
$\Omega = \{(i,j) \;|\; i,j \in \{1,\dots,6\}\}=\{1,\dots,6\}^2$ (mit $i=$ Brittas Würfel und $j=$Alfons Würfel)\\
$\cA = \cP (\Omega)$\\
$\PP$ … Gleichverteilung auf $\Omega$ (da Laplace-Experiment)\\
Alfons Gewinn ist für $(1,4)$ gerade $4-1$\euro{}. Also definieren wir $X: \Omega \to \RR$ mittels $X((i,j)):=j-i$.
\item Gesucht ist $\PP(X<-3)$:
\begin{align*}
\PP(X < -3) &= \PP(\{(i,j) \;|\; X((i,j)) < -3\}\\
&= \PP(\underbrace{\{(i,j)\;|\; j-i < -3\}}_{(1,5), (1,6), (2,6)})\\
&= \frac{3}{36}=\frac{1}{12}
\end{align*}
\end{anumerate}

\cparagraph{Beispiel} In einer Firma werden auf 3 verschiedenen Anlagen Sandwiches produziert. Wir modellieren die Anzahl der Sandwiches pro Tag mit $\Omega = \{ \underbrace{(x,y,z)}_{\omega} \;|\; x,y,z \in \NN_0\}$ mit $x,y,z$ jeweils Produktionsmenge Anlage 1, 2 und 3 ($(200,45,120)$ heißt also $300$ Sandwiches wurden in Anlage 1 produziert, $200$ in Anlage 2 und $120$ in Anlage 3).\\
Wir interessieren uns für die Gesamtproduktion. Definiere daher: $X:\Omega \to \RR$ mittels $X((x,y,z)) = x+ y+z$.

Frage: Mit welcher WK überschreitet die Gesamtproduktion eine gewisse Mindestanzahl $m$ nicht?\\
Gesucht ist also $\PP(X\leq m)=\PP(\{\omega \in \Omega \;|\; X(\omega) \leq m\})$.

\cparagraph{Definition} Sei $(\Omega, \cA, \PP)$ ein WK-Raum und $X$ eine ZV. Die Funktion
$$F_X: \RR\to [0,1], \quad F_X(x):=\PP(X \leq x)$$
heißt Verteilungsfunktion (VF) von $X$.\\
$F_X(x)$ ist also die WK, dass $X$ einen Wert kleiner oder gleich der Zahl $x$ annimmt.

\cparagraph{Beispiel} A und B spielen immer noch mit den gleichen Regeln wie in Bsp 1.2-6.\\
Wie sieht $F_X$ aus? Dazu die Wertetabelle:\\
\begin{tabular}{L{0.13}|L{0.13}|L{0.13}|L{0.13}|L{0.13}|L{0.13}|L{0.13}}
$x\in$ & $(-\infty,-5)$ & $[-5,4)$ & $[-4,3)$& $[-3,-2)$ & $[-2,-1)$ & $[-1,0)$\\
\hline
$F_X(x)$ & $0$ & $\tfrac{1}{36}$ & $\tfrac{3}{36}$ & $\tfrac{6}{36}$ & $\tfrac{10}{36}$ & $\tfrac{15}{36}$ 
\end{tabular}\smallskip\\
\begin{tabular}{L{0.13}|L{0.13}|L{0.13}|L{0.13}|L{0.13}|L{0.13}|L{0.13}}
$x\in$ & $[0,1)$ & $[1,2)$ & $[2,3)$ & $[3,4)$ & $[4,5)$ & $[5,\infty)$\\
\hline
$F_X(x)$ & $\tfrac{21}{36}$ & $\tfrac{26}{36}$ & $\tfrac{30}{36}$ & $\tfrac{33}{36}$ & $\tfrac{35}{36}$ & $\tfrac{36}{36}$
\end{tabular}\smallskip\\
Denn z.B. gilt:\\
$F_X(-4) = \PP(X \leq -4) = \PP(\{(5,1),(6,1), (6,2)\}) = \frac{3}{36}$\\
$F_X(3) = \PP(X \leq 3 ) = 1- \PP(X>3) = 1 - \PP(\{(1,5),(1,6),(2,6)\})=1-\frac{3}{36}=\frac{33}{36}$\\
Beachte: In $F_X$ können alle rellen Zahlen eingesetzt werden (Gezeichnete Funktion geht also von $-\infty$ mit $0$ bis $-5$ und macht dann unstetige Sprünge bis $5$, wo es bis $\infty$ mit $1$ weiter geht).

\cparagraph{Lemma} Sei $X$ eine ZV und $F_X$ die zugehörige VF. Dann gilt:
\begin{itemize}
\item $0\leq F_X (x) \leq 1$
\item $x_1 \leq x_2 \Rightarrow F_X(x_1) \leq F_X(x_2)$ \tab(Monotonie)
\item $\lim_{x\to -\infty} F_X(x) =0$, $\lim_{x\to\infty} F_X(x) = 1$
\item $\lim_{x \searrow x_0} F_X(x)=F_X(x_0)$ \tab\tab(rechts-stetig)
\item $\PP(a <X\leq b)=F_X(b)-F_X(a)$
\item $\PP(X>a) = 1 - F_X(a)$
\item $\PP(X=a)=F_X(a)-\lim_{x\nearrow a}F_X(x)$ \tab (Sprunghöhe bei $x=a$)
\end{itemize}

\subsection{Diskrete und stetige Zufallsvariable}
Wir betrachten 2 Klassen von ZVen: diskrete und stetige.

\cparagraph{Definition} Eine ZV heißt \emph{diskrete ZV}, falls $X$ nur endlich viele oder abzählbar viele oder abzählbar unendlich viele Werte annehmen kann ($M$ abzählbar unendlich $\Leftrightarrow$ $\exists$ eine bijektive Abbildung $\varphi: M \to \NN$. Sprich: „man kann alle Elemente durchnummerieren“, bspw. rationale Zahlen usw.).

%\addtocounter{cparagraphC}{1}
%\cparagraph{-} nicht relevant

\cparagraph{Bemerkung} Sei $X$ eine diskrete ZV welche nur die Werte $x_1, x_2 , \dots$ annehmen kann.
\begin{anumerate}
\item Wir nenne die Funktion
$$f: x_i\mapsto f(x_i):=p_i:= \PP(X=x_i)$$
Wahrscheinlichkeitsfunktion.
\item $\sum_i f(x_i)=\sum_i p_i =1$
\item $\PP(a < X \leq b) = \sum_{i:\; a<x_i \leq b} f(x_i)$
\item Darstellung mit Verteilungstabelle:\\
\begin{tabular}{r | c | c | c | c | c}
Werte & $x_1$ & $x_2$ & $x_3$& …\\
\hline
WK $f(x_i)$ & $p_1$ & $p_2$ & $p_3$ & …
\end{tabular}
\item Darstellung als Stabdiagramm:
\begin{center}
\includegraphics[scale=.75]{Vorlesung/ABB4}
\end{center}
\end{anumerate}

\cparagraph{Beispiel} Betrachte unfaire Münze, die mit WK $0,6$ auf Zahl fällt. Dann
\begin{itemize}
\item $\Omega = \{ K, Z\}$
\item $X(K):=0$, $X(Z):=1$
\item $\PP(X=0)=0,4=1-\PP(X=1)$
\end{itemize}
\begin{tabular}{r | c | c}
Wert $x_i$ & 0 & 1\\
\hline 
WK $f(x_i)$ & 0,4 & 0,6
\end{tabular}
\begin{center}
\includegraphics[scale=.75]{Vorlesung/ABB5}
\end{center}

\cparagraph{Beispiel} Betrachten Wurf mit 2 Würfeln: $\Omega=\{(i,j)\;|\; i,j=1,\dots,6\}$. Augensumme soll als ZV dargestellt werden: $X((i,j)):=i+j$ für $i,j=1,\dots,6$\\
Verteilungstabelle:\\
\begin{tabular}{r | c | c| c| c| c| c| c| c| c| c| c}
$x_i$ & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9  & 10 & 11 & 12\\
\hline
$f(x_i)$ & 1/36 & 2/36 & 3/36 & 4/36 & 5/36 & 6/36 & 5/36 & 4/36 & 3/36 & 2/36 & 1/36
\end{tabular}
\begin{anumerate}
\item $\PP(X>9) = \PP(X=10) + \PP(X=11) + \PP(X=12) = \frac{6}{36}$
\item $\PP(6\leq X \leq 8) = \frac{16}{36}$
\item $F_X(3) = \PP(X\leq 3) = \frac{3}{36}$
\end{anumerate}

\cparagraph{Definition} Eine ZV heißt \emph{stetige ZV}, falls ihre Verteilungnsfunktion $F_X$ stetig ist.

In dieser Vorlesung betrachten wir nur stetige ZV, bei denen $F_X$ differenzierbar ist.

\cparagraph{Definition} Sei $X$ eine ZV mit differenzierbarer Verteilungsfunktion $F_X$. Dann wird die Ableitung $f:= F'_X$ \emph{(Wahrscheinlichkeits-)Dichte(funktion)} genannt.

\cparagraph{Bemerkung}
\begin{itemize}
\item Ist $f$ die Dichtefunktion zur VF $F_X$, so gilt
$$F_X(x) = \int_{-a}^x f(t) \intd{t} \qquad \text{(Hauptsatz der Differential und Integralrechnung)}$$
\item Nicht jede stetige Funktion $F$ kann als Integral einer Dichtefunktion geschrieben werden.
\item Bilder:
\begin{center}
\includegraphics[scale=.75]{Vorlesung/ABB6a}
\includegraphics[scale=.75]{Vorlesung/ABB6b}
\end{center}
\begin{align*}
\PP(X\leq 1)&=F_X(1)\\
&=\PP(\{\omega \in \Omega \;|\; X(\omega)\leq 1 \}) \\
&= \{\text{WK, dass $X$ einen Wert $\leq 1$ annimt}\}\\
&=\{\text{Funktionswert von $F_X$ bei $X=1$}\}\\
&=\int\limits_{-\infty}^1 f(t)\intd{t}\\
&=\{\text{Flächeninhalt des markierten Bereichs der Dichtefunktion}\}
\end{align*}
\end{itemize}

\cparagraph{Satz} Sei $X$ eine stetige ZV mit Dichtefunktion $f$. Dann gilt:
\begin{itemize}
\item $f$ ist auf ganz $\RR$ definiert.
\item $f(x)\geq 0 \quad \forall x \in \RR$
\item $\int\limits_{-\infty}^{\infty}f(x)\intd{x}=1$ (Dichtefunktion ist normiert)
\end{itemize}
Umkehrung des Satzes gilt auch:
\cparagraph{Satz} Sei $f$ eine integrierbare reelwertige Funktion. Dann gilt: 
\begin{itemize}
\item $f$ ist auf ganz $\RR$ definiert.
\item $f(x)\geq 0 \quad \forall x \in \RR$
\item $\int\limits_{-\infty}^{\infty}f(x)\intd{x}=1$ 
\end{itemize}
Dann ist $f$ die Dichte einer Zufallsvariablen $X$. Die zugehörige VF $F_X:\RR\to [0,1]$ ist dann
$$F_X(x):=\int\limits_{-\infty}^{\infty} f(t) \intd{t}$$

\cparagraph{Beispiel} Wir kommen zu einer zufälligen Zeit an der Bushaltestelle an. Der Bus fährt alle 10 Minuten. Die ZV $X$ beschreibe die Wartezeit auf den nächsten Bus, d.h. $X$ kann alle Wert zwischen 0 und 10 annehmen wobei jede Wartezeit gleich-wahrscheinlich sein soll.\\
Die zugehörige Dichtefunktion ist daher:
\begin{center}
\includegraphics[scale=.75]{Vorlesung/ABB7}
\end{center}
$f(x):=\begin{cases}
h & 0 < x < 10\\
0 & \text{sonst}
\end{cases}$
\begin{anumerate}
\item Wie ist $h$ zu wählen?\\
Es muss gelten $1\overset{!}{=}\int\limits_{-\infty}^{\infty}f(x)\intd{x}=\int\limits_0^{10}h\intd{x}=\left[ h\cdot x\right]_0^{10}=10\cdot h \Rightarrow h = \frac{1}{10}$
\item Wie sieht $F_X$ aus?
\begin{center}
\includegraphics[scale=.75]{Vorlesung/ABB8}
\end{center}
$F_X(x)=\int\limits_{-\infty}^x f(t) \intd{t}=\begin{cases}
0 & x\leq 0\\
\tfrac{1}{10} x & 0 < x < 10\\
1 & x \geq 10
\end{cases}$\\
Fall $x\leq 0$: $F_X(x)=\int\limits_{-\infty}^x 0 \intd{t} = 0$\\
Fall $0<x<10$: $F_X(x)= \int\limits_{-\infty}^0 0 \intd{t} + \int\limits_0^x \frac{1}{10} \intd{t} = \frac{1}{10}x$\\
Fall $x \geq 10$: $F_X(x) = \underbrace{\int\limits_{-\infty}^0 0 \intd{t}}_{0}+ \underbrace{\int\limits_0^{10} \frac{1}{10} \intd{t}}_1 + \underbrace{\int\limits_{10}^x 0 \intd{t}}_0 = 1$
\end{anumerate}

\cparagraph{Satz} Sei $X$ eine stetige ZV mit Dichte $f$ und VF $F$. Die WK, dass $X$ einen Wert im Intervall $(a,b)$ (oder $[a,b], [a,b), (a,b]$) annimt ist:
\begin{align*}
\PP(a < X<b) &= \PP(\leq X \leq b)
= \PP(a \leq X <b) 
= \PP(a < X \leq b)\\
&=F(b)-F(a) \\
&= \int\limits_a^b f(x) \intd{x}
\end{align*}

Das entspricht den Flächeninhalt unter $f$ zwischen $a$ und $b$.

\cparagraph{Bemerkung}
\begin{itemize}
\item Für $a=b$ zeigt der Satz: Ist $X$ stetig, so gilt 
$$\PP(X=a) = 0$$
für alle $a \in \RR$
\item Im Satz ist auch $a = - \infty$ und/oder $b=+ \infty$ erlaubt, wobei 
$$F(-\infty) := \lim_{x \to -\infty} F(x) = 0$$
$$F(\infty) := \lim_{x \to \infty} F(x) = 1$$
\end{itemize}

\cparagraph{Beispiel} (Fortsetzung von Beispiel 1.2.19)
\begin{itemize}
\item Wie groß ist die WK maximal 3 Minuten zu warten? Gesucht: $\PP(X \leq 3)$\\
$\PP(X \leq 3) = F(3) = 0,1 \cdot 3 = 0,3$
\item Wie groß ist die WK mindestens 2 Minuten zu warten? Gesucht: $\PP(X \geq 2)$\\
$\PP(X \geq 2 ) = \PP(2 \leq X < \infty) = F(\infty)-F(2) = 1-2\cdot 0,1 = 0,8$
\item Wie groß ist die WK zwischen 5 und 9 Minuten zu warten?\\
$\PP( 5 \leq X \leq 9 ) = F(9) - F(5) = 9 \cdot 0,1 - 5 \cdot 0,1 = 0,4$
\end{itemize}

\subsection{Erwartungswert und Varianz}
\cparagraph{Beispiel} (Würfelspiel) A und B würfeln wieder: 2 Würfel. ZV $X$ beschreibt die Augensumme. Spielregeln:\\
\begin{tabular}{c | c | c}
Ergebnis & WK & Bewertung\\
\hline 
$\{X\leq 3\}$ & 1/12 & A zahlt B 20,10\euro{}\\
$\{4 \leq X \leq 6\}$ & 1/3 & A zahlt B 1,20\euro{}\\
$\{X=7\}$ & 1/6 & niemand zahlt etwas\\
$\{8 \leq X \leq 9\}$ & 1/4 & B zahlt A 3,10\euro{}\\
$\{ 10 \leq X \leq 12\}$ & 1/6 & B zahlt A 7,80\euro{}
\end{tabular}

$Y$… Gewinn von A\\
Verteilungstabelle von $Y$:\\
\begin{tabular}{r | c | c | c | c | c}
Werte $y_i$ & -20,1 & -1,2 & 3,1 & 7,8 & 0\\\hline 
WK $p_i$ & 1/12 & 1/3 & 1/4 & 1/6 & 1/6
\end{tabular}

Frage: Ist das Spiel gerecht?\\
Mittlerer Gewinn: $-20,1 \cdot \frac{1}{12} + (-1,2) \cdot \frac{1}{3}+ 0\cdot \frac{1}{6} + 3,1 \cdot \frac{1}{4} + 7,8 \cdot \frac{1}{6} = 0$\\
Dies motiviert die folgende Definition:
\cparagraph{Definition} Sie $X$ eine ZV. Der Erwartungswert $\EE(X)$ und die Varianz $\var(X)$ sind wie folgt definiert:
\begin{anumerate}
\item Falls $X$ diskret ist, mit Verteilungstabelle:\\
\begin{tabular}{r | c c c c}
Werte & $x_1$ & $x_2$ & $x_3$ & …\\\hline
WK & $p_1$ & $p_2$ & $p_3$ & …
\end{tabular}\\
(bzw. mit WK-Funktion $f$), dann 
$$\EE(X) = \sum_i x_i \cdot p_i = \sum_i x_i \cdot f(x_i)$$
und
$$\var(X)=\sum_i (x_i - \EE(X))^2 \cdot p_i = \sum_i (x_i - \EE(X))^2 f(x_i)$$
\item Falls $X$ stetig ist mit Dicht $f$, dann
$$\EE(X) = \int\limits_{-\infty}^{\infty} x\cdot f(x) \intd{x}$$
und 
$$\var (X) = \int\limits_{-\infty}^{\infty} (x-\EE(X))^2 f(x) \intd{x}$$
\end{anumerate}

\cparagraph{Satz} Sei $X$ eine ZV und $a, b \in \RR$. Dann:
\begin{itemize}
\item $\EE(a+bX)=a+b\EE(X)$ \tab (Linearität des Erwartungswertes)
\item $\var(a+bX) = b^2 \var X$
\item $\var(X)=0 \;\Leftrightarrow\; \exists a \in \RR: \PP(X=a) =1$
\end{itemize}

\cparagraph{Bemerkung} 
\begin{itemize}
\item $\sigma_X=\sqrt{\var X}$ wird \emph{Standardabweichung} genannt.
\item $\var (X)$ ist die mittlere quadratische Abweichung vom Erwartungswert und es gilt:
$$\var (X) = \EE(X^2) - (\EE(X))^2$$
\item Sei $g: \RR \to \RR$ eine beliebige Funktion, dann gilt: \\
(im diskreten) \tab\tab $\EE(g(X))=\sum_i g(x_i) \cdot f(x_i)$\bigskip\\
(im stetigen) \tab\tab $\EE(g(X))=\int\limits_{-\infty}^{\infty} g(x) \cdot f(x) \intd{x}$\\
z.B. für $g(x):=x^2$:\\
$\EE(X^2) = \sum_i x_i^2 f(x_i)$ bzw. $\EE(X^2) = \int\limits_{-\infty}^{\infty}x^2 f(x) \intd{x}$
\end{itemize}

\cparagraph{Beispiel} $X$… Zahl der Einsätze eines Havariedienstes an einem Tag. Erfahrung liefert: \\
\begin{tabular}{r | c c c}
$x_i$ & $0$ & $1$ & $2$\\\hline
$p_i=f(x_i)$ & $0,6$ & $0,3$ & $0,1$
\end{tabular}\medskip\\
$\EE(X)=0\cdot 0,6 + 1 \cdot 0,3 + 2 \cdot 0,1 = 0,5$\\
$\EE(X^2) = 0^2 \cdot 0,6  + 1^2 \cdot 0,3 + 2^2 \cdot 0,1 = 0,7$\\
$\var(X)=\EE(X^2) - (\EE(X))^2 = 0,7-0,5^2 = 0,45$\\
$\sigma_X= \sqrt{0,45}=0,671$\bigskip\\
Wir betrachten nun eine ZV $X$ und fragen uns: Welchen Wert $m\in \RR$ muss man wählen, damit $\PP(X\leq m)\geq \frac{1}{2}$ und $\PP(X\geq m) \geq \frac{1}{2}$ gilt?\\
Problem: Antwort nicht eindeutig!
\begin{center}
\includegraphics[scale=.75]{Vorlesung/ABB9}
\end{center}
Hier erfüllt jedes $m\in [1,3)$ diese Bedingung! Welchen dieser Werte wählen wir? Den kleinsten (und nennen ihn \emph{Median})!

\cparagraph{Definition} Ist $F_X$ die Verteilungsfunktion einer ZV $X$, so heißt
$$F_X^{-1}: [0,1]\to \RR, \quad F_X^{-1}(\alpha):= \min\{x\in\RR\;|\; F_X(x) \geq \alpha \}$$
die \emph{verallgemeinerte inverse Verteilungsfunktion}. Der Median $m_X$ der Verteilungsfunktion $F_X$ ist definiert als
$$m_X = F_X^{-1}(0,5)\text{.}$$
Für gegebenes $\alpha \in (0,1)$ heißt
$$q_\alpha = F_X^{-1}(\alpha)$$
das $\alpha$-Quantil zur Verteilung $F_X$.

\cparagraph{Bemerkung} 
\begin{itemize}
\item Daher ist der Median das $0,5$-Quantil der Verteilung: $m_X=q_{0,5}$
\item Im Allgemeinen gilt: Erwartungswert $\not =$ Median.\\
Beispiel:\\
\begin{tabular}{r | l l l l}
$x_1$ & $1$ & $3$ & $6$ & $7$\\\hline
$\PP(X=x_i)$ & $0,2$ & $0,3$ & $0,1$ & $0,4$
\end{tabular}\\
$\EE(X)=4,5$\\
$m_X=\min\{x\in \RR \;|\; F_X(x) \geq 0,5\}= \min[3,\infty) = 3$
\end{itemize}

\subsection{Kovarianz und Unabhängigkeit}

Betrachten nun mehrere ZVen gleichzeitig.\\
Fragen:
\begin{itemize}
\item Haben ZVen „Einfluss aufeinander“?\\
$\rightsquigarrow$ Unabhängigkeit, Unkorreliertheit
\item Kann man das Verhalten mehrerer ZVn gleichzeitig beschreiben?\\
$\rightsquigarrow$ gemeinsame Verteilung
\end{itemize}

\cparagraph{Definition} Sind $X$ und $Y$ ZVen, so heißt 
$$F: \RR^2 \to [0,1], \; F(a,b) = \PP(X \leq a, Y \leq b)$$
gemeinsame Verteilungsfunktion von $X$ und $Y$.
\begin{itemize}
\item Sind beide ZVen diskret, wobei $X$ die Werte $x_1, x_2, \dots$ und $Y$ die Werte $y_1, y_2, \dots$ annehmen kann, dann heißt die Funktion $f$ gegeben durch 
$$f(x_i, y_j):= \PP(X=x_i, Y=y_j)$$
\emph{gemeinsame Verteilungsfunktion}.
\item Sind beide ZVen stetig und existiert eine Funktion $f: \RR^2 \to [0,\infty)$ mit 
$$F(x,y) = \int\limits_{-\infty}^x\int\limits_{-\infty}^x f(s,t) \intd{t} \intd{s}$$
so heißt $f$ \emph{gemeinsame (Wahrscheinlichkeits-)Dichte(-funktion)} von $X$ und $Y$.
\end{itemize}

\cparagraph{Bemerkung} Im diskreten Fall gilt:
$$F_(x,y) = \sum_{i:\; x_i\leq x} \sum_{j:\; y_j \leq y}f(x_i, y_j)$$
\begin{itemize}
\item Die Definition 1.2.30 lässt sich auf beliebig viele ZVen erweitern.
\item ZVen lassen sich zu einem (zufälligen) Vektor zusammenfassen:
\end{itemize}

\cparagraph{Definition} Sind $X_1, \dots, X_n$ ZVen so heißt
$$\mtr{X_1\\X_2\\\vdots\\X_n}$$
\emph{n-dimensionaler Zufallsvektor}.

\cparagraph{Beispiel} (Zufallsvektor mit $n=2$)\\
Seien $X,Y$ diskrete ZVen gegeben durch\\
$X$… Anzahl der technischen Durchsichten eines PKW eines bestimmten Typs zwischen $0$ und $15.000\;\mathrm{km}$.\\
$Y$… Anzahl der Motorpannen dieses PKW zwischen $0$ und $15.000\;\mathrm{km}$.\\
Setzen $Z=\mtr{X\\Y}$
\begin{itemize}
\item Verteilungstabelle:\\
\begin{tabular}{c | c c c c c c c c c c}
$\mtr{X\\Y}$ & $\mtr{0\\0}$ & $\mtr{0\\1}$& $\mtr{0\\2}$& $\mtr{0\\3}$& $\mtr{1\\0}$& $\mtr{1\\1}$& $\mtr{1\\2}$& $\mtr{2\\0}$& $\mtr{2\\1}$\\\hline
$\PP(X=x,Y=y)$ & $0,02$ & $0,04$ & $0,03$ & $0,01$ & $0,05$ & $0,01$ & $0,05$ & $0,53$ & $0,17$
\end{tabular}
\item gemeinsame Wahrscheinlichkeitsfunktion (in Matrixschreibweise):\\
$P=(p_{ij})$ \qquad $p_{ij}:=f(x_i,y_i)=\PP(X=x_i, Y=y_i)$\\
\begin{tabular}{c | c c c c | c}
x$\setminus$y & 0 & 1 & 2 & 3 &\\\hline
0 & 0,02 & 0,04 & 0,04 & 0,01 & 0,1 \\
1 & 0,05 & 0,1 & 0,05 & 0 & 0,2\\
2 & 0,53 & 0,17 & 0 & 0 & 0,7\\\hline
&0,6 & 0,31 & 0,08 & 0,01 & 1
\end{tabular}\\
z.B. $f(0,2)=0,03$
\item gemeinsame Verteilungsfunktion: Es gilt z.B. $F(2,1)=\PP(X\leq 2, Y\leq 1)=0,02+0,04+0,05+0,1+0,53+0,17=0,91$ (entspricht dem „Rechteck“ der WK-Funktion in Matrixschreibweise, wo $x\leq 2$ und $y\leq 1$)
\item Randverteilungen:\\
\begin{tabular}{l | l}
\mpb[.4]
Verteilung von $X$\\
$\PP(X=x_i)=\sum_j p_{i,j}=:p_{i,\cdot}$\\
\begin{tabular}{c | c c c}
$x_i$ & 0 & 1 & 2\\\hline
$p_{i,\cdot}$ & 0,1 & 0,2 & 0,7
\end{tabular}
\mpe &
\mpb[.4]
Verteilung von $Y$\\
$\PP(Y=y_i)=\sum_i p_{i,j}=:p_{\cdot,j}$\\
\begin{tabular}{c | c c c c}
$y_i$ & 0 & 1 & 2 & 3\\\hline
$p_{\cdot,j}$ & 0,6 & 0,31 & 0,08 & 0,01
\end{tabular}
\mpe
\end{tabular}
\end{itemize}

\cparagraph{Bemerkung} Mit der gemeinsamen Verteilung (Dicht, WK-Funktion) lassen sich z.B.
\begin{enumerate}
\item WKen berechnen und
\item Funktionen von ZVen untersuchen.
\end{enumerate}
Seien $X$ und $Y$ ZVen mit gemeinsamer Dichte $f$, dann gilt z.B.:
\begin{enumerate}
\item $\PP(X\in [x_1, x_2], Y\in [y_1, y_2]) = \PP(x_1\leq X \leq x_2, y_i \leq Y \leq y_2)$\\
$\int\limits_{x_1}^{x_2}\int\limits_{y_1}^{y_2} f(s,t) \intd{t}\intd{s}$
\item und für beliebige $g: \RR^2 \to \RR$:\\
$E(g(X,Y)) = \int\limits_\RR\int\limits_\RR g(x,y) f(x,y) \intd{y}\intd{x}$\\
(sofern die Integrale existieren)\\
Insbesondere:\\
$E(X\cdot Y) = \int\limits_{-\infty}^{\infty}\int\limits_{-\infty}^{\infty}x\cdot y f(x,y) \intd{y}\intd{x}$
\end{enumerate}
Analoge Formeln gelten für diskrete ZVen mit der WK-Funktion $f$, z.B. 
$$E(X\cdot Y)=\sum_i \sum_j x_i y_j f(x_i, y_j)$$
falls $X$ die Werte $x_1, x_2, \dots$ annimmt und $Y$ die Werte $y_1, y_2, \dots$.

\cparagraph{Definition} Seien $X$ und $Y$ zwei ZVen. Dann heißen
\begin{anumerate}
\item $\cov(X,Y) = \EE((X-\EE X) ( Y - \EE Y)) = \EE (XY) - \EE X \cdot \EE Y$ die \emph{Kovarianz} von $X$ und $Y$.
\item $\varrho_{X,Y}:=\frac{\cov(X,Y)}{\sqrt{\var(X)}\sqrt{\var(Y)}}$ der \emph{Korrelationskoeffizient}.
\item $X$ und $Y$ \emph{unkorreliert}, wenn $\varrho_{X,Y}=0$ (also wenn $\cov(X,Y) = 0$)
\end{anumerate}

\cparagraph{Definition} Zwei ZVen $X$ und $Y$ heißen (stochastisch) unabhängig, falls für beliebige Intervalle $I_1, I_2 \subseteq \RR$ gilt:
$$\PP(X\in I_1, Y\in I_2)=\PP(X\in I_1) \cdot \PP(Y \in I_2)$$
Mehrere ZVen $X_1, X_2, \dots$ heißen (stochastisch) unabhängig, falls für jede Auswahl $X_{k_1}, \dots , X_{k_m}$ und beliebige Intervalle $I_1, \dots, I_m$ gilt:
$$\PP(X_{k_1}\in I_1 , \dots , X_{k_m}\in I_m)=\prod_{i=1}^m \PP(X_{k_i}\in I_i)$$

\cparagraph{Bemerkung}
\begin{itemize}
\item $X$ und $Y$ stochastisch unabhängig $\Leftrightarrow$ für beliebige Intervalle $I_1$ und $I_2$ sind $\{x\in I_1\}$ und $\{ Y \in I_2\}$ stochastisch unabhängig.
\item $X$ und $Y$ unabhängig $\Rightarrow \EE(XY)=\EE X \cdot \EE Y$
\item $X$ und $Y$ unabhängig $\Rightarrow X$ und $Y$ unkorreliert
\item ABER: $X$ und $Y$ unkorreliert $\not\Rightarrow X$ und $Y$ unabhängig
\item $\cov(X,X) = \var(X)$
\end{itemize}

\cparagraph{Beispiel} (Tetraeder-Würfel)\\
Ein Tetraeder ist mit den Zahlenpaaren $\Omega=\{(1,2),(0,2),(2,1),(0,0)\}$ beschriftet. Jede Seite ist gleich-wahrscheinlich. Die ZV $X$ beschreibt die erste Zahl, $Y$ die Zweite (im Zahlenpaar).\\
Dann:\\
$\PP(X=0)=\tfrac{1}{2}$, $\PP(X=1)=\tfrac{1}{4}$, $\PP(X=2) = \tfrac{1}{4}$,\\ $\PP(Y=0) = \tfrac{1}{4}$,
$\PP(Y=1) = \tfrac{1}{4}$, $\PP(Y=2) = \tfrac{1}{2}$, \\$\PP(X\cdot Y=0) = \tfrac{1}{2}$, $\PP(X\cdot Y = 2) = \tfrac{1}{2}$\\
Und damit:\\
$\EE(X)=0\cdot \frac{1}{2}+1 \cdot \frac{1}{4}+2\cdot \frac{1}{4}=\frac{3}{4}$\\
$\EE(Y)=\frac{5}{4}$\\
$\EE(XY)=1$\\
$\cov(X,Y)=\EE(XY)-\EE(X)\cdot \EE(Y)=1-\frac{3}{4}\cdot\frac{5}{4}=\frac{1}{16}$\\
$\Rightarrow X$und $Y$ nicht unkorreliert\\
$\Rightarrow$ nicht unabhängig\\
z.B. $\underbrace{\PP(X=1)}_{\tfrac{1}{4}}\cdot \underbrace{\PP(Y=0)}_{\tfrac{1}{4}} \not = \underbrace{\PP(X=1,Y=0)}_{0}$
\cparagraph{Satz} Seien $X$ und $Y$ ZVen und $a,b\in \RR$. Dann gilt:
\begin{itemize}
\item $\EE(aX+bY)=a\EE(X)+b\EE(Y)$
\item $\var(X\pm Y) = \var(X)+\var(Y)\pm \cov(X,Y)$
\item $\cov(aX+bY,Z)=a\cov(X,Z)+b\cov(Y,Z)$
\item $\cov(X,Y)=\cov(Y,X)$
\end{itemize}

\cparagraph{Bemerkung} (zu $\varrho_{X,Y}$)
\begin{itemize}
\item $\varrho_{X,Y} \in [-1,1]$
\item $\varrho_{X,Y}$ ist ein Maß für den linearen Zusammenhang zwischen $X$ und $Y$
\item Extremfälle:\\
$\varrho_{X,Y}=\begin{cases}
+1\\
-1
\end{cases} \Leftrightarrow Y=aX+b$ mit $\begin{cases}
a > 0\\
a < 0
\end{cases}$\\
Hier gilt also jeweils ein streng linearer Zusammenhang.
\item Die Gerade $y=a_0+a_1 x$ mit $a_1 = \frac{\sigma_X}{\sigma_Y}\varrho_{X,Y}$, $a_0=\EE Y - a_1 \EE  X$ heißt Regressionsgerade $Y$ bezüglich $X$ (beste lineare Näherung).
\end{itemize} 

\section{Spezielle Verteilungen}
\subsection{Spezielle diskrete Verteilungen}
\subsubsection{Bernoulli Verteilung}
Die Vorstellung einer (un-)fairen Münze liefert eine sehr einfache Zufallsvariable:
\cparagraph{Definition} Eine ZV $X$ welche genau 2 Werte annehmen kann heißt Bernoulli-verteilt.
\cparagraph{Bemerkung}
\begin{itemize}
\item Die möglichen Werte von $X$ werden typischerweise $\{0,1\}$ genannt.
\item Schreibweise: $\PP(X=1)=p, \; \PP(X=0)=1-p=q$ und $X \sim \mathrm{Ber}(p)$
\item Erwartungswert: $\EE(X)=0\cdot q + 1 \cdot p = p$
\item Varianz: $\var (X) = \EE(X^2) - (\EE(X))^2 = 0^2 \cdot q + 1^2 \cdot p - p^2 = pq$
\item Standardabweichung: $\sigma_X=\sqrt{pq}$
\end{itemize}
\begin{center}
\includegraphics[trim={6.2cm 12cm 5.2cm 10.5cm},clip,page=1, scale=.7]{Vorlesung/Skript/01_diskrete_verteilungen.pdf}
\includegraphics[trim={6.2cm 3.3cm 5.2cm 19.2cm},clip,page=1, scale=.7]{Vorlesung/Skript/01_diskrete_verteilungen.pdf}
\end{center}
\cparagraph{Beispiel} Seien $X,Y \sim \mathrm{Ber}(p)$. Setze $Z_1:= X+Y$, $Z_2=X-Y$ unabhängig.
\begin{anumerate}
\item Wie sind $Z_1$ und $Z_2$ verteilt?
\item Sind $Z_1$ und $Z_2$ unkorreliert?
\item Sind $Z_1$ und $Z_2$ unabhängig?
\end{anumerate}
Lösung:
\begin{anumerate}
\item Mögliche Werte:\\
\begin{tabular}{c c | c c | l}
$X$ & $Y$ & $Z_1$ & $Z_2$ & mit WK\\\hline
0 & 0 & 0 & 0 & $\PP(X=0,Y=0)=\PP(X=0\cdot \PP(Y0=) = q^2$\\
0 & 1 & 1 & -1 & $qp$\\
1 & 0 & 1 & 1 & $pq$\\
1 & 1 & 2 & 0 & $p^2$
\end{tabular}\\
$\Rightarrow$ \begin{tabular}{r | c c c}
$z$ & 0 & 1 & 2\\\hline
$\PP(Z_1=z)$ & $q^2$ & $2pq$ & $p^2$
\end{tabular} \quad \begin{tabular}{r | c c c}
$z$ & -1 & 0 & 1\\\hline
$\PP(Z_2=z)$ & $pq$ & $p^2+q^2$ & $pq$
\end{tabular}\\
\begin{tabular}{l | c c c }
$z$ & -1 &  0 & 1\\\hline
$\PP(Z_1Z_2=z)$ & $pq$ & $p^2+q^2$ & $pq$
\end{tabular}
\item $\cov (Z_1,Z_2)=\EE(Z_1Z_2)-\EE(Z_1) \EE(Z_2) = 0$, denn: \\
$\EE(Z_1)=0\cdot q^2 + 1 \cdot 2 pq + 2 p^2 = 2p(q+p) = 2p$\\
$\EE(Z_2)=-pq+pq = 0 =\EE(Z_1Z_2)$\\
$\Rightarrow Z_1$ und $Z_2$ sind unkorreliert
\item Es müsste bspw. gelten $\underbrace{\PP(Z_1=0, Z_2=1)}_{0}=\underbrace{\PP(Z_1=0)}_{q^2} \underbrace{\PP(Z_2=1)}_{pq}$, ist aber falsch.\\
$\Rightarrow Z_1$ und $Z_2$ nicht unabhängig.
\end{anumerate}
\subsubsection{Binomialverteilung}
\cparagraph{Definition} Die ZV $X$ heißt binomialverteilt mit den Parametern $n$ und $p$ (wobei $n \in \NN, p\in [0,1]$), wenn sie die Werte $0,\dots, n$ mit den WKen
$$p_i=\PP(X=i)=\binom{n}{i}p^i (1-p)^{n-i}, \quad i=0,\dots ,n$$
annimmt.
\cparagraph{Bemerkung} 
\begin{itemize}
\item Kurschreibweise: $X \sim \mathrm{Bin}(n,p)$
\item Erwartungswert: $\EE(X)=np$
\item Varianz: $\var (X) = np (1-p)$
\end{itemize}
\begin{center}
\includegraphics[trim={6.2cm 11.9cm 5.2cm 10.7cm},clip,page=2, scale=.7]{Vorlesung/Skript/01_diskrete_verteilungen.pdf}
\includegraphics[trim={6.2cm 3.2cm 5.2cm 19.3cm},clip,page=2, scale=.7]{Vorlesung/Skript/01_diskrete_verteilungen.pdf}
\end{center}
\cparagraph{Satz} Sind $X_1, \dots , X_n$ unabhängige Bernoulliverteilte ZVen (alle mit Parameter $p$), dann 
$$X_1+X_2+\dots + X_n \sim \mathrm{Bin}(n,p)$$

\cparagraph{Beispiel} (Massenproduktion mit Ausschuss)\\
Ein Massenprodukt (Schokoriegel) mit einem Ausschussanteil von $3\%$ wird in 20er Packungen verkauft. Wie groß ist die WK, dass eine Packung maximal 2 Ausschussstücke enthält?\\
Lösung:\\
$X_i$ … ZV mit:\\
$X_i=1 $ … Schokoriegel $i$ in der Packung ist Ausschuss,\\
$X_i = 0 $ … Schokoriegel $i$ ist keine Ausschuss.\\
$Y=\sum_{i=1}^{20}X_i$\\
Wir wissen $X_i \sim \mathrm{Ber}(0,03)$\\
Annahme $X_i$ sind unabhängig.\\
$\overset{\text{Satz 1.3.6}}{\Longrightarrow} Y \sim \mathrm{Bin}(20,\; 0,03)$\\
Gesucht: $\PP(Y \leq 2)$
\begin{align*}
\PP(\leq 2)&= \PP(Y=0)+\PP(Y=1) + \PP(Y=2)\\
&= \binom{20}{0}\cdot 0,03^0 \cdot 0,97^0 + \binom{20}{1} 0,03^1 \cdot 0,97^{19} + \binom{20}{2} 0,03^2 \cdot 0,97^{18}\\
&= 0,979
\end{align*}

\subsubsection{Diskrete Gleichverteilung}

\cparagraph{Definition} Eine ZV $X$ genügt der diskreten Gleichverteilung auf der Menge $T=\{x_1,\dots,x_n\}$, falls sie nur Werte aus $T$ annehmen kann und 
$$\PP(X=x_1) = \dots = \PP(X=x_n) = \frac{1}{n}$$
gilt.

\cparagraph{Bemerkung}
\begin{itemize}
\item Kurzschreibweise: $X\sim U(T)$
\item Erwartungswert: $\EE(X)=\frac{1}{n}\sum_{i=1}^n x_i$
\item Varianz: $\var(X)=\EE(X^2)-(\EE(X))^2 = \frac{1}{n} \sum_{i=1}^n x_i^2+\left(\frac{1}{n}\sum_{i=1}^n x_i\right)^2$
\item Beispiel: faire Münze, fairer Würfel, …
\end{itemize}
\begin{center}
\includegraphics[trim={6.2cm 11.4cm 5.2cm 11.2cm},clip,page=3, scale=.7]{Vorlesung/Skript/01_diskrete_verteilungen.pdf}
\includegraphics[trim={6.2cm 3cm 5.2cm 19.5cm},clip,page=3, scale=.7]{Vorlesung/Skript/01_diskrete_verteilungen.pdf}
\end{center}

\cparagraph{Bemerkung} (Beziehung zum Laplace-Experiment)
\begin{itemize}
\item Wir betrachten ein Laplace-Experiment mit 
$$\Omega = \{\omega_1, \dots, \omega_n\}$$ 
und dem WK-Maß $\PP$, d.h. 
$$\PP(\{\omega_1\})=\dots= \PP(\{\omega_n\})=\frac{1}{n}$$
\item Die ZV $X:\Omega \to \RR, \; X(\omega) = \omega$ ist damit gleichverteilt. Denn: 
$$\PP(X=\omega_i)=\PP(\{\omega\in \Omega | X(\omega) = \omega_i\})=\PP(\omega_i)=\frac{1}{n}$$
\end{itemize}

\subsubsection{Hypergeometrische Verteilung}
\cparagraph{Definition} Eine ZV $X$ heißt Hypergeometrisch verteilt, mit ganzzahligen Parametern $N$, $M$ und $n$ ($0<M\leq N, 0 < n \leq N$), wenn sie nur die Werte $T=\{\max\{0,n+M-N\}, \dots, \min\{n,M\}\}$ annehmen kann und für jedes $m \in T$ gilt:
$$p_m:=\PP(X=m)=\frac{\binom{M}{n}\binom{N-M}{n-m}}{\binom{N}{n}}$$

\cparagraph{Bemerkung}
\begin{itemize}
\item Kurzschreibweise: $X\sim \mathrm{Hyp}(N,M,n)$
\item Erwartungswert und Varianz: $\EE(X)=n\frac{M}{N}$ und $\var (X)=n\frac{M}{N}\left(1-\frac{M}{N}\right) \frac{N-n}{N-1}$
\item Anwendung: Stichprobe ohne Zurücklegen (bspw. Qualitätskontrolle, Lotto)
\begin{itemize}
\item $N$ Objekte, davon $M$ mit bestimmten Merkmal (bspw. Ausschuss, Gewinnzahl)
\item $n$ Objekte werden entnommen
\item $X$ … Anzahl der Objekte unter den $n$ entnommenen, die das Merkmal besitzen
$$\Rightarrow X\sim \mathrm{Hyp}(N,M,n)$$
\end{itemize}
\end{itemize}
\begin{center}
\includegraphics[trim={6.2cm 10.2cm 5.2cm 13.3cm},clip,page=4, scale=.7]{Vorlesung/Skript/01_diskrete_verteilungen.pdf}
\includegraphics[trim={6.2cm 2.8cm 5.2cm 20.7cm},clip,page=4, scale=.7]{Vorlesung/Skript/01_diskrete_verteilungen.pdf}
\end{center}

\cparagraph{Beispiel} In einer Lostrommel befinden sich $20$ Lose, davon $5$ Gewinnlose. Jemand zieht $3$ Lose (ohne Zurücklegen). Wie groß ist die WK, dass sich darunter genau 2 Gewinnlose befinden?\\
Lösung:\\
$X$ … Anzahl der Gewinnlose unter den $3$ gezogenen.\\
Es gilt $X \sim \mathrm{Hy}(20,5,3)$. Daher 
$\PP(X=2)=\frac{\binom{5}{2}\binom{15}{1}}{\binom{20}{3}}=\frac{10 \cdot 15}{1140}=0,1316$

\cparagraph{Bemerkung} Wie kommt man darauf gerade diese Formel zu verwenden?\\
Idee: Modellierung als Laplace-Experiment.\\
$\Omega=\{\{a_1,a_2,a_3\}\;|\; a_i \not = a_j \text{ fals } i \not = j \text{ und }a_1, a_2, a_3 \in \{\underbrace{g_1, \dots, g_5}_{\text{Gewinnlose}}, \underbrace{n_1, \dots, n_{15}}_{\text{Nieten}}\}\}$ $\rightsquigarrow $ Elementarereignisse gleich-wahrscheinlich. Es gilt: $|\Omega|=\binom{20}{3}$.\\
Das Ereignis, das uns interessiert ist: \\
$A=\{\{a_1, a_2, a_3\}\in \Omega \;|\; \{a_1, a_2, a_3\} \text{ enthält genau 2 der }\{g_1, \dots,g_5\}\text{ und genau 1 der }\{n_1,\dots,n_{15}\}\}$\\
Es gilt nun $A=\{X=2\}$ und $|A| = \binom{5}{2}\cdot \binom{15}{1} \Rightarrow \PP(X=2) = \frac{\binom{5}{2}\binom{15}{1}}{\binom{20}{3}}$

\subsubsection{Geometrische Verteilung}
\cparagraph{Definition} Eine ZV $X$ heißt geometrisch verteilt mit dem Parameter $p\in (0,1)$, falls sie nur die Werte $1,2,\dots$ annehmen kann und 
$$p_m:=\PP(X=m)=p(1-p)^{m-1} \quad m=1,2,\dots$$
gilt.
\cparagraph{Bemerkung}
\begin{itemize}
\item Kurzschreibweise: $X\sim \mathrm{Geo}(p)$
\item Varianz: $\var(X)=\frac{1-p}{p^2}$
\item Anwendung: Anzahl der Versuche bis der erste Erfolg eintritt, bei hintereinander ausführen von unabhängigen identischen Bernoulli Zufallsexperimenten.
\end{itemize}
\begin{center}
\includegraphics[trim={6.2cm 11.3cm 5.2cm 11.3cm},clip,page=5, scale=.7]{Vorlesung/Skript/01_diskrete_verteilungen.pdf}
\includegraphics[trim={6.2cm 2.8cm 5.2cm 19.7cm},clip,page=5, scale=.7]{Vorlesung/Skript/01_diskrete_verteilungen.pdf}
\end{center}

\cparagraph{Beispiel} Der Postbote hat ein Paket für Petra bei ihrem Nachbarn abgegeben. Petra klopft jeden Nachmittag an seine Tür. Leider ist er nur mit WK $0,3$ zu Hause. Annahme: Anwesenheiten des Nachbarn an verschiedenen Tagen sind unabhängig voneinander. 
\begin{anumerate}
\item Wie groß ist die WK, dass Petra ihr Paket erst beim 5. Klingeln bekommt?
\item Wie groß ist die WK, dass Petra ihr Paket spätestens beim 5. Klingeln bekommt?
\item Wie viele Tage muss sie im Mittel warten, bis sie ihren Nachbarn antrifft?
\end{anumerate} 
Lösung:\\
$Y$ sei die ZV, die beschreibt, ob Petra ihren Nachbarn am $i$-ten Tag antrifft:\\
$\{Y_i=1\}$ … sie trifft ihn am $i$-ten Tag an\\
$\{Y_i=0\}$ … sie trifft ihn am $i$-ten Tag nicht an\\
laut Voraussetzung: $Y_i \quad i=1,2, \dots$ sind unabhängig und $\PP(Y_i=1) = 0,3 = 1-\PP(Y_i=0)$\\
Wir führen also unabhängige, identische Bernoulli-Zufallsexperimente aus und fragen uns nach dem ersten Erfolg.

\begin{anumerate}
\item gesucht: \begin{align*}
\PP(Y_1=0, \ldots, Y_4=0, Y_5=1) &= \PP(Y_1=0) \cdot \ldots \cdot \PP(Y_4=0) \cdot \PP(Y_5=1) \\
&= 0,7 ^4 \cdot 0,3 \\
&= 0,07203
\end{align*}
Setzen wir $X$ … Tag an dem der erste „Erfolg“ eintritt, so gilt $\PP(X=5)=0,7^4\cdot 0,3$\\
Allgemein gilt $P(X=m)=0,7^{m-1}\cdot 0,3 \Rightarrow X$ ist geometrisch verteilt mit Parameter $p=0,3$.
\item Gesucht:
\begin{align*}
\PP(X\leq 5)&=\PP(\{X=1\}\cup \{X=2\} \cup \{X=3\} \cup \{X=4\} \cup \{X=5\}) \\
&= \PP(X=1) + \ldots + \PP(X=5) \\
&= 0,7^0\cdot 0.3 + 0,7^1 \cdot 0.1 + \ldots + 0,7^4 \cdot 0,3 \\
&= (0,7^0+\ldots+0,7^4)\cdot 0,3 ) \\
&= 0,8919
\end{align*}
Diese Rechnung funktioniert für beliebiges $m$. Daher gilt: 
$$F_X(m)=\PP(X\leq m) = 0,3 \sum_{i=0}^{m-1}0,7^i=0,3 \frac{1-0,7^m}{1-0,7}=1-0,7^m$$
\item Gesucht: $\EE(X)=\frac{1}{0,3}=\frac{10}{3}$\\
$\Rightarrow$ erwartete Wartezeit ist $3,\bar{3}$ Tage.
\end{anumerate}

\cparagraph{Bemerkung} Für eine geometrisch verteilte ZV $X$ mit Parameter $p$ gilt 
$$F_X(m)=\PP(X\leq m) = 1-(1-p)^m$$
für $n \in \NN_0$. Dazwischen ist $F_X$ konstant.

\subsubsection{Poisson-Verteilung}
\cparagraph{Definition} Eine ZV $X$ heißt Poisson-verteilt mit dem Parameter $\lambda >0$, falls sie nur die Werte $0,1,2,\dots$ annehmen kann und 
$$p_m:=\PP(X=m)=\frac{\lambda^m}{m!}e^{-\lambda} \quad m=0,1,2,\dots$$
\cparagraph{Bemerkung} 
\begin{itemize}
\item Kurzschreibweise: $X\sim \mathrm{Poi}(\lambda)$
\item Erwartungswert: $\EE(X)=\lambda$
\item Varianz: $\var(X)=\lambda$
\item Anwendung: Bedientheorie, Zuverlässigkeitstheorie
\begin{itemize}
\item Anzahl der Kunden pro Zeiteinheit
\item Anzahl der Störungen im Produktionsprozess eines Betriebs pro Zeiteinheit
\end{itemize}
\end{itemize}

\cparagraph{Beispiel} In einer Fließbandanlage tritt im Durchschnitt alle $5$ Stunden eine Störung auf (d.h. im Mittel $0,2$ Störungen pro Stunde). Die Zahl der Störungen in einer bestimmten Zeiteinheit kann als Poissonverteilt angenommen werden.\\
Wie groß ist die WK, dass in einer 8-Stunden-Schicht mehr also 2 Störungen auftreten?\\
Lösung:\\
$X$… Anzahl der Störungen in 8 Stunden
\begin{itemize}
\item $X\sim \mathrm{Poi}(\lambda)$ mit $\EE X = 8 \cdot 0,2 = 1,6 = \lambda$
\begin{align*}
\Rightarrow \PP(X >2) &= 1- \PP(X\leq 2) \\
&= 1- \PP(X=0) - \PP(X=1) - \PP(X=2)\\
&= 1-e^{-1,6}\left(\frac{1,6^0}{0!}+\frac{1,6^1}{1!}+\frac{1,6^2}{2!}\right)\\
&= 0,2166
\end{align*}
\end{itemize}

\begin{center}
\includegraphics[trim={6.2cm 11.2cm 5.2cm 11.2cm},clip,page=6, scale=.7]{Vorlesung/Skript/01_diskrete_verteilungen.pdf}
\includegraphics[trim={6.2cm 2.8cm 5.2cm 19.7cm},clip,page=6, scale=.7]{Vorlesung/Skript/01_diskrete_verteilungen.pdf}
\end{center}

\subsection{Spezielle stetige Verteilungen}

\begin{enumerate}[label=(D\arabic*)]
\item stetige Gleichverteilung (Bus-Beispiel)
\item Normalverteilung (Zentraler Grenzwertsatz $\to$ wichtig!)
\item Exponentialverteilung
\item $\chi^2$-Verteilung (Chi-Quadradt-Verteilung)
\item $t$-Verteilung
\item $F$-Verteilung
\end{enumerate}
S4-S5 vor allem für Statistik relevant
\subsubsection{Stetige Gleichverteilung}
\cparagraph{Definition} Eine ZV $X$ heißt stetig gleichverteilt auf dem Intervall $I\subset \RR$, falls für alle Intervalle $J \subset I$ gilt:
$$\PP(X\in J)=\frac{|J|}{|I|}$$
\cparagraph{Bemerkung}
\begin{itemize}
\item Kurzschreibweise: $X \sim U(I)$
\item Sei $a<b$. Ein Intervall $I$ kann die Form $(a,b),\;[a,b],\;[a,b)$ oder $(a,b]$ haben. Dann gilt $|I|=b-a$. Ist $I$ von dieser Form, so gilt:
\item $\EE(X)=\frac{a+b}{2}$, $\var(X)=\frac{1}{12}(b-a)^2$
\item Dichte und Verteilungsfunktion:
$$f(x)=\begin{cases}
\frac{1}{b-a} & a\leq x \leq b\\
0 & \mathrm{sonst}
\end{cases}, \quad F(x)=\begin{cases}
0 & x \leq a\\
\frac{x-a}{b-a} & a<x<b\\
1 & x \geq b
\end{cases}$$
\end{itemize}
\begin{center}
\includegraphics[trim={6.2cm 10.6cm 5.2cm 12.9cm},clip,page=1, scale=.7]{Vorlesung/Skript/02_stetige_verteilungen.pdf}
\includegraphics[trim={6.2cm 2.6cm 5.2cm 20.3cm},clip,page=1, scale=.7]{Vorlesung/Skript/02_stetige_verteilungen.pdf}
\end{center}
\subsubsection{Normalverteilung}
\cparagraph{Definition} Eine ZV $X$ heißt normalverteilt mit den Parametern $\mu$ und $\sigma^2$, ($\mu \in \RR, \; \sigma > 0$, wenn sie die Dichte
$$f: \RR\to \RR, \qquad f(x)=\frac{1}{\sqrt{2\pi\sigma}}\exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right)$$
besitzt.

\cparagraph{Bemerkung}
\begin{itemize}
\item Kurzschreibweise: $X\sim \cN(\mu, \sigma^2)$
\item $\EE(X)=\mu$
\item $\var(X) = \sigma^2$
\item Verteilungsfunktion nicht in geschlossener Form angebbar (nur als Integraldarstellung oder unendliche Reihe)
\end{itemize}
\begin{center}
\includegraphics[trim={1.5cm 11cm 11.3cm 11cm},clip,page=2, scale=.7]{Vorlesung/Skript/02_stetige_verteilungen.pdf}
\includegraphics[trim={10.2cm 11cm 2.2cm 11cm},clip,page=2, scale=.7]{Vorlesung/Skript/02_stetige_verteilungen.pdf}
\includegraphics[trim={1.5cm 3cm 11.3cm 18.8cm},clip,page=2, scale=.7]{Vorlesung/Skript/02_stetige_verteilungen.pdf}
\includegraphics[trim={10.2cm 3cm 2.2cm 18.8cm},clip,page=2, scale=.7]{Vorlesung/Skript/02_stetige_verteilungen.pdf}
\end{center}

\cparagraph{Satz} Gilt $X\sim \cN(\mu, \sigma^2)$, dann gilt für die transformierte ZV
$$Y=\frac{X-\mu}{\sigma} \sim \cN (0,1)$$
Wir sagen dann: $Y$ ist standardnormalverteilt.

\cparagraph{Bemerkung} Für $Y \sim \cN (0,1)$ gilt:
\begin{itemize}
\item für die Verteilungsfunktion
\begin{align*}
\Phi(x):=F_Y(x)&=\frac{1}{\sqrt{2\pi}}\int\limits_{-\infty}^x \exp\left(-\frac{t^2}{2}\right)\intd{t}\\
&= 0,5 + \frac{1}{\sqrt{2\pi}}\int\limits_0^x \exp\left(-\frac{t^2}{2}\right)\intd{t}
\end{align*}
\item Werte von $\Phi$ lassen sich Tabellen oder Software entnehmen.
\item Jede beliebige Normalverteilung lässt sich auf die Standardnormalverteilung $\Phi$ zurückführen.
\item Symmetrie: $\Phi(-x)=1-\Phi(x)$
\end{itemize}

\cparagraph{Bemerkung} Für $X \sim \cN(\mu, \sigma^2)$ gilt:
\begin{itemize}
\item $F_X(x) = \PP(X\leq x) = \Phi \left(\frac{x-\mu}{\sigma}\right)$
\item $\PP(X\geq a) = 1 - \Phi \left(\frac{a-\mu}{\sigma}\right)$
\item $\PP(a\leq X\leq b)=\Phi \left(\frac{b-\mu}{\sigma}\right)-\Phi \left(\frac{a-\mu}{\sigma}\right)$
\item $\PP(X=a)=0$
\item Anwendung:
\begin{itemize}
\item Messfehler
\item geometrische und physikalische  Kenngrößen von Produkten (Länge, Masse, Widerstand, …)
\item biologische Merkmale
\item allgemein: Summe großer Anzahl von unabhängigen Größen
\end{itemize}
\end{itemize}

\cparagraph{Beispiel} (Drehteil) Ein Drehteil besitzt einen Soll-Durchmesser von $500\unit{mm}$. Die Toleranzgrenzen sind $499,6\unit{mm}$ und $500,3 \unit{mm}$.\\
Die von der Maschine hergestellten Teile besitzen in Wirklichkeit (statistisch überprüft) einen normalverteilten Durchmesser mit $\mu=500$ und $\sigma = 0,2$.\\
Wie groß ist die WK, dass ein solches Teil…
\begin{anumerate}
\item innerhalb der Toleranzgrenzen liegt?
\item einen Durchmesser kleiner als die untere Toleranzgrenze hat?
\item Wie genau muss die Maschine arbeiten (also wie groß darf $\sigma$ sein) damit maximal $1\%$ der produzierten Teile einen Durchmesser von maximal $499,6\unit{mm}$ haben?
\end{anumerate}
Lösung:\\
$X$ … Durchmesser in $\unit{mm}$\\
dann $X \sim \cN(500,\; 0,2^2)$.
\begin{anumerate}
\item 
\begin{align*}
\PP(499,6 \leq X \leq 500,3)&=\Phi \left(\frac{500,3-500}{0,2}\right)-\Phi \left(\frac{499,6-500}{0,2}\right)\\
&=\Phi(1,5)-\Phi(-2)\\
&= \Phi (1,5)-(1-\Phi(2))\\
&= \Phi(1,5)+\Phi(2)-1\\
&= 0,93319+0,97725-1 &&|\;\mathrm{Tabelle}\\
&= 0,91044\\
&\approx 91\%
\end{align*}
\item $\PP(X<499,6) = \Phi\left(\frac{499,6-500}{0,2}\right) = 1-\Phi(2)=1-0,97725=0,02275$
\item Nun ist $\sigma$ unbekannt. Also:\\
$X\sim \cN(500, \sigma^2)$\\
Wir suchen $\sigma$ mit 
\begin{align*}
0,01\geq\PP(X<499,6) &= \Phi\left(\frac{499,6-500}{\sigma}\right)\\
&=\Phi\left(\frac{-0,4}{\sigma}\right)\\
&=1-\Phi\left(\frac{0,4}{\sigma}\right)\\
\Leftrightarrow 0,01 &\overset{!}{=}1-\Phi\left(\frac{0,4}{\sigma}\right)\\
\Leftrightarrow \Phi\left(\frac{0,4}{\sigma}\right) &= 0,99\\
\Leftrightarrow \frac{0,4}{\sigma}&=\Phi^{-1}(0,99) =:z_{0,99} && 0,99\mathrm2{-Quantil}\\
z_{0,99}&=2,326 && |\; \mathrm{Tabelle}\\
\Rightarrow \sigma &=0,172
\end{align*}
Bei ein Standardabweichung von max. $0,172$ wird im Mittel höchstens $1\%$ Ausschuss produziert.
\end{anumerate}

\cparagraph{Bemerkung} Sei $\Phi$ die Verteilungsfunktion zur Standard-Normalverteilung.
\begin{itemize}
\item Für $\alpha \in (0,1)$ benötigt man oft $\Phi^{-1}(\alpha)$.\\
Dies ist das $\alpha$-Quantil $q_\alpha$.
\item Im Fall der Normalverteilung schreibt man oft $q_\alpha = z_\alpha \quad\Big(=\Phi^{-1}(\alpha)\Big)$.
\item Die Werte $z_\alpha$ entnimmt man einer Tabelle (o.ä.).
\item $z_\alpha = - z_{1-\alpha}$
\end{itemize}

\cparagraph{Satz} Seien $X\sim \cN(\mu_1, \sigma_1^2)$ und $Y\sim \cN(\mu^2, \sigma^2)$ unabhängige ZVen. Dann:
$$X+Y \sim \cN (\mu_1+\mu_2, \sigma_1^2+\sigma_2^2)$$

\subsubsection{Exponentialverteilung}
\cparagraph{Definition} Die ZV $X$ heißt exponentialverteilt mit dem Parameter $\lambda >0$, wenn sie die folgende Dichte besitzt:
$$f(x)=\begin{cases}
\lambda \exp(-\lambda x) & \mathrm{falls} \; x\geq 0\\
0 & \mathrm{sonst}
\end{cases}
$$
\cparagraph{Bemerkung}
\begin{itemize}
\item Kurzschreibweise: $X\sim \mathrm{Exp}(\lambda)$
\item $\EE(X)=\frac{1}{\lambda}, \quad \var(X)=\frac{1}{\lambda^2}$
\item Verteilungsfunktion:
$$F(x)=\begin{cases}
1-\exp(-\lambda x) & \mathrm{falls}\; x \geq 0\\
0 & \mathrm{sonst}
\end{cases}$$
\item Anwendung: Bedientheorie, Zuverlässigkeitstheorie, Verteilung von Zeitdauern wie Lebenszeiten, Reperaturzeiten, Wartezeiten, …
\end{itemize}

\begin{center}
\includegraphics[trim={6cm 10.5cm 5.3cm 11.8cm},clip,page=3, scale=.7]{Vorlesung/Skript/02_stetige_verteilungen.pdf}
\includegraphics[trim={6cm 2.4cm 5.3cm 19.9cm},clip,page=3, scale=.7]{Vorlesung/Skript/02_stetige_verteilungen.pdf}
\end{center}

\cparagraph{Beispiel} (Parallelschaltung) Ein System besteht aus 3 unabhängig voneinander arbeitenden, parallel geschalteten Elementen. Es sei bekannt, dass die Lebensdauer der einzelnen Elemente exponentialverteilt ist. Die mittlere Lebensdauer eines Elementes ist $ 1000\unit{[h]} $
\begin{anumerate}
	\item Wie groß ist die WK, dass Element 1 höchstens $ 500\unit{Std.} $ funktioniert?
	\item Wie groß ist die WK, dass das System mindestens $ 500 \unit{Std} $ funktioniert?
	\item Für welchen Zeitraum beträgt die Zuverlässigkeit des Systems $ 99\% $
\end{anumerate}
Lösung:\\
$ X_i $ … zufällige Lebensdauer von Element $ i, \; i=1,2,3 $\\
$ \Rightarrow X_i \sim \exp(\lambda), \; \EE(X_I)=\frac{1}{\lambda}=1000 \Rightarrow \lambda=\frac{1}{1000} $
\begin{anumerate}
	\item ges.: $ \underbrace{\PP(X_1 \leq 500)}_{F_{X_1}(500)} = 1-\exp\left(-\frac{1}{1000}\cdot 500\right)=1-\exp\left(-\frac{1}{2}\right) = 0,3935 $
	\item $ X $ … Lebensdauer des Systems\\
	$ X=\max(X_1,X_2,X_3) $\\
	Wie ist $ X $ verteilt?
	\begin{align*}
	F_X(x)&=\PP(X\leq x)=\PP(\max(X_1,X_2,X_3)\leq x)\\
	&=\PP(\{X_1 \leq x\} \cap \{X_2 \leq x\} \cap \{X_3 \leq x\} )\\
	&=\PP(X_1 \leq x) \cdot \PP(X_2 \leq x) \cdot \PP(X_3 \leq x)\\
	&= \left(1-\exp\left(-\frac{1}{1000}x\right)\right)^3 \qquad \text{für alle }x\geq 0
	\end{align*}
	gesucht: 
	\begin{align*}
	\PP(X\geq 500) &= 1-\PP(X\leq 500)\\
	&=1-\left(1-\exp\left(-\frac{500}{1000}\right)\right)^3\\
	&=0,9391
	\end{align*}
	\item gesucht: Zeit $ t $, so dass $ X\geq t $ mit WK von mind. $ 0,99 $. Also: $ 0,99 \leq \PP(X\geq t) $
	\begin{align*}
	&&0,99 &= \PP(X\geq t)\\
	\Leftrightarrow&& 0,99 &= 1-F_X (t)\\
	\Leftrightarrow&& F_X(t) &= 0,01\\
	\Leftrightarrow&& \left(1-\exp\left(-\frac{t}{1000}\right)\right)^3 &=0,01\\
	\Leftrightarrow&& t &= 242,6 \unit{h}
	\end{align*}
\end{anumerate}

\subsubsection{\texorpdfstring{$ \chi^2 $}{Chi-Quadrat}-Verteilung}

\cparagraph{Definition} Eine stetige ZV heißt $ \chi^2 $-verteilt mit $ n \in \NN $ Freiheitsgraden, falls $ X $ die Diche 
$$f_n(x)=\begin{cases}
\frac{x^{\frac{n}{2}-1}\exp\left(-\frac{x}{2}\right)}{2^{\frac{n}{2}}\Gamma\left(\frac{n}{2}\right)} & \text{falls }x>0\\
0 & \text{sonst}
\end{cases} \quad (x\in \RR)$$
besitzt. Hier ist $\Gamma$ die Gammafunktion, d.h. $\Gamma(x):= \int\limits_{0}^{\infty}t^{x-1}e^{-t}\intd{t}$ für $x>0$.

\cparagraph{Bemerkung}
\begin{itemize}
	\item Kurzschreibweise: $X\sim \chi^{2}$(n)
	\item $\EE(X)=n$, $\var(X)=2n$
	\item Verteilungsfunktion zeigen wir hier nicht (lässt sich mittels Gammafunktion darstellen)
	\item Quantile: Ist $\alpha\in (0,1)$ und $F_X$ die Verteilungsfunktion zu $X \sim \chi^{2}(n)$, so bezeichnen wir das $\alpha$-Quantil $q_\alpha$ mit $\chi^{2}_{n,\alpha}=q_{\alpha}=F_X^{-1}(\alpha)$
	\item Anwendung: Statistik, insbesondere Testtheorie
\end{itemize}

\begin{center}
\includegraphics[trim={6cm 10.2cm 5.3cm 12.2cm},clip,page=4, scale=.7]{Vorlesung/Skript/02_stetige_verteilungen.pdf}
\includegraphics[trim={6cm 2.4cm 5.3cm 20.2cm},clip,page=4, scale=.7]{Vorlesung/Skript/02_stetige_verteilungen.pdf}
\end{center}

Ein Grund für die große Bedeutung der $ \chi^2 $-Verteilung (in der Statistik) ist:
\cparagraph{Satz} Seien $ X_1, X_2, \ldots, X_n $ unabhängige standard-normalverteilte ZVen. Dann ist 
$$ X:=X_1^{2} + X_2^{2}+\ldots + X_n^{2} $$
$ \chi^{2} $-verteilt mit $ n $ Freiheitsgraden.

\subsubsection{\texorpdfstring{$ t $}{t}-Verteilung}

\cparagraph{Definition} Eine stetige ZV $X$ heißt $t$-verteilt mit $n\in \NN$ Freiheitsgraden, falls $X$ die Dichte 
\[ f_n(x)=\frac{\Gamma\left(\frac{n+1}{2}\right)}{\sqrt{n \pi}\Gamma\left(\frac{n}{2}\right)}\left(1+\frac{x^2}{n}\right)^{-\frac{n+1}{2}} \quad (x\in \RR) \]
besitzt. Hier ist $\Gamma$ wieder die Gammafunktion.

\cparagraph{Bemerkung}
\begin{itemize}
	\item Kurzschreibweise: $X\sim t(n)$
	\item falls $n>1$: $\EE(X)=0$, für $n=1$ existiert $\EE(X)$ nicht
	\item falls $n>2$: $\var(X)=\frac{n}{n-1}$, für $n=1,2$ existiert $\var(X)$ nicht
	\item Verteilungsfunktion zeigen wir nicht (lässt sich mittels Betafunktion darstellen)
	\item Quantile: Ist $\alpha \in (0,1)$ und $F_X$ die Verteilungsfunktion zu $X\sim t(n)$, so bezeichnen wir das $\alpha$-Quantil $q_\alpha$ mit $t_{n,\alpha}=q_\alpha=F_{X}^{-1}(\alpha)$
	\item Anwendung: Statistik, insbesondere Testtheorie
\end{itemize}

\begin{center}
\includegraphics[trim={6cm 10.3cm 5.3cm 12.3cm},clip,page=5, scale=.7]{Vorlesung/Skript/02_stetige_verteilungen.pdf}
\includegraphics[trim={6cm 2.4cm 5.3cm 20.2cm},clip,page=5, scale=.7]{Vorlesung/Skript/02_stetige_verteilungen.pdf}
\end{center}

Ein Grund für die große Bedeutung der $ t $-Verteilung (in der Statistik) ist:
\cparagraph{Satz} Seien $ Y $ und $ Z $ unabhängige ZVen mit $ Y\sim \chi^{2} (n) $ und $ Z \sim \cN(0,1) $. Dann ist 
\[ X=\frac{Z}{\sqrt{\frac{Y}{n}}} \]
$ t $-verteilt mit $ n $ Freiheitsgraden.

\subsubsection{\texorpdfstring{$ F $}{F}-Verteilung}

\cparagraph{Definition} Eine stetige ZV $X$ heißt $F$-verteilt mit $m\in \NN$ Freiheitsgraden im Zähler und $n\in \NN$ Freiheitsgraden im Zähler, falls $X$ die Dichte
\[ f_{m,n}(x)=\begin{cases}
m^{\frac{m}{2}}n^{\frac{n}{2}}\frac{\Gamma\left(\frac{m}{2}+\frac{n}{2}\right)}{\Gamma\left(\frac{m}{2}\right)\Gamma\left(\frac{n}{2}\right)}\cdot \frac{x^{\frac{m}{2}-1}}{(mx+n)^{\frac{m+n}{2}}} & \text{falls }x\geq 0\\
0 & \text{sonst}
\end{cases} \] 
besitzt. Hier ist $\Gamma$ wieder die Gammafunktion.
\cparagraph{Bemerkung}
\begin{itemize}
	\item Kurzschreibweise: $X\sim F(m,n)$
	\item falls $n>2$: $\EE(X)=\frac{n}{n-2}$, für $n=1,2$ existiert $\EE(X)$ nicht
	\item falls $n>4$: $\var(X)=\frac{2n^2(m+n-2)}{m(n-2)^2(n-4)}$, für $n=1,2,3,4$ existiert $\var(X)$ nicht
	\item Quantile: Ist $F_X$ die Verteilungsfunktion zu $X\sim F(m,n)$, so bezeichnen wir das $\alpha$-Quantil $q_\alpha$ mit $F_{m,n,\alpha}=q_\alpha=F_{X}^{-1}(\alpha)$
	\item Anwendung: Statistik, insbesondere Testtheorie
\end{itemize}

\begin{center}
\includegraphics[trim={6cm 10.2cm 5.3cm 12.5cm},clip,page=6, scale=.7]{Vorlesung/Skript/02_stetige_verteilungen.pdf}
\includegraphics[trim={6cm 2.4cm 5.3cm 20.2cm},clip,page=6, scale=.7]{Vorlesung/Skript/02_stetige_verteilungen.pdf}
\end{center}

Ein Grund für die große Bedeutung der $ F $-Verteilung (in der Statistik) ist:
\cparagraph{Satz} Seien $ Y $ und $ Z $ unabhängige ZVen mit $ Y\sim \chi^{2} (m) $ und $ Z \sim \chi^{2}(n) $. Dann ist 
\[ X=\frac{\frac{Z}{m}}{\frac{Z}{n}}\sim F(m,n) \text{.} \]
\section{Grenzwertsätze}

Wir betrachten nun Folgen von ZVen $X_1, X_2, X_3, \ldots$

\cparagraph{Definition} Sind $X_1, X_2, \ldots$ ZVen, welche alle die gleiche Verteilungsfunktion haben, so sagen wir „die ZV sind \emph{identisch verteilt}“.

\subsection{Gesetz der Großen Zahlen}
\cparagraph{Beispiel} Wir werfen eine faire Münze $n$ mal und zählen die Ereignisse „Kopf“ und „Zahl“:\\
\begin{tabular}{c | c | c | c}
	$n$ & Anzahl Kopf & Anzahl Zahl & rel. Anz. Kopf\\\hline
	$50$ & $22$ & $28$ & $0,44$\\
	$200$& $89$& $111$ & $0,445$\\
	$1000$ & $493$& $507$& $0,493$\\
	$100\,000$& $50\,256$&$49\,744$& $0,50256$
\end{tabular}\\
Die relative Anzahl Kopf nähert sich anscheinend der $0,5$ immer weiter an.\\
Diesen Zusammenhang formalisiert das Gesetz der großen Zahlen.

\cparagraph{Satz} Seien $X_1, X_2, \ldots$ unabhängige und identisch verteilte ZVen mit Erwartungswert $\mu$ und Varianz $\sigma^{2}$ und sei
\[ \overline{X_n}=\frac{1}{n}\cdot (X_1 + \ldots + X_n) \]
das arithmetische Mittel der ersten $n$ ZVen.\\
Dann gilt für jede (noch so kleine) Zahl $\varepsilon >0$
\[ \lim_{n\to \infty} \PP(|\overline{X_n}) -\mu| < \varepsilon) = 1 \text{.}\]
Insbesondere gilt
\[ \PP(|\overline{X_n}-\mu | < \varepsilon)\geq 1-\frac{\sigma^{2}}{n \cdot \varepsilon^{2}} \text{.} \]

Um zu verstehen, warum das GdgZ gilt benötigen wir die folgende Ungleichung:

\cparagraph{Satz} (Tschebyschew-Ungleichung) Sei $X$ eine ZV so dass $\var(X)$ existiert: Dann gilt für beliebiges $a>0$:
\[ \PP(|X-\EE X| \geq a) \leq \frac{\var(X)}{a^{2}} \text{.} \]

\cparagraph{Bemerkung} Die $T$-Ungleichung liefert eine obere Schranke an die WK, dass eine ZV um einen Mindestabstand $a$ von ihrem Erwartungswert abweicht.\\
Die Schranke ist klein, falls
\begin{itemize}
	\item $a$ groß ist
	\item $\var(X)$ klein ist
\end{itemize}

\begin{proof}
Sei also $X_1, X_2$ unabhängig identisch verteilt mit Erwartungswert $\mu$ und Varianz $\sigma^2$ und sei $\overline{X}_n=\frac{1}{n}\sum_{i=1}^nX_i$. Dann gilt:
$$ \EE(\overline{X}_n)=\EE\left(\frac{1}{n}\sum_{i=1}^nX_i\right) = \frac{1}{n}\sum_{i=1}^n\underbrace{\EE X_i}_\mu = \mu$$
und wegen der Unabhängigkeit gilt auch:
$$\var(\overline{X}_n)=\var\left(\frac{1}{n}\sum_{i=1}^n X_i\right) = \frac{1}{n^2}\var\left(\sum_{i=1}^nX_i\right) \overset{\substack{\text{da}\\\text{unabh.}}}{=}\frac{1}{n^2}\sum_{i=1}^n \var(X_i)=\frac{\sigma^2}{n}$$
Nun wenden wir Tschebyschew an:
$$\underbrace{\PP(|\overline{X}_n-\EE \overline{X}_n|\geq \varepsilon)}_{\PP(|\overline{X}_n-\mu|\geq \varepsilon)}\leq \underbrace{\frac{\var(\overline{X}_n)}{\varepsilon^2}}_{\frac{\sigma^2}{n \varepsilon^2}}$$
$$\PP(|\overline{X}_n-\mu| < \varepsilon) = 1-\PP(|\overline{X}_n-\mu | \geq \varepsilon) \geq 1-\frac{\sigma^2}{n\varepsilon^2}\overset{n\to \infty}{\longrightarrow} 1$$
\end{proof}

\cparagraph{Beispiel} Gegeben: unabhängige Poisson-verteilte ZVen mit $X_i \sim \mathrm{Poi}(3)$ für alle $i$\\
$\Rightarrow\EE (X_i) = 3 = \var(X_i)$ für alle $i$\\
$\Rightarrow$ für $\varepsilon = 0,1$ und $n=5000$ gilt $\PP(|\overline{X}_n-3|<0,1) \geq 1-\frac{3}{5000-0,1^2}=0,94$ 

\subsection{Der zentrale Grenzwertsatz}

\cparagraph{Satz} (Zentraler Grenzwertsatz)\\
Seien $X_1, X_2, \ldots$ unabhängige und identisch verteilte Zufallsvariablen mit Erwartungswert $\mu$ und Varianz $\sigma^2$. Für $n\in \NN$ setzen wir
$$S_n=X_1+\ldots+ X_n\text{.}$$
Für die standardisierte Zufallsvariable
$$Z_n=\frac{S_n-\EE S_n}{\sqrt{\var S_n}}=\frac{S_n - n \mu}{\sqrt{n}\cdot \sigma}$$
gilt dann
$$\lim_{n\to \infty} \underbrace{\PP(Z_n \leq z)}_{F_{Z_n}(z)} = \Phi (z) \qquad (z \in \RR)$$
wobei $\Phi$ (wie immer) die Verteilungsfunktion der Standardverteilung ist.

\cparagraph{Bemerkung} 
\begin{itemize}
\item Der Satz sagt aus, dass für großes $n$ die ZV $Z_n$ nahezu normalverteilt ist.
\item Wesentlich: es ist \emph{keine} Annahme über die Verteilung der $X_i$ gemacht.
\item mit $\overline{X}_n = \frac{1}{n}\sum_{i=1}^n X_i$ gilt
$$Z_n=\frac{S_n - n \mu}{\sqrt{n}\sigma} = \frac{\overline{X}_n - \mu}{\frac{\sigma}{\sqrt{n}}}$$
\item Sprechweise: „$Z_n$ ist asymptotisch/approximativ (standard-)normalverteilt.“
\item Schreibweise: Die Gleichung
$$\lim_{n\to \infty} \PP(Z_1 \leq z) = \Phi (z) \qquad (z \in \RR)$$
wird als 
$$Z_n \overset{a}{\sim}\cN (0,1)$$
abgekürzt. In diesem Sinne kann man auch 
$$S_n \overset{a}{\sim} \cN(n \mu, n \sigma^2) \text{ und } \overline{X}_n\overset{a}{\sim}\cN\left(\mu, \frac{\sigma^2}{n}\right)$$
verstehen.
\end{itemize}

\cparagraph{Beispiel} Wir werfen einen fairen Würfel mehrmals hintereinander.\\
$X_i$ … Ergebnis des $i$-ten Wurfs\\
$S_n = \sum_{i=1}^n X_i$ … Augensumme der ersten $n$ Würfe\\
ZGWS: $S_n \overset{a}{\sim} \cN (n \mu, n\sigma^2)$\\
$S_n$ ist asymptotisch normalverteilt mit Erwartungswert $n \cdot \mu =3,5$ und Varianz $n\sigma^2 = n \cdot 2,91\bar 6$, denn: \\
$\mu = \EE(X_n) = \frac{1}{6}(1+\ldots+6)=3,5$ und \\
$\sigma^2=\var(X_n)=\underbrace{\frac{1}{6}(1^2+\ldots + 6^2}_{\EE(X_n^2)}-\underbrace{3,5^2}_{(\EE X_n)^2}=2,91\bar 6$

\cparagraph{Beispiel} Es werden Schrauben mit einem zufälligen Gewicht mit EW $4\unit{g}$ und Standardabweichung $0,3\unit{g}$ hergestellt. Berechnen Sie mit dem ZGWS (unter Annahme der Unabhängigkeit):
\begin{anumerate}
\item WK, dass der inhalt einer Packung mit $200$ Schrauben maximal $795\unit{g}$ wiegt.\label{itm:1.4-10-a}
\item Welches Nettogewicht wird eine $200$er Packung mit WK $0,99$ überschreiten?\label{itm:1.4-10-b}
\end{anumerate}
Lösung:\\
$X_i$ … Gewicht der Schraube $i$ in Gramm, $i=1,\ldots, 200$\\
$S=\sum_{i=1}^{200} X_i$\\
$\Rightarrow \EE S = 800 \quad \var S = \var \left( \sum_{i=1}^{200} X_i\right)=\sum_{i=1}^{200} \underbrace{\var X_i}_{0,3^2} = 200 \cdot 0,09 = 18$

\begin{anumerate}
\item
\begin{align*}
\PP(S \leq 795) &= \PP( S - \EE S \leq 795 - \EE S) \\
&= \PP\left(\underbrace{\frac{S - \EE S}{\sqrt{\var S}}}_{Z}\leq \frac{795-\EE S}{\sqrt{ \var S}}\right)\\
&= \PP\left( Z \leq \frac{-5}{\sqrt{18}}\right)\\
&= \PP(Z \leq - 1,1785)\\
&\approx \PP(Z \leq - 1,18) \qquad \text{(runden)}\\
&\approx \Phi(-1,18) \qquad \text{(ZGWS)}\\
&= 1- \Phi(1,18) = 1-0,881 = 0,119
\end{align*}
Wahrscheinlichkeit ist etwa $20\%$.
\item Gesucht: Gewicht $a$ mit $\PP(S > a) = 0,99$
\begin{align*}
0,99 \overset{!}{=}& 1- \PP(S \leq a)\\
=& 1- \PP\left( \frac{S-\EE S}{\sqrt{\var S}} \leq \frac{a-\EE S}{\sqrt{\var S}}\right)\\
=& 1- \Phi\left(\frac{a-800}{\sqrt{18}}\right)\\
\Leftrightarrow 0,01 =& \Phi (\dots)\\
\Leftrightarrow \underbrace{\Phi^{-1} (0,01)}_{-2,3243} =& \frac{a-800}{\sqrt{18}}\\
\Leftrightarrow a =& 790,13
\end{align*}
\end{anumerate}

\cparagraph{Bemerkung}
Bei der Anwendung des ZGWS spielt oft die Gleichung
$$\PP(\sum_{i=1}^n X_i \leq a) = p$$
ein Rolle. Im Beispiel \ref{itm:1.4-10-a} war $p$ gesucht (mit $a$ und $n$ gegeben), in \ref{itm:1.4-10-b} war $a$ gesucht (mit $p$ und $n$ gegeben). 

Es könnte auch mal $n$ gesucht sein (siehe Hausaufgabe).\\
Spezialfall des ZWGS:
\cparagraph{Satz} (von Moivre-Laplace)\\
Gilt $S_n \sim \mathrm{Bin}(n,p)$, so gilt 
$$\lim_{n\to \infty} \PP\left( \frac{S_n - np}{\sqrt{np (1-p)}} \leq z \right) = \Phi(z)$$
bzw.
$$\frac{S_n - np}{\sqrt{np (1-p)}} \overset{a}{\sim} \cN(0,1)\text{.}$$

\cparagraph{Bemerkung}
\begin{itemize}
\item Satz sagt, dass für \emph{großes} $n$ nahezu $S_n \sim \cN(np, np(1-p))$ gilt.
\item \emph{Faustregel} für großes $n$:
$$np(1-p) \geq 9$$
\item Sind $X_1, X_2, \ldots$ unabhängig identisch Bernoulli-verteilte ZVen mit Parameter $p$, dann
$$\EE(X_1)=p, \quad \var (X_1) = p (1-p)$$
und
$$S_n = \sum_{i=1}^n X_i \sim \mathrm{Bin}(n,p)$$
Formel aus Satz 1.4-14 folgt jetzt aus ZGWS.
\end{itemize}

\cparagraph{Beispiel} Betrachten den $12\, 000$-fachen Münzwurf. Frage: Wie groß ist die WK, dass die Anzahl der Ergebnisse „Zahl“ weniger als $20$ vom Erwartungswert abweichen?\\
Lösung:\\
$S$ … Anzahl des Eintretens von Zahl bei $12\, 000$ Würfen\\
$\Rightarrow S\sim \mathrm{Bin}(12\,000,\; 0,5)$\\
$\overset{\text{Moivre-Laplace}}{\Longrightarrow} S \overset{a}{\sim} \cN (6\,000, 3\,000)$\\
Es gilt: $\EE(S)=12\,000 \cdot 0,5 = 6\,000$\\
Gesucht: $\PP(|S-6\,000|\leq 19)$\\
Wir berechnen diese WK approximativ mit Satz von Moivre-Laplace. Dazu: 
$$\PP(|S-6\,000|\leq 19)=\PP(|S-6\,000|\leq 19,99) = \PP(|S-6\,000|\leq 19,5)$$
Diese Werte wären theoretisch gleich (weil Verteilung diskret), in der Approximation (die dann stetig Verteilt ist) dann aber nicht mehr. Daher nehmen wir für die Approximation den Wert zwischen den beiden Extremen: die $19,5$ (Stetigkeits-Korrektur)!\\
Damit gilt:
\begin{align*}
\PP(5\,980,5 \leq S \leq 6\,019,5)&\approx \Phi\left(\frac{6\,019,5-6\,000}{\sqrt{3\,000}}\right) - \Phi \left( \frac{5\,980,5-6\,000}{\sqrt{3\,000}}\right) \\
&= 2 \Phi \left( \frac{19,5}{\sqrt{3\,000}}\right)-1 \\
&= 0,27817416
\end{align*}
Bemerkung: Exakter Wert $\sum_{m=5\,901}^{6\,019} \binom{12\,000}{m}\cdot \left(\frac{1}{2}\right)^{12\,000}=0,2781725$

\chapter{Statistik}
\section{Deskriptive Statistik}
\subsection{Grundbegriffe}
\cparagraph{Definition} (Grundgesamtheit und Merkmale)
\begin{itemize}
\item Grundgesamtheit $\Omega$ … klar festgelegte Menge von gleichartigen Objekten, die hinsichtlich bestimmter Eigenschaften untersucht werden sollen
\item $\omega \in \Omega$ … Merkmalsträger / statistische Einheit / Untersuchungseinheit
\item Merkmal … die in der Grundgesamtheit zu untersuchende Eigenschaft
\item Zustandsraum $S$ … Menge der möglichen Merkmalsausprägungen / unterschiedliche Eigenschaften
\item $s \in S$ … Merkmalsausprägung\\
Mathematische Darstellung:
$$X: \Omega \to S, \; \omega \mapsto x$$
\end{itemize}
Beachte: $X$ ordnet jedem Element aus $\Omega$ ein Merkmal zu. $X$ wird daher oft selbst als \emph{Merkmal} bezeichnet.

\cparagraph{Beispiel} (Notenspiegel)
\begin{itemize}
\item $\Omega = \{ \text{alle Schüler einer Klasse}\}$
\item $S=\{1,2,3,4,5,6\}$
\item $X$ … Funktion, welche jedem Schüler seine Zensur zuordnet, bspw. $X(\omega_1) = 3; \; X(\omega_2) = 5;$
\end{itemize}

\cparagraph{Beispiel} (medizinischer Fragebogen zur Pneumonie)
\begin{itemize}
\item $\Omega = \{ \text{alle Patienten, die in einem bestimmten Jahr an Pneumonie erkrankt sind}\}$
\item abfrage Merkmale: Alter, Geschlecht, Größe, Dauer des Krankenhausaufenthalts
\item Mehrdimensionaler Zustandsraum, z.B.:\\
$X(\omega_1)=(65,"m",182\unit{cm},5\unit{d}) \in S$\\
$X(\omega_2)=(34,"w",162\unit{cm},2\unit{d}) \in S$
\item $X$ … Funktion, welche jedem Patienten seine Merkmals-Vektoren zuordnet
\item Beachte: Mehrdimensionale Merkmale behandelt man in der \emph{multivariaten Statistik}
\end{itemize}

\cparagraph{Bemerkung} Merkmale lassen sich auf verschiedene Weisen in Klassen einteilen. Wir betrachten 3 dieser möglichen Einteilungen:
\begin{enumerate}[label=(\Alph*)]
\item Ein Merkmal heißt
\begin{itemize}
\item \emph{qualitatives Merkmal}, falls die Ausprägungen eine Qualität wiedergeben (und nicht ein Ausmaß). Insbesondere gibt es nur endlich viele Ausprägungen. Für qualitative Merkmale gibt es keine zwingende Ordnung/Reihenfolge.\\
Beispiele: Geschlecht, Religionszugehörigkeit oder Parteipräferenz
\item \emph{quantitatives Merkmal}, falls die Ausprägung ein Ausmaß bzw. eine Intensität wiederspiegeln. Die Ausprägungen sind in diesem Fall Zahlen (mit oder ohne Maßeinheit).\\
Beispiele: Alter, Größe oder Einkommen.
\end{itemize}
\item Ein Merkmal heißt
\begin{itemize}
\item \emph{diskret}, wenn es endlich viele oder abzählbar unendlich viele Ausprägungen annehmen kann.\\
Beispiele: Zensuren, Einwohnerzahl, Produktionszahlen einer Maschine an verschiedenen Tagen
\item \emph{stetig}, wenn überabzählbar viele Ausprägungen angenommen werden können.\\
Beispiele: Gewicht, Zeitmessung in $100\unit{m}$ Lauf, Länge einer Schraube
\end{itemize}
\item Ein Merkmal heißt
\begin{itemize}
\item \emph{nominalskaliert}, genau dann wenn es qualitativ ist (also qualitatives Merkmal = nominalskaliertes Merkmal)\\
Beispiele: Geschlecht, Religionszugehörigkeit oder Parteipräferenz
\item \emph{ordinalskaliert}, wenn es eine Rangordnung der Merkmalausprägung gibt, jedoch die Abstände zwischen den Merkmalsausprägungen nicht interpretiert werden können.\\
Beispiele: Dienstrang beim Militär, Zufriedenheit mit Produkt (gut > mittel > schlecht)
\item \emph{metrisch skaliert (oder karinalskaliert)}, falls es eine Rangordnung der Merkmalsausprägung gibt und die Abstände zwischen den Ausprägungen messbar und interpretierbar sind.\\
Weitere Unterscheidung für metrisch skalierte Merkmale:
\begin{itemize}
\item \emph{Intervallskala:} natürlicher Nullpunkt existiert nicht\\
Beispiele: IQ-Skala, Temperatur in Celsius-Skala, Jahreszahlen
\item \emph{Verhältnisskala:} natürlicher Nullpunkt existiert\\
Beispiele: Zeitdauer, Masse, Preis
\end{itemize}
\end{itemize}
\end{enumerate}

\cparagraph{Bemerkung} Statistisch Sinnvolle Auswertungen
\begin{itemize}
\item \emph{Nominalskala}
\begin{itemize}
\item Häufigkeiten durch Zählen der einzelnen Ausprägungen
\item geeignetes Lagemaß: Modalwert
\item kein sinnvolles Streuungsmaß
\end{itemize}
\item \emph{Ordinalskala}
\begin{itemize}
\item Häufigkeiten durch Zählen der einzelnen Ausprägungen
\item geeignetes Lagemaß: Modalwert, Median
\item geeignetes Streuungsmaß: Spannweweite
\end{itemize}
\item \emph{metrische Skala}
\begin{itemize}
\item Häufigkeiten durch Zählen der einzelnen Ausprägungen
\item geeignetes Lagemaß: Modalwert, Median, arithmetisches Mittel
\item geeignetes Streuungsmaß: Spannweite, Standardabweichung, Varianz, …
\end{itemize}
\end{itemize}

\cparagraph{Bemerkung}
\begin{itemize}
\item Bei Nominal und Ordinalskala sind keine Rechenoperationen wie Addition, Subtraktion, Multiplikation oder Division erlaubt.
\item Bei Intervallskala ist Differenzenbildung erlaubt (jedoch keine Quotienten), da kein natürlicher Nullpunkt existiert.
\item Bei Verhältnisskala ist Quotientenbildung erlaubt (jedoch keine Differenzen), da natürlicher Nullpunkt existiert.
\end{itemize}

Nun wollen wir Stichproben einführen.\\
Vorüberlegung:
\begin{itemize}
\item Ist $X: \Omega \to S, \; \omega \mapsto x$ ein Merkmal mit $S\subseteq \RR$ (metrische Skala), so interessiert uns wie dieses Merkmal auf der Grundgesamtheit (GG) verteilt ist, d.h. 
$$F_X(z) = \PP(X \leq z)$$
(das WK-Maß $\PP$ entsteht durch zufälliges (gleichverteiltes) rausgreifen eines Merkmalsträgers aus $\Omega$)\\
Verteilung des Merkmals in $\Omega \leftrightsquigarrow$ Verteilung $\PP$ bzw. $FX$\\
z.B. ein Viertel der Personen in der GG hat Körpergröße $> 1,8 \unit{m} \leftrightsquigarrow \PP(X > 1,8) = 0,25$
\item Problem: Oft ist $\Omega$ zu groß, als dass man alle Werte $X(\omega), \; \omega \in \Omega$ erheben kann (Gründe sind etwa: Kosten, Zeit, …).
\item Idee: Einschränkung auf möglichst „representative“ Teilmenge von Messungen der Merkmale. Berechnung der Kennzahlen, Eigenschaften, … auf dieser Teilmenge.
\item Hoffnung: Diese Berechnung geben uns Aufschluss über die Zusammensetzung der Merkmale.
\item Ziehen daher Stichprobe aus den Daten.
\end{itemize}

\cparagraph{Definition} Sei ein Merkmal $X$ gegeben und seien $X_1, \ldots, X_n$ unabhängige, identische wie $X$ verteilte Zufallsvariablen. Dann heißt der Vektor 
$$\vec{X} = (X_1, \ldots, X_n)^T$$
mathematische Stichprobe vom Umfang $n$. Jede Realisierung $\vec{x}=(x_1, \ldots, x_n)^T$ von $\vec{X}$ heißt konkrete Stichprobe (Beobachtungsreihe).

\cparagraph{Bemerkung} Sei $X: \Omega \to S, \; \omega \mapsto x$ ein Merkmal
\begin{itemize}
\item Um die Stichprobe vom Umfang $n$ zu modellieren wählen wir $n$ unabhängige identisch (wie $X$) verteilte ZV:
$$X_1, \ldots, X_n \qquad \text{(große Buchstaben)}$$
(Vor der Beobachtung, Mathematische Stichprobe $\rightsquigarrow$ Induktive Statistik)
\item Nach der Auswertung dieser Variablen (einsetzen von $\omega$) erhalten wir Realisierungen dieser Zufallsvariablen:
$$x_1, \ldots, x_n \qquad \text{(kleine Buchstaben)}$$
(Nach der Beobachtung, konkrete Stichprobe $\rightsquigarrow$ Deskriptive Statistik)
\end{itemize}

\subsection{Eindimensionales Datenmaterial}
Erinnerung:\\
\begin{tabular}{C{0.49} C{0.49}}
eindimensional & mehrdimensional\\
\mpb[0.45]
\begin{itemize}[leftmargin=*]
\item $S=\{ 1, \ldots , 6\}$ (Schulnoten, Würfel)
\item $S=\{0,1\}$ (Geschlecht, Münze, …)
\end{itemize}
\mpe
&
\mpb[0.45]
\begin{itemize}[leftmargin=*]
\item $S=\RR^2$ (Körpergröße und Gewicht)
\item $S=\{1,\ldots,6\}^2$ (2 mal würfeln)
\end{itemize}
\mpe
\\
\end{tabular}

\subsubsection{Stichprobenfunktionen}
\cparagraph{Definition} Sei $(X_1, \ldots, X_n)$ eine mathematische Stichprobe. Sei $f$ eine Funktion auf $S^n$, also $f: S^n \to \RR, \; (x_1, \ldots, x_n) \mapsto f(x_1, \ldots, x_n) = y$.\\
Dann heißt die Zufallsvariable 
$$T:= f(X_1, \ldots , X_n)$$
\emph{Stichprobenfunktion}.\\
Es folgen spezielle Stichprobenfunktionen.

\cparagraph{Definition} Sei $(X_1, \ldots, X_n)$ eine mathematische Stichprobe zum Merkmal $X$. Wir definieren:
\begin{itemize}
\item (Stichproben-)Mittelwert:
$$\overline{X}=\frac{X_1+\ldots + X_n}{n}$$
\item (Stichproben-)Streuung/Varianz
$$S^2=\frac{1}{n-1} \sum_{i=1}^n (X_i - \overline{X})^2$$
\item (Stichproben-)Standardabweichung
$$S=\sqrt{S^2}$$
\item Variationskoeffizient
$$V=\frac{S}{\overline{X}}$$
\item Spannweite
$$R=\max (X_1, \ldots, X_n) - \min (X_1, \ldots, X_n) \bigskip$$
Sei $X=(X_1, \ldots, X_n)$ dann bezeichnet 
$$(X_{(1)}, X_{(2)}, \ldots, X_{(n)})$$ 
den Vektor der geordneten Stichproben, d.h. 
$$X_{(1)}\leq X_{(2)} \leq \ldots \leq X_{(n)}\text{.}$$
Wir definieren damit
\item $\alpha$-Quantil $\widetilde{X}_\alpha$ mittels
$$\widetilde{X}_\alpha := \begin{cases}
X_{(k)} & \text{falls }\alpha n\text{ keine ganze Zahl ist und }\\
& k\text{ kleinste ganze Zahle größer }\alpha n\text{.}\\
\frac{1}{2}(X_{(\alpha n)}+X_{\alpha n+1)}) & \text{falls }\alpha n\text{ ganzzahlig.}
\end{cases}$$
dann gilt:
\begin{enumerate}
\item höchstens $\alpha \cdot n$ Stichprobenwerte sind kleiner als $\widetilde{X}_\alpha$.
\item höchstens $(a-\alpha) n$ SP-Werte sind größer als $\widetilde{X}_\alpha$
\end{enumerate}
\item Median $:=\widetilde{X}_{0,5}$
\item Inter-Quartilsabstand (Inter-Quartil-Range)
$$IQR = \widetilde{X}_{0,75}-\widetilde{X}_{0,25}$$
\end{itemize}

\cparagraph{Definition} Sei $X_1, \ldots, X_n$ eine mathematische Stichprobe. Dann heißt 
$$S_n: \RR \to \RR, \; S_n(z)= \frac{\text{Anzahl der }X_i\text{ mit } X_1 \leq z}{n}$$
empirische Verteilungsfunktion der Stichprobe.

\cparagraph{Bemerkung} 
\begin{itemize}
\item Bezeichnungen für konkrete SP ($x_1, \ldots ,x_n$) analog, nur mit kleinen Buchstaben:
$$\overline{x},\; s^2,\; s, \; v, \; \tilde{x}_\alpha, \; s_n(z) $$
\item Stichproben-Mittelwert, -Varianz, -Standardabweichung, Variationskoeffizient sind nur sinnvoll für \emph{metrisch} skalierte Merkmale!
\item Quantile, Median, IQR und empirische Verteilungsfunktionen auch sinnvoll für ordinal skalierte Daten.
\item Fur nominal skalierte Merkmale ist keine der oben genannten Funktionen sinnvoll. Hier verwendet man z.B. den Modalwert (Häufigkeit aufgetretener Werte) zur Charakterisierung.
\end{itemize}
Die empirische Verteilungsfunktion $S_n$ ist eine Näherung der theoretischen Verteilungsfunktion $F$ von $X$:
\cparagraph{Satz} (Glivenko-Cantelli, Hauptsatz der Statistik)\\
Sei $X_1, X_2, \ldots$ eine Folge von unabhängigen, identisch mit Verteilungsfunktion F verteilten ZVen und $S_n$ die empirische VF von den ersten $n$ Zufallsvariablen. Dann gilt für jede noch so kleine Zahl $\varepsilon > 0$ und jedes $x \in \RR$:
$$\lim_{n\to \infty} \PP(|S_n(x) - F(x)|<\varepsilon) = 1$$

\subsubsection{Aufbereitung statistischer Daten am Beispiel}

\cparagraph{Beispiel} $X$ … Anzahl der Störungen im Maschinenpark eines Betriebes in einer Woche
\begin{itemize}
\item $n=20$ Beobachtungen ($20$ verschiedene Wochen)
\item konkrete Stichprobe:\\
$(x_1, \ldots , x_{20}) = (4,2,6,3,3,1,5,2,2,1,0,4,2,5,5,3,7,2,1,3)$
\item Beobachtete Ausprägungen $a_j$:\\
$a_1=0, \; a_2 = 1, \ldots, \; a_8=7$
\item Häufigkeitstabelle:\\
\begin{tabular}{L{0.15} | L{0.15} | L{0.2} | L{0.15} | L{0.2}}
Ausprägung $a_j$ & Abs. Häufigkeit $h_j$ & Summen der abs. Häufigkeiten $\sum_{i=1}^j h_i$ & relative Häufigkeit $w_j$ & Summe der rel. Häufigkeiten $s_j = \sum_{i=1}^j w_i$\\\hline
0 & 1 & 1 & 0,05 & 0,05\\
1 & 3 & 4 & 0,15 & 0,2\\
2 & 5 & 9 & 0,25 & 0,45\\
3 & 4 & 13 & 0,2 & 0,65\\
4 & 2 & 15 & 0,1 & 0,75\\
5 & 3 & 18 & 0,15 & 0,9\\
6 & 1 & 19 & 0,05 & 0,95\\
7 & 1 & 20 & 0,05 & 1
\end{tabular}\\
Beachte: bei metrisch oder ordinal skalierten Merkmalen ordnet man die Ausprägungen der Größe nach.\\
Summen sind auch nur für metrisch oder ordinal skalierte Merkmale sinnvoll.
\item Graphische Dartellung mittels Stabdiagramm:
\begin{itemize}
\item absolute/relative Häufung $h_j$/$w_j$ auf $y$-Achse
\item Ausprägung $a_j$ auf $x$-Achse
\end{itemize}
\end{itemize}

\subsection{Zweidimensionales Datenmaterial}

\subsubsection{Anschauung am Beispiel}
\begin{itemize}
\item Zwei Merkmale $X$ und $Y$ werden an $n$ Untersuchungseinheiten beobachtet.
\item Wir erhalten eine 2-dimensionale mathematische Stichprobe
$$(X_1, Y_1), \ldots , (X_n, Y_n)$$
und die konkrete Stichprobe 
$$(x_1,y_1), \ldots, (x_n,y_n)$$
\item Ausprägungen von $X: a_1, \ldots, a_l$, $Y: b_1, \ldots, b_m$
\item Ausprägungen von $(X,Y): (a_j,b_k)$ mit $j\in\{1,\ldots, l\},\; k \in \{1,\ldots ,m\}$
\item absolute Häufigkeit von $(a_j, b_k)$ wird mit $h_{jk}$ bezeichnet.
\end{itemize}
\subsubsection*{Darstellungsmöglichkeiten}
\begin{enumerate}
\item Häufigkeitstabelle\\
Die Häufigkeiten $H=(h_{jk})$ werden in einer Tabelle dargestellt. Diese heißt auch Kreuztabelle oder Kontingenztafel.\\
Besonders geeignet für diskrete Merkmale mit wenigen Ausprägungen.
\item Streudiagramm\\
Graphische Veranschaulichung, wobei die Werte $(x_1,y_1),\ldots ,(x_n, y_n)$ in einem 2-dimensionalen Koordinatensystem als Punkte dargestellt werden.\\
Besonders geeignet für stetige Merkmale oder diskrete Merkmale mit beiden Ausprägungen.
\end{enumerate}

\cparagraph{Beispiel}
\begin{itemize}
\item $X$ … Anzahl der Störungen im Maschinenpark eines Betriebes innerhalb einer Woche
\item $X$ ist quantitativ, metrisch skaliert, diskret
\item $n=20$ Beobachtungen ($20$ Arbeitsperioden von je einer Woche)
\item Konkrete Stichprobe:
$$(x_1, \ldots, x_{20})=(4,2,6,3,3,1,5,2,2,1,0,4,2,5,5,3,7,2,1,3)$$
\item Beobachtete Ausprägungen $a_j$:
$$a_1=0, a_2 = 1, \ldots , a_8=7$$
\item Häufigkeitstabelle schafft Übersicht:\\
\begin{tabular}{C{0.15} C{0.19} C{0.19} C{0.19} C{0.19}}
Ausprägungen $a_j$ & absolute Häufigkeiten $h_j$ & Summe der absoluten Häufigkeiten $\sum_{i=1}^j h_j$ & relative Häufigkeit $w_j$ & Summe der relativen Häufigkeiten $s_j=\sum_{i=1}^j w_j$\\\hline
0 &	1 & 1 & 0,05 & 0,05\\
1 & 3 & 4 & 0,15 & 0,20\\
2 & 5 & 9 & 0,25 & 0,45\\
3 & 4 & 13 & 0,20 & 0,65\\
4 & 2 & 15 & 0,10 & 0,75\\
5 & 3 & 18 & 0,15 & 0,90\\
6 & 1 & 19 & 0,05 & 0,95\\
7 & 1 & 20  & 0,05 & 1
\end{tabular}
\paragraph{Beachte:} bei metrischen oder ordinal skaliertem Merkmal ordnet man die Ausprägungen der Größe nach. Summen (Spalte 3 und 5) sind auch nir für metrische oder ordinal skalierte Merkmale sinnvoll.
\item Graphische Darstellung mittels Stabdiagramm
\begin{itemize}
\item absolute Häufigkeit $h_j$ auf $y$-Achse\\
Ausprägung $a_j$ auf $x$-Achse
\begin{center}
\includegraphics[trim={7.8cm 2.4cm 7.3cm 21.8cm},clip,page=1, scale=1]{Vorlesung/Skript/05_deskriptive_statistik_beispiel_diskrete_daten.pdf}
\end{center}
\item relative Häufigkeit $w_j$ auf $y$-Achse\\
Ausprägung $a_j$ auf $x$-Achse
\begin{center}
\includegraphics[trim={7.8cm 18.7cm 7.3cm 5.6cm},clip,page=2, scale=1]{Vorlesung/Skript/05_deskriptive_statistik_beispiel_diskrete_daten.pdf}
\end{center}
\end{itemize}
\item Graphische Darstellung mittels Kreisdiagramm
\begin{center}
\includegraphics[trim={13.3cm 8.8cm 2.2cm 15.1cm},clip,page=2, scale=1]{Vorlesung/Skript/05_deskriptive_statistik_beispiel_diskrete_daten.pdf}
\end{center}
Abgetragen: Anzahl der Störungen\\
Winkel $\varphi_j$ proportional zur relativen Häufigkeit $w_j$\\
$\varphi_j = 360^\circ \cdot w_j$\\
\begin{tabular}{c c c}
$a_j$ & $w_j$ & $\varphi_j$\\
0 & 0,05 & $18^\circ$\\
1 & 0,15 & $54^\circ$\\
2 & 0,25 & $90^\circ$\\
3 & 0,20 & $72^\circ$\\
4 & 0,10 & $36^\circ$\\
5 & 0,15 & $54^\circ$\\
6 & 0,05 & $18^\circ$\\
7 & 0,05 & $18^\circ$
\end{tabular}
\item Stichprobenmittelwert
\begin{align*}
\overline{x} &= \frac{1}{n} \sum_{i=1}^n x_i = \frac{1}{n} \sum_{j=1}^k h_j a_j\\
&= \frac{1}{20}(4+2+6+3+3+11+5+2+2+1+0+4+2+5+5+3+7+2+1+3)\\
&= 3,05
\end{align*}
\item Stichprobenvarianz
\begin{align*}
s^2 &= \frac{1}{n-1}\sum_{i=1}^n (x_i-\overline{x})^2 = \frac{1}{n-1}\sum_{j=1}^k h_j (a_j-\overline{x})^2\\
&= \frac{1}{19} (1 \cdot (0-3,05)^2 + 3 \cdot (1-3,05)^2 + \ldots)\\
&= 3,418
\end{align*}
\item Median\\
Nötig: geordnete Stichprobe\\
Für gerade Anzahl von Stichproben:
$$(x_{(1)}\ldots x_{(20)}=(0,1,1,1,2,2,2,2,2,\textbf{3},\textbf{3},3,3,4,4,5,5,5,6,7)$$
$$\tilde x _{0,5} = \frac{1}{2}(x_{(0,5\cdot 20)} + x_{(0,5\cdot 20 + 1)}) = \frac{1}{2}(3+3) = 3$$
Genauso werden die Quantile $\tilde x_q$ für beliebiges $q \in (0,1)$ bestimmt.\\
Für ungerade Anzahl von Stichproben: 
$$\tilde x_{0,5}=x_{(0,5 \cdot n\;[\mathrm{aufgerundet}])}$$
\item Graphische Darstellung mittels Boxplot
\begin{center}
\includegraphics[trim={13cm 7cm 3.9cm 15.6cm},clip,page=3, scale=1]{Vorlesung/Skript/05_deskriptive_statistik_beispiel_diskrete_daten.pdf}
\end{center}
$y$-Achse: Anzahl der Störungen\\
Graphische Darstellung von 
\begin{itemize}
\item Maximum
\item $0,75$-Quantil
\item Median
\item $0,25$-Quantil
\item Minimum
\end{itemize}
\item empirische Verteilungsfunktion
$$s_n(x) = \begin{cases}
0 & \text{falls }x < a_1\\
s_j & \text{falls }a_j \leq x < a_{j+1} \quad s_n(j_j) = s_j\\
1 & \text{falls }x\geq a_k
\end{cases}$$
\begin{center}
\includegraphics[trim={6.7cm 19.4cm 6.8cm 3.5cm},clip,page=4, scale=1]{Vorlesung/Skript/05_deskriptive_statistik_beispiel_diskrete_daten.pdf}
\end{center}
\end{itemize}

\cparagraph{Beispiel} (stetige bzw. metrische Daten)
\begin{itemize}
\item Bei 100 elektrischen Bauteilen des gleichen Typs wurde die Lebensdauer überprüft. Die sortierten Daten lauten:
$$(x_{(1)}, \ldots, x_{(100)} = (121.9,131.7,167.2,171.7,203.3,208.6,\ldots,6954.8,7859.8,8448.9)$$
Jeder Wert kommt nur einmal vor.
\item Darstellung:
\begin{itemize}
\item Häufigkeitstabelle
\item Stabdiagramm
\item Kreisdiagramm
\end{itemize}
sehr ungünstig
\begin{center}
\includegraphics[trim={6.9cm 17.3cm 2cm 7.4cm},clip,page=1, scale=1]{Vorlesung/Skript/06_deskriptive_statistik_beispiel_metrische_daten.pdf}
\end{center}
\item Besser geeignet:
\begin{itemize}
\item Boxplot (übersichtlich, aber Informationsverlust)
\item Verteilungsfunktion (übersichtlich, ohne Informationsverlust)
\item Klassierung der Daten (und anschließend Histogramm, Häufigkeitstabelle, Kreisdiagramm, …)
\end{itemize}
\begin{center}
\includegraphics[trim={3.9cm 4.3cm 3.9cm 17.8cm},clip,page=1, scale=1]{Vorlesung/Skript/06_deskriptive_statistik_beispiel_metrische_daten.pdf}
\end{center}
\item \emph{Klassierung der Daten}\\
Um auf für stetige Merkmale Häufigkeitstabellen und Säulendiagramme zu nutzen, fassen wir „ähnliche“ Daten in Klassen zusammen. Genauer:\\
Wir unterteilen das Intervall $x_{min},x_{max})$ in $k$ Intervalle auf und betrachten dann diese gruppierten Daten in Häufigkeitstabelle und Diagrammen.\\
Empfehlung zur Einteilung der Klassen:
\begin{itemize}
\item Anzahl $k$ der Klassen:
\begin{itemize}
\item $k \approx \sqrt{n}$ falls $n\leq 400$
\item $20$ falls $n > 400$
\end{itemize}
\item Klassenbreite $d_j$ muss nicht notwendigerweise für jede Klasse gleich sein. Falls doch
$$d_j = d \approx \frac{x_{max}-x_{min}}{k}$$
\end{itemize}
\item Häufigkeitstabelle für klassierte Daten\\
\begin{tabular}{c C{0.18} C{0.18} C{0.18} C{0.18} C{0.18}}
$j$ & Klasse $K_j$ & absolute Klassenhäufigkeit $h_j$ & Klassenmitte $m_j$ & relative Klassenhäufigkeiten $w_j$ & relative Summenhäufigkeit $s_1+\ldots + s_j$\\\hline
1 & [0,1000) & 36 & 500 & 0,36 & 0,36\\
2 & [1000,2000) & 23 & 1500 & 0,23 & 0,59\\
3 & [2000,3000) & 19 & 2500 & 0,19 & 0,78\\
4 & [3000,4000) & 10 & 3500 & 0,1 & 0,88\\
5 & [4000,5000) & 3 & 4500 & 0,03 & 0,91\\
6 & [5000,6000) & 4 & 5500 & 0,04 & 0,95\\
7 & [6000,7000) & 3 & 6500 & 0,03 & 0,98\\
8 & [7000,8000) & 1 & 7500 & 0,01 & 0,99\\
9 & [8000,9000) & 1 & 8500 & 0,01 & 1\\
\end{tabular}
\item Histogramm mit konstanter Klassenbreite
\begin{center}
\includegraphics[trim={2.4cm 2.2cm 11.3cm 20.5cm},clip,page=2, scale=1]{Vorlesung/Skript/06_deskriptive_statistik_beispiel_metrische_daten.pdf}
\end{center}
Säulenfläche proportional zur absoluten Häufigkeit $h_j$\\
Bei konstanter Klassenbreite ist auch Säulenhöhe proportional zur absoluten Häufigkeit $h_j$
\item Histogramm mit unterschiedlicher Klassenbreite
\begin{center}
\includegraphics[trim={2.9cm 18.2cm 11.3cm 4.6cm},clip,page=3, scale=1]{Vorlesung/Skript/06_deskriptive_statistik_beispiel_metrische_daten.pdf}
\end{center}
Säulenfläche proportional zur absoluten Häufigkeit $h_j$\\
Bei unterschiedlicher Klassenbreite ist die $y$-Achse so skaliert, dass gilt:
$$\sum_{j=1}^k d_j \cdot l_j = 1$$
wobei $d_j$ … Klassenbreite, $l_j$ … Säulenhöhe
\end{itemize} 

\cparagraph{Beispiel} Uns liegt eine Stichprobe der Größe $116$ von (gleichzeitigen) Messungen des Ozongehaltes $X$ der Luft (in 1/1Mio Teilchen) und der Temperatur $Y$ (in Grad Fahrenheit)) vor:
$$((x_1,y_1),(x_2,y_2), \ldots, (x_{150},y_{150}))=((41,67),(36,72),(115,79),\ldots, (18,62))$$
\begin{itemize}
\item Streudiagramm
\begin{center}
\includegraphics[trim={7.1cm 15.8cm 7.1cm 7.7cm},clip,page=1, scale=1]{Vorlesung/Skript/07_deskriptive_statistik_beispiel_2d_daten.pdf}
\end{center}
\item \emph{Klassierung und Kontingenztafel}\\
Wir stellen uns vor die Daten liegen uns nur in klassierter Form vor:
\begin{itemize}
\item Ozongehalt $X$ nimmt Werte $1,2,3$ an, wobei\\
$1$ … Ozongehalt $<50$;\\
$2$ … Ozongehalt in $[50,100)$;\\
$3$ … Ozongehalt $\geq 100$
\item Temperatur $Y$ nimmt Werte $0,1$ an, wobei\\
$0$ … Temperatur $<75$;\\
$1$ … Temperatur $\geq 75$
\end{itemize}
Nun sieht die konkrete Stichprobe wie folgt aus:
$$((x_1,y_1),(x_2,y_2),\ldots,(x_{150},y_{150}))=((1,0),(1,0),(3,1),\ldots,(1,0))$$
Kontingenztafel und Streudiagramm\\
\begin{tabular}{c | c c}
& $Y=0$ & $Y=1$\\\hline
$X=1$ & 40 & 41\\
$X=2$ & 0 & 28\\
$X=3$ & 0 & 7
\end{tabular}
\begin{center}
\includegraphics[trim={12.4cm 2cm 3.8cm 23.1cm},clip,page=1, scale=1]{Vorlesung/Skript/07_deskriptive_statistik_beispiel_2d_daten.pdf}
\end{center}
\item Regressionsgerade:
$$a_1=r_{xy}\frac{s_y}{s_x}=\frac{s_{xy}}{s_x \cdot s_y}\cdot \frac{s_y}{s_x}=\frac{s_{xy}}{s_x^2}=0,2$$
und $a_0=\overline{y}-a_1 \cdot \overline{x}=77,87 - 0,2 \cdot 42,13 = 69,4$ also 
$$y=0,2 x + 69,4$$
\begin{center}
\includegraphics[trim={8.2cm 17.6cm 8cm 7.6cm},clip,page=2, scale=1]{Vorlesung/Skript/07_deskriptive_statistik_beispiel_2d_daten.pdf}
\end{center}
\end{itemize}

\subsubsection{Stichprobenfunktionen für 2-dimensionale Merkmale}

\cparagraph{Definition} Zu den beiden metrisch skalierten Merkmalen sei die zweidimensionale Stichprobe $(X_1,Y_1),\ldots, (X_n, Y_n)$ gegeben.\\
Wir definieren die folgenden Stichprobenfunktionen:
\begin{itemize}
\item Stichprobenkovarianz:
$$S_{X,Y}=\frac{1}{n-1}\sum_{i=1}^n(X_i - \overline{X})(Y_i-\overline{Y})$$
\item Stichproben-Korrelationskoeffizient (nach Pearson)
$$R_{X,Y}=\frac{S_{X,Y}}{S_X\cdot S_Y} \qquad \in [-1,1]$$
\end{itemize}

\cparagraph{Bemerkung} Für 2 ZVen $X$ und $Y$ kennen wir schon den Korrelationskoeffizienten
$$\varrho_{X,Y}=\frac{\cov{X,Y}}{\sigma_X \sigma_Y}\text{.}$$
Der Stichprobenkorrelationskoeffizient $R_{X,Y}$ (bzw. $r_{x,y}$ für die konkrete Stichprobe) ist ein Schätzwert für (das unbekannte) $\varrho_{X,Y}$.\bigskip

Wie findet man die Gerade $g$, welche die Daten $(x_1,y_1), \ldots, (x_n, y_n)$ „am besten“ approximiert?
\begin{itemize}
\item dazu sollen die Werte $(y_i-g(x_i))^2$ für alle $i$ möglichst klein sein.\\
\begin{tikzpicture}[scale=1]
\draw[green] (-3.5,-3) -- (2.5,2.5);
\node at (-3,-1) {$\bullet$};
\node at (-1,-2.5) {$\bullet$};
\node at (1.5,0) {$\bullet$};
\node at (0,1.5) {$\bullet$};
\node at (2,3) {$\bullet$};
\node at (-0.5,-1) {$\bullet$};
\draw[orange] (-3,-1) -- (-3,-2.5);
\draw[orange] (-1,-2.5) -- (-1,-0.7);
\draw[orange] (0,1.5) -- (0,0.24);
\draw[orange] (2,3) -- (2,2.05);
\draw[orange] (1.5,0) -- (1.5,1.6);
\draw[orange] (-0.5,-1) -- (-0.5,-0.22);
\end{tikzpicture}
\item wir minimieren dazu die Summer der quadrierten Abstände, also wir suchen $g$ so, dass 
$$\sum_{i=1}^n (y_i-g(x_i))^2$$
minimal wird. Dies führt zu folgender Definition:
\end{itemize}
\cparagraph{Satz} Sei eine konkrete Stichprobe $(x_1,y_1),\ldots, (x_n,y_n)$ mit $s_x\not = 0$ gegeben. Die Gerade 
$$g: \RR\to \RR, \; g(x)=a_0+a_1x$$
mit
$$a_1 = r_{xy}\frac{s_y}{s_x} \text{ und } a_0 = \overline{y} - a_1 \overline{x}$$
ist die eindeutige Lösung des Minimierungsproblems (siehe Summe aus vorhergehender Bemerkung). D.h. für eine beliebige Gerade $\tilde{g}$ gilt
$$\sum_{i=1}^n (y_i - g(x_i))^2 \leq \sum_{i=1}^n(y_1 - \tilde{g}(x_i))^2 \text{.}$$
$g$ heißt \emph{Regressionsgerade}.\\
(nur sinnvoll für metrische Merkmale)

\cparagraph{Bemerkung} Falls eine 2-dimensionale Stichprobe aus mindestens einem ordinal-skalierten Merkmal besteht, verwendet man den Korrelationskoeffizient nach Spearman.\\
Vorgehen:
\begin{enumerate}
\item Ordne der Größe nach:
$$x_{(1)}\leq x_{(2)} \leq \ldots \leq x_{(n)}$$
Z.B.:\\
\begin{tabular}{r | c c c c c c c c c}
$x_{(i)}$ & -2 & -2 & 0 & 1 &  5 & 6 &6 &6 &8\\\hline
Platz & 1 & 2 & 3 &4 &5 & 6 & 7 &8 &9\\
Rang & 1,5 & 1,5& 3 &4 &5 &7 &7 &7 &9
\end{tabular}
\item Rang einer Ausprägung berechnen mittels
$$R_(a) = \begin{cases}
k & \text{falls }a\text{ nur einmal (auf Platz }k\text{) auftritt}\\
\frac{k_1+k_2}{2} & \text{falls }a\text{ auf den Plätzen }k_1\text{ bis }k_2\text{ auftritt}
\end{cases}$$
\item $R(x_i)=$Rang der Ausprägung $x_i$\\
Setze $$\tilde{x}:= (R(x_1),R(x_2), \ldots, R(x_n))$$
\item gehe genauso für $y_i$ vor:
$$\tilde{y}=(R(y_1),\ldots, R(y_n))$$
\item Der Rangkorrelationskoeffizient nach Spearman ist nun
$$r_{x,y}^{(S)} := r_{\tilde{x},\tilde{y}}\text{.}$$
\end{enumerate}

\section{Schätztheorie}

\subsection{Einführung}
\begin{itemize}
\item Ziel: Anhand einer Stichprobe Rückschlüsse auf die Verteilung eines Merkmals $X$ in einer Grundgesamtheit zu ziehen.
\item Gegeben: Stichprobe $X_1,\ldots, X_n$ zu Merkmal $X$.
\item Bekannt: Der Verteilungstyp (Normal-/Poisson-/…verteilung). D.h. wir unterstellen, dass die tatsächliche Verteilung aus einer vorgegebenen ein- oder mehrparametrigen Schar von Verteilungsfunktionen stammt.\\
Raum der möglichen Parameter: $\Theta$ (groß Theta)
\item Unbekannt: der wahre Parameter $\vartheta \in \Theta$
\item Aufgabe: $\vartheta$ anhand der Stichprobe schätzen.
\item Beispiele: 
\begin{itemize}
\item Exponentialverteilung: Setzen voraus, dass $X\sim \mathrm{Exp}(\lambda)$ wobei $\lambda = \vartheta$ der unbekannte Parameter ist. $\Theta =(0,\infty) $
\item Normalverteilung: Setzen voraus, dass $X\sim \cN (\mu, \sigma^2)$, wobei $\mu$ und $\sigma^2$ unbekannt sind. Dann:
$$\Theta = \RR \times (0,\infty)$$
\end{itemize}
\end{itemize}
Wir unterscheiden:
\begin{itemize}
\item \emph{Punktschätzer}\\
Stichprobenfunktion $T=T(X_1,\ldots, X_n)$ liefert zu jeder konkreten Stichprobe eine konkrete Schätzung $\hat{\vartheta}$ des Parameters $\vartheta$.
\item \emph{Bereichsschätzer}\\
Gesucht ist hier ein Bereich $I=I(X_1,\ldots, X_n)$ mit 
$$\PP(\vartheta \in I) \geq 1-\lambda$$
für kleines (vorgegebenes) $\lambda$.\\
Meist ist $I$ ein \emph{Intervall}.
\end{itemize}

\subsection{Punktschätzer}

\subsubsection{Eigenschaften von Punktschätzern}

\cparagraph{Definition} Eine Stichprobenfunktion $T(X_1,\ldots, X_n)$ welche zur Schätzung eines Parameters $\vartheta \in \Theta$ verwendet wird heißt \emph{Schätzfunktion} (oder „Punktschätzer“ oder „Schätzer“) für $\vartheta$.

\cparagraph{Bemerkung} 
\begin{itemize}
\item Eine Stichprobenfunktion ist eine Zufallsvariable.
\item Um die Abhängigkeiten von $T(X_1,\ldots, X_n)$ von der Stichprobengröße $n$ zu verdeutlichen schreibt man oft auch $T_n$ statt $T(X_1, \ldots, X_n)$.
\item Oft verwendet man auch um den Schätzer zu bezeichnen den gleichen wie den zu schätzenden Parameter, jedoch versehen mit einem $\hat{\;}$, also etwa $\hat{\vartheta}$ (statt $T$).
\end{itemize}

\cparagraph{Beispiel}
\begin{itemize}
\item Gesuchter Parameter: Mittlere Abfüllmenge bei einem Getränkehersteller.\\
Schätzfunktion: $T=\overline{X}=\frac{1}{n}(X_1+\ldots + X_n)$
\item Gesuchter Parameter: Varianz der Abfüllmenge bei einem Hersteller\\
Schätzfunktion: $T=S^2=\frac{1}{n-1}\sum_{i=1}^n (X_i-\overline{X})^2$
\end{itemize}

\cparagraph{Definition}
Ein Punktschätzer $T$ für $\vartheta$ heißt
\begin{anumerate}
\item \emph{erwartungstreu} (oder unverzerrt), wenn 
$$\EE(T)=\vartheta\text{.}$$
\item \emph{asymptotisch erwartungstreu}, wenn
$$\lim_{n\to \infty} \EE(T_n)=\vartheta$$
\item \emph{(schwach) konsistent}, wenn für jedes $\varepsilon > 0$ gilt:
$$\lim_{n\to \infty}\PP(|T_n-\theta| < \varepsilon) = 1$$
\end{anumerate}

\cparagraph{Satz} Ist ein Schätzer $T_n$
\begin{itemize}
\item erwartungstreu und 
\item erfüllt $\lim_{n\to \infty} \var (T_n) = 0$
\end{itemize}
so ist er auch (schwach) konsistent.

\cparagraph{Beispiel} Sei $X$ ein Merkmal. Setze $\mu := \EE(X)$ und $\sigma ^2 = \var (X)$.
\begin{anumerate}
\item $T:= \overline{X} = \frac{1}{n} (X_1+\ldots + X_n)$ ist erwartungstreuer Schätzer für $\vartheta = \mu$, denn
$$\EE(T)=\EE \left( \frac{1}{n} (X_1+\ldots + X_n) \right)=\frac{1}{n}\cdot (\underbrace{\EE(X_1)}_{\mu}+\ldots + \underbrace{\EE(X_n)}_{\mu})=\mu $$
\item Wegen (a) und 
$$\var (T)=\var (\overline{X}) = \var \left( \frac{1}{n} \sum_{i=1}^n X_i\right) \overset{(unabh.)}{=}\frac{1}{n^2}\sum_{i=1}^n \underbrace{\var X_i}_{\sigma^2} = \frac{\sigma^2}{n} \overset{n\to \infty}{\longrightarrow} 0$$
ist $T=\overline{X}$ sogar ein konsistenter Schätzer für $\mu$.
\item $T=S^2 = \frac{1}{n-1}\sum_{i=1}^n (X_i-\overline{X})^2$ ist erwartungstreuer Schätzer für $\vartheta = \sigma^2$ (siehe Übung).
\end{anumerate}

\subsection{Bereichsschätzer}

\subsubsection{Problemstellung}

Wozu Bereichsschätzer?
\begin{itemize}
\item Punktschätzer liefert Wert, der den wahren Parameter höchstwahrscheinlich nicht genau trifft.
\item Frage: Wie weit liegt die Schätzung neben dem wahren Wert?
\item Bereichsschätzer liefern einen (zufälligen) Bereich, welcher mit hoher WK den wahren Wert überdeckt.
\item Meist (und hier immer) ist dieser Bereich ein Intervall.\\
Daher auch „Intervallschätzer“ oder „Konfidenzintervall“.
\end{itemize}

\cparagraph{Definition} Ein Intervall
$$I(X_1, \ldots, X_n) =[g_u (X_1, \ldots, X_n), g_o(X_1, \ldots, X_n)]$$
welches zur vorgegebenen $\alpha \in (0,1)$ die Bedingung
$$\PP(\vartheta \in I(X_1, \ldots, X_n)) \geq 1-\alpha$$
erfüllt heißt \emph{Konfidenzintervall} (oder „Vertrauensintervall“) zum Niveau $1-\alpha$. man nennt $1-\alpha$ das \emph{Konfidenzniveau}.

\cparagraph{Bemerkung} 
\begin{itemize}
\item $I(X_1, \ldots, X_n$ ist zufällig!
\item $\vartheta \in \Theta$ ist fest (aber unbekannt).
\item Um ein Konfidenzintervall (KI) zu bestimmen, wählt man \emph{zuerst} $\alpha\in (0,1)$. Typische Werte: $\alpha = 0,01$, $\alpha = 0,05$.
\item Die Intervallgrenzen $g_u$ und $g_o$ können $-\infty$ bzw. $+\infty$ annehmen. D.h. Intervalle der Art $(-\infty, b]$ oder $[a,\infty)$ sind möglich.
\item Die Realisierung $I(x_1, \ldots, x_n)$ der KI für eine konkrete Stichprobe heißt konkretes Konfidenzintervall.
\end{itemize}
Warum nicht einfach $\alpha = 0$ wählen?
\begin{itemize}
\item d.h. wir suchen $I$ mit $\PP(\vartheta \in I) =1$
\item dies liefert typischer Weise $I=\Theta$ und damit keinen Erkenntnisgewinn.
\end{itemize}

\cparagraph{Beispiel} (und allgemeine Vorgehensweise)\\
Sei $X\sim \cN(\mu, \sigma^2)$ ein Merkmal mit \emph{bekanntem $\sigma^2$}.\\
Gesucht: KI für $\vartheta= \mu$ zum Niveau $1-\alpha$.
\begin{enumerate}
\item Punktschätzer bestimmen: Kennen wir schon aus Beispiel 2.2-6:
$$T=\overline{X}$$
\item Verteilung von $T$ bestimmen: \\
$T$ ist normalverteilt (wegen Satz 1.3-31) und $\EE(T) = \mu$, $\var (T) = \frac{\sigma^2}{n}$ (siehe Bsp. 2.2.6) also $T\sim \cN \left( \mu, \frac{\sigma^2}{n}\right)$
\item Transformation von $T$, so dass $T$ in bekannte Verteilung übergeht.
\item $s_1$ und $s_2$ so wählen, dass 
$$\PP(S \in [s_1, s_2]) \geq 1-\alpha$$
\begin{itemize}
\item Wähle zuerst $\alpha_1$ und $\alpha_2$ mit $\alpha = \alpha_1 + \alpha_2$.
\item Wähle $s_1$ und $s_2$ so, dass $\PP(S\leq s_1) \leq \alpha$ und $\PP(S\geq s_2) \leq \alpha_2$
\end{itemize}
\begin{center}
\includegraphics[scale=.75]{Vorlesung/ABB10}
\end{center}
Also $s_1=z_{\alpha_1} = -z_{1-\alpha_1}$ und $s_2 = z_{1-\alpha_2}$. Dann:
$$\PP\left( - z_{1-\alpha_1} \leq \frac{\overline{X}-\mu}{\sigma}\sqrt{n} \leq z_{1-\alpha_2}\right) \geq 1-\alpha$$
\item Umstellen liefert:
$$\PP\left(\overline{X}-\frac{z_{1-\alpha_2}\sigma}{\sqrt{n}}\leq \mu \leq \overline{X} + \frac{z_{1-\alpha_1}\sigma}{\sqrt{n}}\right) \geq 1-\alpha$$
d.h. das gesuchte KI ist
$$I=\left[ \overline{X}-\frac{z_{1-\alpha_2}\sigma}{\sqrt{n}},\; \overline{X} + \frac{z_{1-\alpha_1}\sigma}{\sqrt{n}} \right]$$
\end{enumerate}

Für Prüfung: KI muss abgelesen (nicht gebildet) werden.

\cparagraph{Bemerkung}
\begin{itemize}
\item Oft wird $\alpha_1=\alpha_2 = \frac{\alpha}{2}$ gewählt.
\item Teilweise werden aber auch einseitige KIe betrachtet. Dann gilt:
$$\alpha_1 = \alpha, \; \alpha_2 = 0 \text{ oder } \alpha_1 = 0 ,\; \alpha_2 = \alpha$$
\end{itemize}

\subsubsection{Konfidenzintervalle bei Normalverteilung}
Sei $X$ ein normalverteiltes Merkmal mit Erwartungswert $\mu$ und Varianz $\sigma^2$. Konfidenzintervalle für $\mu$ und $\sigma^2$ sind der Tabelle zu entnehmen.\\
Achtung: Es ist jeweils zu beachten, ob der andere Parameter bekannt ist oder auch aus den Daten geschätzt wurde.
\cparagraph{Beispiel}
In einem Abfüllautomaten werde Zucker in Tüten abgefüllt. Der Sollwert beträgt $\mu_0 = 1\,000\unit{[g]}$. Die tatsächliche Abfüllmenge ist jedoch normalverteilt mit EW $\mu$ und Varianz $\sigma^2$. Aus einer SP vom Umfang $n=50$ ergab sich der Wert $\overline{x}=988,7$ und $s=31,2$.\\
Gesucht: einseitiges KI der Art $(-\infty, a]$ für $\mu$ zum Niveau $1-\alpha = 0,99$.\\
Lösung: KI für $\mu$, wobei $\sigma^2$ unbekannt ist:
\begin{align*}
I(x_1, \ldots, x_{50}) &= \left[ \overline{x}-\frac{t_{n-1,1-\alpha_2}}{\sqrt{n}} \cdot s, \; \overline{x}-\frac{t_{n-1,1-\alpha_1}}{\sqrt{n}} \cdot s \right]\\
& \text{mit }\alpha_2=0, \alpha_1=\alpha=0,01\\
&=\left[988,7 - \frac{t_{49,1}}{\sqrt{50}}\cdot 31,2, \; 988,7 - \frac{t_{49,099}}{\sqrt{50}}\cdot 31,2\right]\\
& \text{mit }t_{49,1} = \infty \quad t_{49,099}=2,405\\
&= (-\infty,\; 999,31]
\end{align*}
Beachte: $999,31 < 1\,000$
\cparagraph{Bemerkung} Ob ein einseitiges oder zweiseitiges KI gefragt ist, hängt von der konkreten Anwendung ab.
\begin{itemize}
\item Aus Sicht des Abnehmers der Ware:\\
$I=(-\infty,\; 999,31] \Rightarrow$ Ablehnung der Ware, da ein solches KI den wahren Mittelwert mit WK $0,99$ enthält. Der wahre Mittelwert liegt also mit $99\%$ WK unter den gewünschten $1\,000$, nämlich wahrscheinlich höchstens bei $999,31$.
\item Aus Sicht des Herstellers:\\
Ansatz: $I_2 = [a,\infty)$ liefert $I_2=[978,09,\; \infty)$. Da $1\,000 \in I_2$, hat er keine Einwände.
\item Aus Sicht eines unabhängigen Kontrolleurs:\\
Zweiseitiges KI ($\alpha_1 = \alpha_2 = 0,005$) ergibt $I=[976,87, \; 1\,000,53]$. Da $1\,000 \in I_3$ hat er keine Einwände.
\end{itemize}

\subsubsection{Konfidenzintervall für eine unbekannte Wahrscheinlichkeit}
Problem: Betrachte zufälliges Ereignis $A$ mit $\PP(A)=p$.\\
Zur Schätzung von $p$ betrachten wir $n$ unabhängige Versuchswiederhoungen. $\rightsquigarrow$ Modellierung mit $n$ unabhängigen ZV $X_1, \ldots, X_n$, welche alle Bernoulli-verteilt sind mit $p$. Erinnerung: $\EE(X_i)=p$ und $T=\overline{X}$ ist konsistenter Schätzer für $p$.\\
Gesucht ist KI für $\vartheta = p$.\\
2 Möglichkeiten:
\begin{enumerate}
\item \emph{asymptotisches KI} (beruht auf ZGWS) liefert Intervall, welches nahezu ein KI ist.\\
Faustregel zur Anwendung: $n \overline{x}(1-\overline{x})\geq 9$
\item \emph{exaktes KI} liefert tatsächliches KI
\end{enumerate}
(siehe Tabelle)

\cparagraph{Beispiel} Bei der Produktion von USB-Sticks wird eine SP der Größe $n=200$ entnommen. $12$ dieser USB-Sticks sind unbrauchbar.\\
Gesucht: KI zum Niveau $1-\alpha = 0,95$ für Ausschussteil $p$.
\hangpara{Lösung: $n=200$, $\overline{x}=\frac{12}{200}= 0,06$, $\alpha = 0,05$.\\
Faustregel: $n\overline{x}(1-\overline{x})=11,28 > 9 \Rightarrow$ ok. \\
$Z_{1-\frac{\alpha}{2}}=Z_{0,975} = 1,96$.}
Einsetzen: 
\begin{itemize}
\item asymptotisches KI
$$I_a=[0,0346, \; 0,1020]$$
\item exaktes KI
$$F_1=F_{24,\; 378,\; 0,025}=0,5103$$
$$F_2=F_{26,\; 376, \; 0,975}=1,6509$$
$$I_e=[0,0314, \; 0,1025]$$
\end{itemize}

\subsection{Bootstrapping}
Bootstrapping liefert eine Methode um Güte von Schätzern zu bewerten (auch wenn keine klassische Formel für KI vorhanden ist).\\
Frage: wie bewerten wir die Güte von Schätzern, wenn
\begin{itemize}
\item keine Annahme über zugrunde liegende Verteilung gemacht werden kann/soll.
\item wir einen Wert schätzen, für den es (in der Literatur) keinen Ansatz für ein KI gibt.
\end{itemize}
Grundidee:
\begin{itemize}
\item Es liegt nur \emph{eine} Stichprobe vor (Größe $n$)
\item Satz von Glivenko-Cantelli besagt, dass für großes $n$ die theoretische Verteilung (reale Verteilung) durch die empirische Verteilung (Verteilung der Stichprobe) approximiert werden kann.
\item Entsprechend der empirischen Verteilung generieren wir nun zufällig $k$ neue Stichproben (der Größe $n$), sogenannte Bootstrap-Stichproben. Dies entspricht $n$-fachem Ziehen mit Zurücklegen (aus original SP) $\rightsquigarrow$ liefert $k$ unabhängige SP der Größe $n$.\\
Anhand dieser lassen sich die Varianz des Schätzers, sowie Konfidenzintervalle schätzen.
\end{itemize}

\cparagraph{Definition} Sei $(X_1, \ldots, X_n)$ eine SP zum Merkmal $X$ nd $(x_1, \ldots, x_n)$ eine konkrete SP. Sei $T(X)$ eine reellwertige SP-Funktion. Das folgende Vorgehen generiert die Bootstrap-Schätzung für die Varianz von $T(X)$, sowie ein $(1-\alpha)$-Bootstrap-Konfidenzintervall für $T(X)$.
\begin{enumerate}
\item Ziehe $n$-mal aus $x_1, \ldots, x_n$ mit Zurücklegen und nenne diese Bootstrap-SP $x_1^{(b)}$
\item Wiederhole (1) noch $(k-1)$ mal und erhalte so die Bootstrap-SPen $x_2^{(B)}, \ldots ,x_k^{(B)}$
\item Wende die SP-Funktion $T$ auf die Bootstrap-SPen an:
$$t_1=T(x_1^{(B)}), \ldots , t_n=T(x_k^{(B)})$$
\item Die Bootstrap-Schätzung für die Varianz von $T(X)$ ist nun:
$$s_B^2=\frac{1}{k-1}\sum_{i=1}^k (t_i-\overline{t})^2\quad \overline{t}=\frac{1}{k}\sum_{i=1}^k t_i$$
\item Die Quantile $\tilde{t}_{\frac{\alpha}{2}}, \tilde{t}_{1-\frac{\alpha}{2}}$ des Vektors $t_1, \ldots, t_k$ liefern Schätzer für das 2-seitige KI.:
$$I_B=[\tilde{t}_{\frac{\alpha}{2}},\; \tilde{t}_{1-\frac{\alpha}{2}}]$$
\end{enumerate}

\cparagraph{Beispiel} Die Qualität eines Laser Entfernungsmesser soll überprüft werden. Dafür wurde $10$ mal die gleiche Entfernung in $\unit{mm}$ gemessen:
$$x=(1432,1431,1429,1430,1425,1431,1432,1436,1442,1422)\text{.}$$
Es soll ein Bootstrap Konfidenzintervall zum Niveau $1-\alpha = 0,8$ für die Standardabweichung angegeben werden. Außerdem ist eine Schätzung für die Varianz des Schätzers für die Standardabweichung zu bestimmen.\\
Lösung:
\begin{itemize}
\item Wir verwenden $k=15$ Bootstrap-Wiederholungen (in der Praxis sollte $k$ deutlich größer sein). $15$ mal $n$-maliges Ziehen mit Zurückliegen ergibt:
% Tabelle Skript
\item für alle $15$ Bootstrap-Stichproben berechnen wir die Stichprobenstandardabweichung:
$$t_1=6,85, \; t_2 = 5,83,\ldots, \; 5_{15}=4,65$$
\item Für alle $15$ Bootstrap-Stichproben die Stichprobenstandardabweichung, geordnet:
$$2,71,\; 2,96, \; 3,23,\; 4,65,\; 4,98,\; 5,03,\; 5,06,\; 5,83,\; 6,06,\; 6,46,\; 6,70,\; 6,85,\; 6,85$$
\item Quantile: $\alpha = 0,2, \; \frac{\alpha}{2}=0,1$\\
$0,1 \cdot 15 = 1,5$ und $0,9 \cdot 15 = 13,5$ sind keine Zahlen, daher wird $1,5$ und $13,5$ aufgerundet und es gilt
$$\tilde{t}_{0,1}=2,96 \text{ und } \tilde{t}_{0,9}=6,85$$
\item Konfidenzintervall:
$$I=[2,96\; 6,85]$$
\item Varianz:
\begin{align*}
s_B^2&=\frac{1}{14}\sum_{i=1}^15 (t_i-\tilde{t})^2\\
&= ((2,71-5,14)^2 + \ldots + (6,85-5,14)^2)/14-1,87
\end{align*}
\end{itemize} 

\cparagraph{Bemerkung} 
\begin{itemize}
\item Wie groß ist $k$ zu wählen?\\
$\to$ Möglichst groß! Mithilfe von PCs ist $k=1\,000$ und mehr meist kein Problem.
\item Vorteile:
\begin{itemize}
\item keine Verteilungsannahmen nötig
\item auf beliebige Stichprobenfunktionen anwendbar
\item einfach
\end{itemize}
\item Nachteil:
\begin{itemize}
\item Ungenauigkeit, da 2 Approximationsschritte vorgenommen werden:
\begin{enumerate}
\item theoretische Verteilung \\
$\rightsquigarrow$ empirische Verteilung
\item zufällige Stichproben aus empirischen Verteilung
\end{enumerate}
\item nicht deterministisch (liefert bei jedem Durchführen neue Werte)
\end{itemize}
\item Bootstrapping ist eine Methode aus dem Bereich Resampling.
\end{itemize}

\section{Testtheorie}
\subsection{Grundidee}
\begin{itemize}
\item Gegeben: Stichprobe $X_1, \ldots, X_n$ zu Merkmal $X$.
\item Aufgabe: Annahmen (Hypothese) über die (unbekannte) Verteilung von $X$ überprüfen.
\end{itemize}
Zwei Fälle:
\begin{anumerate}
\item Verteilung ist bis auf einen Parameter $\vartheta$ bekannt. Hypothese betrifft nur den Parameter $\vartheta$ (bspw. $\vartheta = \vartheta _0$ wobei $\vartheta_0$ der Sollwert ist).
\item Verteilungstyp unbekannt (nicht parametrische Tests).
\end{anumerate}
Idee:
\begin{itemize}
\item Definiere Nullhypothese ($H_0$, der für mich unproblematische Normalfall) und Alternativhypothese ($H_1$, problematischer Fall)
\item Ein Test ist eine Entscheidungsregel, die anhand der Stichprobe zu „Ablehnen“ oder „Nicht-Ablehnen“ der Nullhypothese führt.
\item Eine solche Entscheidung kann natürlich auch falsch sein („Nullhypothese ablehnen, obwohl sie stimmt“ oder „Nullhypothese nicht ablehnen, obwohl sie nicht stimmt“).
\item Wollen WK für „$H_0$ ablehnen, obwohl $H_0$ stimmt“ (peinlicher Irrtum) durch vorgegebenes $\alpha \in (0,1)$ beschränken.
\end{itemize}

\cparagraph{Definition} Ein (statistischer) Test ist eine Abbildung $\varphi$, welche eine Stichprobe $\mathbf{X}=(X_1, \ldots, X_n)$ nach $\{0,1\}$ abbildet. Seien zusätzlich $\alpha \in (0,1)$ und $\{P_\theta \;|\; \theta \in \Theta\}$ die Menge aller mäglichen Verteilungen der Stichprobe und $\Theta_0 \subseteq \Theta$, sowie $\Theta_1 = \frac{\Theta}{\Theta_0}$ gegeben. Dann heißt $\phi$ Test der Nullhypothese $\theta \in \Theta_0$ zum Signifikanzniveau $\alpha$, wenn
$$\PP_\theta (\underbrace{\phi = 1}_{H_0\text{ ablehnen}}) \leq \alpha \text{ für alle } \underbrace{\theta \in \Theta_0}_{H_0 \text{ stimmt aber}}\text{.}$$

\cparagraph{Bemerkung} Interpretation des Testergebnis:\\
\begin{tabular}{l p{0.85\linewidth}}
$\phi (\mathbf{X}) = 0$ & … Anhand der Stichprobe $\mathbf{X}=(x_1, \ldots, x_n)$ lässt sich der Verdacht, dass die Alternativhypothese richtig ist nicht rechtfertigen.\\
$\phi (\mathbf{X}) = 1$ & … Die Stichprobe $\mathbf{X}$ spricht gegen die Nullhypothese. Wir verwerfen sie daher und nehmen an, dass die Alternativhypothese gilt.
\end{tabular}

\cparagraph{Bemerkung} (konkrete Vorgehensweise)\\
Gegeben:
\begin{itemize}
\item Merkmal $X$ mit (unbekannter) Verteilung $\PP_{\theta^*}$.
\item Stichprobe $\mathbf{X} = (X_1, \ldots, X_n)$, \\
konkrete SP $\mathbf{x}=(x_1, \ldots, x_n)$.
\item $\{\PP_\theta \;|\; \theta \in \Theta\}$ … Menge aller in Frage kommenden Verteilungen.
\end{itemize}
\begin{enumerate}
\item[(0)] Beschreibung der Zufallsvariablen, wie sie verteilt ist und was bekannt ist.
\item Wahl des Signifikanzniveaus $\alpha \in (0,1)$
\item Aufstellen einer (Null-)hypothese\\
Wähle $\Theta_0 \subseteq \Theta$ dann \\
$H_0: \theta^* \in \Theta_0$ \\
$H_1: \theta^* \in \Theta_1 = \frac{\Theta}{\Theta_0}$\\
(bspw. $X$ ist normalverteilt mit unbekanntem Erwartungswert $\mu$, wir vermuten $\mu = \mu_0$, befürchten aber $\mu \not = \mu_0$. Dann $\Theta = \RR, \; \Theta_0 =\{\mu\}$ und $\Theta_1 = \RR\setminus \{\mu_0\}$. $H_0: \mu=\mu_0$, $H_1: \mu \not = \mu_0$)
\item Konstruktion (und Berechnung) einer Testgröße
$$T=T(\mathbf{X})$$
mit bekannter Verteilung, falls $H_0$ richtig ist.\\
$T$ soll Unterschiede zwischen der hypothetischen Verteilung $\PP_\theta, \; \theta \in \Theta_0$ und der tatsächlichen Verteilung widerspiegeln.\\
Für eine konkrete SP $\mathbf{x}$ wird der Testwert $t=T(\mathbf{x})$ berechnet.
\item Konstruktion eines kritischen Bereichs $K$ mit der Eigenschaft
$$\PP_\theta (T\in K) \leq \alpha \text{ für alle }\theta \in \Theta_0$$
(nach Möglichkeit mit $=$ statt $\leq $).
\item Entscheidungsregel:
\begin{itemize}
\item Fall $t\in K$: Ablehnen der Nullhypothese $H_0$ (Test ist signifikant; $\phi(\mathbf{x})=1$)
\item Fall $t \not \in K$: Auf Basis des durchgeführten Test ist nichts gegen die Nullhypothese einzuwenden (Test ist nicht signifikant; $\phi(\mathbf{x})=0$).
\end{itemize}
\end{enumerate}

\cparagraph{Bemerkung} Konstellation für Hypothesen (bei Parametertests)
\begin{itemize}
\item $H_0: \theta = \theta_0 ,\qquad H_1: \theta \not = \theta_0$
\item $H_0: \theta \leq \theta_0 ,\qquad H_1: \theta > \theta_0$
\item $H_0: \theta \geq \theta_0, \qquad H_1: \theta < \theta_0$
\end{itemize}

\cparagraph{Bemerkung} (Fehler) Bei Tests kann es zu verschiedenen Fehlern kommen:
\begin{enumerate}
\item Fehler 1. Art: Entscheidung für $H_1$, obwohl $H_0$ wahr ist ($\alpha$-Fehler, type-I-error)\\
\fbox{$\phi(\mathbf{x})=1$ obwohl $H_0$ gilt.}
\item Fehler 2. Art: $H_0$ wird nicht abgelehnt, obwohl $H_1$ wahr ist ($\beta$-Fehler, type-II-error)\\
\fbox{$\phi(\mathbf{x})=0$ obwohl $H_1$ gilt.}
\end{enumerate}
\begin{tabular}{r | c c}
& $H_0$ gilt & $H_1$ gilt\\\hline
Test verwirft $H_0$, $\phi(\mathbf{x})=1$ & Fehler 1. Art & korrekt\\
Test verwirft $H_0$ nicht, $\phi(\mathbf{x})=0$ & korrekt & Fehler 2. Art
\end{tabular}

\cparagraph{Bemerkung} Sei $\phi$ ein Test zur Nullhypothese $\theta \in \Theta_0$ mit $\alpha \in (0,1)$.
\begin{itemize}
\item Laut Konstruktion ist WK für Fehler 1. Art durch $\alpha$ beschränkt:
$$\PP_\theta (\phi =1 ) \leq \alpha \text{ für } \theta \in \Theta_0$$
\item $\beta$ ist eine Schranke für den Fehler 2. Art, falls
$$\PP_\theta (\phi =0 )\leq \beta \text{ für alle } \theta \in \Theta_1$$
(Test verwirft $H_0$ nicht, obwohl $H_1$ richtig ist)\\
Wählt man die kleinstmögliche Schranke $\beta$, so heißt $1-\beta$ die Macht (oder Power) des Tests.
\end{itemize}

\subsection{Parametertests}

Geben Übersicht zu wichtigsten Test.\\
Zum Durchführen wichtig:
\begin{itemize}
\item Welche Nullhypothese wird getestet?
\item Testvoraussetzungen?
\item Testgröße $T$?
\item Verteilung von $T$ unter $H_0$?
\item Kritischer Bereich?
\end{itemize}

\subsubsection[Tests für mü und sigma unter Normalverteilung]{Tests für $\mu$ und $\sigma$ unter Normalverteilung}

Sei $X\sim \cN(\mu, \sigma^2)$ ein normalverteiltes Merkmal und $X_1, \ldots, X_n$ zugehörige Stichprobe. Tests werden entsprechend der Tabelle 1 durchgeführt.

\cparagraph{Beispiel} 
Bei der Herstellung von Zylindern kann der Durchmesser als normalverteilt
angenommen werden. Die Standardabweichung $\sigma$ des Durchmessers kann als Maß für die Qualität der Produkte angesehen werden. Der Hersteller gibt an, dass die Standardabweichung $\sigma$ höchstens $0,03 \unit{[mm]}$ beträgt. Der Käufer zweifelt dies an, entnimmt eine Stichprobe vom Umfang $n = 40$ um die Aussage des Herstellers zu widerlegen. Aus der Stichprobe ergeben sich die
Werte $\overline{x} = 50,03 \unit{[mm]}$ und $s = 0,037 \unit{[mm]}$.

Führen Sie einen Test aus Sicht des Käufers zum Signifikanznivau $ \sigma = 0,05$ durch.\medskip\\
Lösung: Verwende $\chi^2$-Steuungstest, wobei $\theta = \sigma^2$ und $\mu$ unbekannt ist.\\
Setze $\sigma_0 = 0,03$.
\begin{enumerate}
\item Signifikanznivau: $\alpha = 0,05$
\item Hypothesen: $H_0: \; \sigma^2 \leq 0,03^2 \quad H_1: \sigma^2 > 0,03^2$\\
(\emph{Merke}: Was man zeigen will, wird als Alternativhypothese formuliert. Hier: der Käufer will zeigen, dass die Abweichung höher als angegeben ist.)
\item Testgröße:
$$t=\frac{(n-1)S^2}{\sigma_0^2 \sim \chi^2 (n-1)}$$
Konkreter Testwert: $t=T(x)=\frac{(n-1)s^2}{\sigma_0^2}=\frac{39 \cdot 0,037^2}{0,03^2}=59,32$
\item  Kritischer Bereich: $K=(\chi^2_{n-1, 1-\alpha}, \infty) = (\chi^2_{39, \; 0,95}, \infty) = (54,57, \infty)$\\
(aus Quantiltabelle für die $\chi^2$-Verteilung ablesen)
\item Entscheidung: $t \in K \Rightarrow H_0$ wird abgelehnt ($\phi(xi)=1$)
(6) Interpretation: Die Stichprobe bestätigt die Vermutung des Käufers. Die Nullhypothese, dass „die Standardabweichung maximal $0.03\unit{[mm]}$ beträgt“, wird verworfen.
\end{enumerate}

\cparagraph{Bemerkung}
\begin{itemize}
\item Die Entscheidung „Ablehnen von $H_0$“ oder nicht hängt von $\alpha$ ab. Hätten wir im Beispiel $\alpha = 0,01$ gewählt, so erhielten wir $t \not \in K = (62,43 \;,\; \infty)$, d.h. gegen $H_0$ wäre nichts einzuwenden gewesen.
\item $\alpha$ ist immer \emph{vor} der Durchführung des Tests zu wählen.\\
Derjenige $\alpha$-Wert, für den die Grenze des kritischen Bereichs genau mit dem konkreten Wert $t$ der Testgröße übereinstimmt (also die Grenzstelle zwischen Ablehnung und Nicht-Ablehnung) heißt \emph{p-Wert}.
\item Es gilt:\\
$p < \alpha \Rightarrow$ Ablehnen von $H_0$\\
$p \geq \alpha \Rightarrow$ gegen $H_0$ ist nichts einzuwenden.\\
Beachte: p-Wert ist die typische Ausgabe von Statistik-Software beim Durchführen von Tests.
\item p-Wert ist die WK, dass die Testgröße $T$ den konkreten Wert $t$ oder einen extremeren annimmt.\\
Liegt das $t$ in dem kritischen Bereich $K$ (dessen Flächeninhalt $\alpha$ ist), wird $H_0$ abgelehnt, der p-Wert ist die Fläche ab $t$ (und ist kleiner $\alpha$, wenn $H_0$ abgelehnt wird).\\
Liegt das $t$ nicht im kritischen Bereich $K$, dann ist der p-Wert die Fläche ab $t$ (und $p\geq \alpha \Leftrightarrow t \not \in K$).\\
Bei der beidseitigen Betrachtung wird für p-Wert die Fläche von $\pm t$ bis $\pm \infty$ betrachtet. Dabei gilt wieder: $p< \alpha \Leftrightarrow H_0$ wird abgelehnt und anders herum.
\end{itemize}

\subsubsection{Tests für 2 unabhängige Stichproben unter Normalverteilung}
\begin{itemize}
\item Betrachte 2 normalverteilte Merkmale mit je einer Stichprobe.
\item Die SPen können von unterschiedlicher Größe sein.
\item Es sollen Hypothesen zum Vergleich der Erwartungswerte bzw. der Varianzen untersucht bzw. getestet werden.
\item Beispiele:
\begin{itemize}
\item Sind Männer im Mittel größer als Frauen?
\item Ist das Einkommen in den neuen und den alten Bundesländern im Mittel gleich?
\item Ist die Varianz der Körpergrößen bei Männern und bei Frauen die gleiche?
\end{itemize}
\item Vorgehen: Entsprechend der Schritte (1)-(5) aus Bemerkung 2.3-3, wobei Testgröße, kritischer Bereich, … der Tabelle 2 zu nehmen sind. 
\end{itemize}

\cparagraph{Beispiel} Klaus behauptet sein Ruhepuls ist niedriger als der von Peter. Nachdem Klaus $10$ Tage und Peter $15$ Tage mit einem Messgerät den Ruhepuls gemessen haben, versucht Klaus mit einem Test (zum Sig.niveau $\alpha = 0,05$) seine Behauptung zu bestätigen. Welches Ergebnis zeigt sich, wenn folgendes gemessen/berechnet wurde:\\
$\overline{x}_K=55\quad, \; \overline{x}_P=57$\\
$s_k = 3 \quad, \; s_P = 4$\\
(Annahme: Merkmale normalverteilt und $\sigma_P=\sigma_K$)
\begin{enumerate}
\item $\alpha = 0,05$
\item $H_0:\mu_K \geq \mu_P \qquad H_1: \mu_K < \mu_P$ (weil Klaus zeigen will, dass sein Ruhepuls niedriger ist)
\item $T=\frac{(\overline{X}-\overline{Y}\sqrt{\frac{n_1 n_2}{n_1+n_2}}}{\sqrt{\dots}}$\\
$t=\frac{(55-57)\cdot \sqrt{\frac{10\cdot 15}{10 + 15}}}{\sqrt{\frac{9\cdot 3^2 - 14 \cdot 4^2}{23}}}=-1,345$
\item $K=(-\infty, -t_{n_1+n_2-2, \; 1-\alpha})=(-\infty, \; - 1,7139)$
\item Entscheidung: $t\not \in K \Rightarrow H_0$ wird nicht verworfen.
\item Interpretation: Auf Grundlage der vorliegenden Daten kann (bei einem Signifikanzniveau von $\alpha=0,05$) nicht gezeigt werden, dass „der Ruhepuls von Klaus im Mittel niedriger ist als der von Peter“.
\end{enumerate}
Beachte: Hätte Klaus weniger Angst vor einem falsch-positiven Ergebnis gehabt, hätte er mit $\alpha=0,1$ gerechnet. Dann wäre $t\in K$ heraus gekommen.

\subsubsection{Tests für unbekannte Wahrscheinlichkeiten}
\begin{enumerate}[label=(\Alph*)]
\item eine Stichprobe\\
Gegeben:
\begin{itemize}
\item A zufälliges Ereignis mit $\PP(A)=p\in[0,1]$
\item $X$ mit Parameter $p$ Beroulli-verteiltes Merkmal mit SP $X_1, \ldots, X_n$
\item $\sum_{i=1}^n X_i = n \overline{X}$ … absolute Häufigkeit von $A$ bei $n$ unabhängigen Versuchen
\item $\overline{X}$ … relative Häufigkeit
\end{itemize}
Aufgabe: Nullhypothese $p=p_0, \; p \leq p_0$ bzw $p \geq p_0$ für vorgegebenes $p_0\in [0,1]$ überprüfen.\\
Vorgehen: entsprechend Bemerkung 2.3-3 und Tabelle 3
\item zwei SPen\\
Gegeben:
\begin{itemize}
\item $A,\;B$ zufällige Ereignisse mit $\PP(A)=p_1, \; \PP(B)=p_2$
\item $X\sim \mathrm{Bin}(p_1), \; Y\sim \mathrm{Ber}(p_2)$ Merkmale mit SPen $X_1, \ldots, X_n$ und $Y_1, \ldots , Y_n$
\end{itemize}
Aufgabe: Nullhypothese $p_1=p_2,\; p_1 \leq p_2$ bzw. $p_1 \geq p_2$ überprüfen\\
Vorgehen: entsprechend Bemerkung 2.3-3 und Tabelle 4
\end{enumerate}

\cparagraph{Beispiel} Bei der Herstellung von Zahnprothesen wird der Ausschussanteil untersucht. Es ist zu prüfen ob sich zeigen lässt, dass das neue Herstellungsverfahren (B) gegenüber dem alten Verfahren (A) eine Verbesserung ist.\\
\begin{tabular}{c | c | c}
Verfahren & SP-Umfang & Ausschussanzahl\\\hline
A & $400$ & $29$\\
B & $500$ & $25$
\end{tabular}\\
Es ist ein Test zum Signifikanzniveau $\alpha=0,05$ durchzuführen.
\begin{enumerate}
\item $\alpha = 0,05$
\item $H_0=p_a \leq p_B \qquad H_1= p_A > p_B$\\
$p_A$ … Ausschussverfahren von Verteilung A\\
$p_B$ … Ausschussverfahren von Verteilung B
\item $T=\frac{\overline{X}-\overline{Y}}{\sqrt{\hat{p}(1-\hat{p})\frac{n_1+n_2}{n_1\cdot n_2}}} \sim \cN(0,1)$ mit $\hat{p}=\frac{n_1 \overline{X}-n_2 \overline{Y}}{n_1+n_2}$\\
konkreter Testwert: $t=\frac{\overline{x}-\overline{y}}{\sqrt{\hat{p}(1-\hat{p})\frac{n_1+n_2}{n_1\cdot n_2}}}=\frac{\frac{29}{400}-\frac{25}{500}}{\sqrt{0,06(1-0,06)\frac{900}{400\cdot 500}}}=1,412$\\
$\hat{p}=\frac{29+25}{900}=0,06$\\
Prüfen der Faustregel: $n\overline{x}(1-\overline{x})=26,9 > 9 \quad n\overline{y}(1-\overline{y})=23,8>9 \Rightarrow$ ok
\item Kritischer Bereich\\
$K=(z_{1-\alpha}, \infty) = (z_{0,95}, \infty) = (1,645\;,\;\infty)$
\item $t\not \in K \Rightarrow H_0$ wird nicht verworfen.
\item Interpretation: Auf Grundlage der vorliegenden SP lässt sich die (Alternativ-)hypothese, dass „das neue Herstellungsverfahren gegenüber dem alten Verfahren einen geringeren Ausschussanteil hat“ nicht nachweisen.
\end{enumerate}

\subsection{Parameterfreie Tests}
Vorgehensweise ist fast wie bei parametrischen Tests, mit dem Unterschied, dass hier nicht nur die Parameterwerte in die Hypothesen eingehen. Wir lernen hier „nur“ den $\chi^2$-Un\-ab\-häng\-ig\-keits\-test kennen.

\subsubsection[chi-quadrat-Unabhängigkeitstest]{$\chi^2$-Unabhängigkeitstest}
Aufgabenstellung: Zu überprüfen ist, ob zwei diskrete Merkmale $X$ und $Y$ unabhängig sind. Dafür liegt eine 2-dimensionale SP vor.
$$(X_1,Y_1), (X_2, Y_2), \ldots, (X_n, Y_n)$$
Kontingenztafel:\\
$X$ habe Ausprägungen $1, \ldots, l$\\
$Y$ habe Ausprägungen $1, \ldots, m$\\
\begin{tabular}{c | c c c c | c}
$X\setminus Y$ & $1$ & $2$ & $\dots$ & $m$ & $\sum$\\\hline
$1$ & $H_{11}$ & $H_{12}$ & $\dots$ & $H_{1m}$ & $H_{1 *}$\\
$2$ & $H_{21}$ & $H_{22}$ & $\dots$ & $H_{2m}$ & $H_{2 *}$\\
$\vdots$ & $\vdots$ &  &  & $\vdots$ & $\vdots$\\
$l$ & $H_{l1}$ & $H_{l2}$ & $\dots$ & $H_{lm}$ & $H_{l *}$\\\hline
$\sum$ & $H_{* 1}$ & $H_{* 2}$ & $\dots$ & $H_{* m}$ & $n$
\end{tabular}
\begin{itemize}
\item $H_{jk}$ … Häufigkeit des gleichzeitigen Auftreten von $X=j$ und $Y=k$
\item $H_{j*}=\sum_{k=1}^m H_{jk}$ … Randhäufigkeit (Zeilensumme)
\item $H_{* k} =\sum_{k=1}^l H_{jk}$ … Randhäufigkeit (Spaltensumme)
\end{itemize}
Gehe nun in die üblichen Schritte (1)-(5) bzw. (6) und nach Tabelle 6 vor.

\cparagraph{Bemerkung}
\begin{itemize}
\item Falls die Merkmal $X$ bzw. $Y$ stetig sind, so lässt sich ein $\chi^2$-Unabhängigkeitstest rechnen, wenn man die Daten in Klassen einteilt.
\item Faustregel für Anwendbarkeit:
$$\frac{H_{j*} \cdot H_{* k}}{n}\geq 5 \text{ für alle }j,k$$
\item Die Teststatistik $T=\sum\sum \dots$ wird groß, falls die beobachteten Häufigkeiten $H_{jk}$ stark von den erwarteten Häufigkeiten $\frac{1}{n}\cdot H_{j*} \cdot H_{*k}$ abweichen.\\
Die Größe $\frac{H_{j*}H_{*k}}{n}$ beschreibt die erwartete Häufigkeit unter der Annahme von Unabhängigkeit bei gegebenen Randhäufigkeiten $H_{j*}$ und $H_{*k}$.
\item Im Spezialfall $m=l=2$ gibt es eine vereinfachte Formel für $T$, siehe Tabelle.
\end{itemize}

\cparagraph{Beispiel} (mit $m=l=2$) Von $90$ Schülern ($47$ Mädchen, $43$ Jungs) der 4. Klasse einer Grundschule gehen $34$ auf das Gymnasium. Von diesen $34$ Schülern sind $20$ Mädchen. Lässt sich mit einem Test zum Signifikanzniveau $0,05$ zeigen, dass die Wahl der Bildungseinrichtung vom Geschlecht abhängig ist?
\begin{enumerate}
\item $\alpha = 0,05$
\item $H_0: X\text{ und }Y\text{ unabhängig} \quad H_1=X \text{ und }Y \text{ nicht unabhängig}$ wobei \\
$X$ … Wahl der Bildungseinrichtung ($1=$Gymnasium, $2=$kein Gymnasium)\\
$Y$ … Geschlecht ($1$ … männlich, $2$ … weiblich)
\item $T=n\cdot \frac{(H_{11} H_{22}-H_{12}H_{21})^2}{H_{1*}H_{2*}H_{*1}H_{*2}}$\\
Kontingenztafel:\\
\begin{tabular}{c | c c | c}
$X\setminus Y$ & $1$ & $2$ & $\sum$\\\hline
$1$ & $14$ & $20$ & $34$\\
$2$ & $29$ & $27$ & $56$\\\hline
$\sum$& $43$ & $47$ & $90$
\end{tabular}\\
$t=90\frac{(14\cdot 27-20 \cdot 29)^2}{34\cdot 56 \cdot 43 \cdot 47}=0,945$
\item Kritischer Bereich\\
$K=(\chi_{1, 1-0,05}, \infty) = (3,84\;,\; \infty)$
\item $t\not \in K \Rightarrow H_0$ wird nicht verworfen
\item Interpretation: Auf Grundlage der SP lässt sich die Unabhängigkeit von Bildungseinrichtungswahl und Geschlecht nicht widerlegen.
\end{enumerate}

\cparagraph{Beispiel} $550$ Personen wurden nach Rauchgewohnheiten und sportlichen Betätigungen befragt. Von den $381$ Nichtrauchern treiben $56$ regelmäßig, $143$ gelegentlich und $182$ nie Sport. Unter den Rauchern betragen entsprechende Häufigkeiten $15$, $46$ und $108$.\\
Kann man (mit Signifikanzniveau $0,01$) zeigen, dass das Rauchverhalten und sportliche Betätigung als abhängig angesehen werden können?\\
Lösung:\\
$X$ … Rauchgewohnheit ($1=$ Nichtraucher, $2=$ Raucher)\\
$Y$ … Sport ($1=$ regelmäßig, $2=$ gelegentlich, $3=$ nie)\\
\begin{tabular}{c | c c c | c}
$X\setminus Y$ & $1$ & $2$ & $3$ & $\sum$\\\hline
$1$ & $56$ & $143$ & $182$ & $381$\\
$2$ & $15$ & $46$ & $108$ & $169$\\\hline
$\sum$& $71$ & $189$ & $290$ & $550$
\end{tabular}
\begin{enumerate}
\item $\alpha = 0,01$
\item $H_0: X\text{ und }Y\text{ unabhängig} \quad H_1=X \text{ und }Y \text{ nicht unabhängig}$
\item $T=\sum_{j=1}^2 \sum_{k=1}^3 \left(H_{jk}-\frac{H_j H_k}{n}\right)^2 \cdot \frac{n}{H_{j*}H_{*k}}$\\
Trage $\frac{h_{j*}h_{*k}}{n}$ in Tabelle ab:\\
\begin{tabular}{c | c c c | c}
$X\setminus Y$ & $1$ & $2$ & $3$ & $\sum$\\\hline
$1$ & $49,2$ & $130,9$ & $200,9$ & $381$\\
$2$ & $21,8$ & $58,1$ & $108$ & $89,1$\\\hline
$\sum$& $71$ & $189$ & $290$ & $550$
\end{tabular} z.B. $\frac{381\cdot 71}{550}=49,2$\\
$t=\frac{(56-49,2)^2}{49,2}+\frac{(143-130,9)^2}{130,9}+\ldots + \frac{(108-89,1)}{89,1}=12,45$
\item $K=(\chi_{1\cdot 2, 0,99},\infty) = (9,81\;,\; \infty)$
\item $t\in K \Rightarrow H_0 $ ablehnen
\item Interpretation: Auf Grundlage der SP lässt sich die Unabhängigkeit von Rauchgewohnheiten und sportlicher Betätigung widerlegen (sie sind also abhängig).
\end{enumerate}


%\newpage
%\printbibliography

\end{document}