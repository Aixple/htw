\section{Grundlagen}
\subsection{Motivation}
\slides{04-mem}{2}
\subsection{Probleme}
\slides{04-mem}{3}
Prüfungsfrage: Welche Arten von Fragmentierung gibt es?
\begin{itemize}
\item intern: Segmentgröße „zu groß“ $\to$ kleinere Segmente belegen trotzdem ganzes Segment
\item extern: Stichwort „defragmentierung“ $\to$ Segmente sind verteilt mit Lücken dazwischen
\end{itemize}

\section{Bitmap}
\slides{04-mem}{4}
\subsection*{Blockungsfaktor}
\slides{04-mem}{5}

\section{Freispeicherliste}
\slides{04-mem}{6}
Nachteil: Verteilungsaufwand (Pflege der Liste, Folgen der Pointer in der Liste usw., Finden von freien Listenelementen)!
\subsection{Implementierung: Blöcke mit integrierten Headern}
\slides{04-mem}{7}
$\to$ Liste wird im Speicher integriert.\\
Nachteil: noch ineffizienterer Zugriff (generiert viel Cache-misses/pagefaults).\\
Vorteil: ist fehlertoleranter (Liste kann nicht überschrieben werden, da sie im Hauptspeicher integriert ist).
\subsection{Suchstrategien}
\slides{04-mem}{8}
First/Next Fit: beste Strategien, dabei First Fit das bessere (Daumenregel: da schneller, die Fragmentierung ist zweitrangig).
\slides{04-mem}{9}
Best Fit: es hat sich gezeigt, dass es sich nicht lohnt.\\
Wort Fit: nur „akademischer Natur“
\subsection{Techniken zur Effizienzsteigerung}
\slides{04-mem}{10}
\slides{04-mem}{11}
\subsection{Getrennte Freispeicherliste (Segregated Fits)}
\slides{04-mem}{12}
\slides{04-mem}{13}
Vereinigung benachbarter freier Segmente kostet wieder Geschwindigkeit!
\subsection{Buddy-Verfahren}
\slides{04-mem}{14}
Teilung passiert rekursiv:\\
Wenn nur ein 1MiB Block frei ist und 78KiB gefordert sind, wird des 1MiB zerstückelt:
\begin{itemize}
\item 2*512KiB (davon eins wieder zerstückelt)
\item 2*256KiB (davon eins wieder zerstückelt)
\item 2*128KiB (davon wird eins ausgeliefert).
\end{itemize}
Resultiert in freien Blöcken:\\
1*512KiB, 1*256KiB, 1*128KiB
\subsubsection*{Beurteilung}
\slides{04-mem}{15}

\section{Virtueller Speicher}
\lecdate{10.05.2017}
\subsection{Motivation}
\slides{04-mem}{16}
\subsection{Seiten vs Kacheln}
\slides{04-mem}{17}
\slides{04-mem}{18}
Kacheln/Seitenrahmen: Segmente im physischen Speicher\\
(virtuelle/logische)Seiten: Segmente im virtuellen Speicher\\
MMU+OS: Memory Management Unit (im Prozessor) + Betriebssystem (Prozessor muss es unterstützen und Betriebssystem muss es nutzen)
\subsection{Gestreute Speicherung}
Umsetzung virtueller in physische Adresse
\slides{04-mem}{19}
Seitentabelle existiert für jeden Prozess.
\subsection{Seitentabelleneintrag/Page Table Entry (PTE)}
\slides{04-mem}{20}
\subsubsection{Größe der Seitentabelle}
\slides{04-mem}{21}
\slides{04-mem}{22}
Zugriffe: Immer eins mehr als die Hierarchiestufe.
\subsubsection{Beispiel: Zweistufige Seitentabelle i386}
\slides{04-mem}{23}
\subsection{Demand Paging}
\slides{04-mem}{24}
\subsection{Seitenfehler/Pagefault}
\slides{04-mem}{25}
\subsection{Einlagerungstrategien}
\slides{04-mem}{26}
\subsection{Seitenaustauschverfahren}
\slides{04-mem}{27}
\subsubsection{Optimales Verfahren, LRU}
\slides{04-mem}{28}
\subsubsection{Not Recently Used (NRU)}
\slides{04-mem}{29}
\slides{04-mem}{30}
\subsubsection{FIFO, Second Chance}
\slides{04-mem}{31}
Second Chance Lazy Evaluation: Im „Uhrzeigersinn“ durch die (Ring-)Liste gehen und alle R-Bits auf 0 setzen wenn 1 war oder Eintrag löschen, falls R-Bit 0.
\subsubsection{NFU, Aging}
\slides{04-mem}{32}
\slides{04-mem}{33}
(Hier würde also 3. rausfliegen)
\subsection{Arbeitsmenge (Working Set)}
(nur geringfügig relevant für Klausur)
\slides{04-mem}{34}
\slides{04-mem}{35}
\slides{04-mem}{36}
\subsubsection{Abhängigkeit der Größe der Arbeitsmenge von Delta}
\slides{04-mem}{37}
\slides{04-mem}{38}
\subsection{Idee für Ersetzungsstrategie}
\slides{04-mem}{39}

\subsection{Beladys Anomalie}
\slides{04-mem}{40}
\slides{04-mem}{41}




