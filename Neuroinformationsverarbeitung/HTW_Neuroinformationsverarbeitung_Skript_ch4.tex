\lecdate{21.11.2017}
\section{Probleme des EBP-Algorithmus}
\subsection{Resultierend aus Gradientenabstieg}
\slides{NI_WS2016_Kap4_BP_ext}{4}
Kommt aus lokalem Minimum nicht mehr raus, weil dort der Gradient $0$ ist $\Rightarrow$ es kann keine Änderung mehr statt finden. Einzige Lösung: neu Initialisieren bzw. willkürlicher Schritt.
\slides{NI_WS2016_Kap4_BP_ext}{5}
\slides{NI_WS2016_Kap4_BP_ext}{6}
\slides{NI_WS2016_Kap4_BP_ext}{7}

\subsection{Resultierend aus Netzwerk-Topologie}
\slides{NI_WS2016_Kap4_BP_ext}{8}
Sehr weit außerhalb des Arbeitsbereichs bekommt man einen kleinen Gradienten ($\corr$ Adaptionsgeschwindigkeit gering)
\slides{NI_WS2016_Kap4_BP_ext}{9}

\section{Training mit Momentum-Term}
\slides{NI_WS2016_Kap4_BP_ext}{10}
\slides{NI_WS2016_Kap4_BP_ext}{11}
„Langsamer ins Tal gleiten, Schwung von starkem Abstieg ins Plateau mitnehmen.“

\section{Modifikation der Ableitung der Transferfunktion}
\slides{NI_WS2016_Kap4_BP_ext}{12}
Schrittgröße hat ein festes Minimum, Gradient gibt dann nur die Richtung an.

\section{Training mit Weight-Decay}
\slides{NI_WS2016_Kap4_BP_ext}{13}
\slides{NI_WS2016_Kap4_BP_ext}{14}
\slides{NI_WS2016_Kap4_BP_ext}{15}
\slides{NI_WS2016_Kap4_BP_ext}{16}

\section{Manhatten-Training}
\slides{NI_WS2016_Kap4_BP_ext}{17}
\slides{NI_WS2016_Kap4_BP_ext}{18}
$\To$ wie Modifikation der Ableitung der Transferfunktion, nur für beide Richtungen.

\section{Eigene Schrittweite für jeden Parameter}
\slides{NI_WS2016_Kap4_BP_ext}{19}
\slides{NI_WS2016_Kap4_BP_ext}{20}

\section{Resilient Backpropagation (Rprop)}
\slides{NI_WS2016_Kap4_BP_ext}{24}
\slides{NI_WS2016_Kap4_BP_ext}{25}
\slides{NI_WS2016_Kap4_BP_ext}{26}
\slides{NI_WS2016_Kap4_BP_ext}{27}
\slides{NI_WS2016_Kap4_BP_ext}{28}

\section{Quickpropagation (Quickprop)}
\slides{NI_WS2016_Kap4_BP_ext}{21}
\slides{NI_WS2016_Kap4_BP_ext}{22}
\slides{NI_WS2016_Kap4_BP_ext}{23}

\section{Fazit}
\slides{NI_WS2016_Kap4_BP_ext}{29}
\slides{NI_WS2016_Kap4_BP_ext}{30}





